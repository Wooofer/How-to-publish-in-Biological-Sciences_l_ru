[["index.html", "How to publish in Biological Sciences: A guide for the uninitiated Welcome Why read this book Whats not in this book Structure of the book Why A guide for the uninitiated? Acknowledgments", " How to publish in Biological Sciences: A guide for the uninitiated John Measey 2021-06-01 Welcome Cover The Tower of Babel (by Pieter Bruegel the Elder 1563) represented the demolition and scattering of peoples so to impair their communication. To me, it is a similar story to the attempts of modern day publishers to turn the scientific project into a business that profits only them. The collapse is coming, but can we save the scientific project? Welcome to my guide on how to publish in the biological sciences. This guide is pitched at the early career researcher. It is not going to tell you what to write, but to demystify what goes on in the world of scientific publishing, and more broadly in the academic context. My intention is to demystify publication in the biological sciences, so that readers become aware of what is happening once they have submitted a manuscript, and how to better interpret the decisions made by colleagues who are reviewing and editing your work. Publishing has become vital for all academics, such that it is recognised that we inhabit a publish or perish academic landscape. Yet for some, the process appears to require little or no stress, while others are left in the cold. This book is meant to be a guide to those uninitiated members of the academic community, postgraduate students and early career researchers, to bring them up to speed with all the background information on publishing. Why read this book Publishing a paper in an academic journal should simply consist of submitting a publication worthy manuscript. But having a working knowledge of publishing will enable you to make better decisions about what, where and how to submit manuscripts. In this book, I explain the many choices that exist for those wishing to submit a manuscript for publication in the Biological Sciences. I describe publication bias, and how this is evidenced by reviewers and editors. Impact Factors and how the desire to track the performance of academics has led to unethical practices and exploitation of science and scientists. This guide provides an everything you wanted to know about publishing but were afraid to ask approach for anyone who still feels that there is more they need to know about publishing that might get them onto an even footing. Whats not in this book Depending on just how early you are in your career, there is a lot missing from this book but that has been provided in another book How to write a PhD in Biological Sciences. That book concentrates on getting PhD students started writing, while this book concentrates on the business of publishing. Hence, if you want extra information about writing in the biological sciences, I would point you to the other book. If you are happy with what you have written, but want help to demystify the publishing process, then this is the right book for you. There is common ground in both books, and I will point to important chapters relevant to publishing in the other book that are not reproduced here: Plagiarism, Mental Health, Being aware that you can get it wrong, Transparency Structure of the book This book is written in four parts: Part 1 - Getting your manuscript ready for submission Although you may have already done your research, and written your manuscript, getting it ready for publication will require a new set of hurdles for you to jump over. In this section, I discuss what you need to know before entering into the publication arena. What are scientific journals for, and who are the gatekeepers? How does peer review work? The publishing world is at a turning point, and before you start publishing you should be aware of the current reality in Biological Sciences around the currency of citations and how these relate to other metrics such as the Impact Factor and career advancement. You also need to know potential directions for publishing, including the need for transparency in your work, whether or not you should deposit your manuscript as a preprint, and who you should invite to be an author. Chapters are written for Early Career Researchers, and how to actively build and maintain a network to facilitate and support your work. Part 2 - Submission, reviews and reviewing, revising and resubmitting Sending a paper to a journal is like posting it into a black box where, after some time, you might simply get a rejection and have no idea what has happened. In this section, I take you through the mechanisms of submitting a manuscript from choosing the right journal for your submission, writing a letter to the editor, suggesting reviewers, entering metadata about your manuscript into the editorial management software, all the way to pressing the submit button. I explain how the editorial submission system works, and what you can expect from editors and peer reviewers. I take a practical approach to writing a rebuttal and explain how and why you should expect to revise your manuscript for the editor. The eventual goal of this section is to demystify the entire process between submission and acceptance, and to understand the process from the view of an editor and reviewer. Part 3 - Once your paper is published Once your article is accepted, you can celebrate together with your co-authors! You will need to submit the final version of your manuscript, have this type-set and then approve the proofs before a Version of Record appears. At this point, you can start to share your paper, but there are still some key steps that you can take to improve the dissemination of the research both to the academic community and to your funders, the public at large. Who is it best to share your research with, and what would be the best form to share it in? In this section, there are chapters that explain how to write a press release and a popular article on your paper, and how you can improve and monitor its circulation both in academia and in the general media and social-media, especially to those stakeholders who might use your findings. Part 4 - Further challenges in academia The last part of this book discusses the wider challenges posed in academia for those who want to continue on with it as a career, as well as advice for those who want to leave. This section deals with the growing problems driven by a publish or perish culture, and what this means for Early Career Researchers. Special focus is given to the paywall erected by many publishers, Open Access publishing and predatory publishers. I also explain the problems in the current system of biases in peer review, and the confirmation bias in scientific publishing. Instead of just presenting you with problems, this section provides insight into ideas that the academic community has in order to get over the current problems Other important hurdles that you might meet, such as retractions, mental health, fraud and bullying, receive in depth focus. The section ends with some advice to those who wish to continue a career in academia, as well as for those who want to leave it. Why A guide for the uninitiated? I think that most people with doctorates would agree that a PhD is not awarded to people because they are particularly bright or smart. If you had to be a genius then I wouldnt have a PhD. Indeed, I dont consider myself to be particularly clever, but I worked very hard to get my PhD. I was hampered by the fact that I didnt know anything about the goals and aims of the academic process of working towards a PhD, so it took a lot more work, wasted time, and (lets not mince our words) real pain. The end product was a fraction of the potential that I could have achieved, if I had understood more about the process. If I had only had a guide to tell me what it was all about, I could have saved myself so much time and energy. In short, I feel that I was uninitiated, and this is the guide I wish that I had had. So, this guide is my practical attempt to help you to get you up to speed in the world of academic publishing, specifically for the biological sciences. Too often, however, its a nightmare journey of cul-de-sacs, and groping in the dark. Acknowledgments There are a great many people that I need to thank. First and foremost are my students, past and present, who have inspired me to put together first the blog posts and then the book. It is because you wanted more that I put this together. I have also been a student, and have been inspired by colleagues around the world who have been exemplary advisors. This book contains lots of links to blogs and articles written and posted freely on the internet by others who also aim to demystify and help. I thank this greater academic community (especially #academicTwitter) for sharing and inspiring. Thanks go to the many reviewers and editors who have taken their time to improve my writing. I am still learning. Lots of the text in this book has been improved by feedback from my students and postdocs. A special mention must go to my brother, Richard, who has hosted my lab website for more than a decade, and especially for saving blog posts from hacking attacks. Thanks also to my wife, Thalassa, who proofread many of the blog posts after I had published them late at night, so that I could correct them over breakfast in the morning. James Baxter-Gilbert, Jack Dougherty, Anthony Herrel, Allan Ellis, Lisa and Mark OConnell, James Vonesh, Carla Wagener all read or commented on different aspects of the book. Thanks are also due to my colleagues at the Centre for Invasion Biology, the Department of Botany and Zoology, and Stellenbosch University. A special thanks to the librarians who have supported many of my more extreme rantings about publishers. John Measey Cape Town "],["author.html", "About the Author Do you have something to contribute? If you havent already, read the other book Creative Commons License Disclaimer", " About the Author John Measey is Associate Professor of Biological Sciences at Stellenbosch University. He has authored or co-authored more than 200 peer reviewed scientific papers and book chapters, and five books. He has been the Editor-in-Chief of an ISI journal for 9 years, and currently serves as Associate Editor for 4 other journals. He has graduated more than 20 postgraduate students, and his blog on writing and publishing in biological sciences is read by thousands globally. British born and educated, he lives and works in the beautiful Western Cape, South Africa. Do you have something to contribute? This book is written in bookdown (Xie 2016) specifically to make it a live project that will be open to anyone who wants to contribute, improve, or use as the basis for your own book. The easiest way for readers to contribute content directly is through a GitHub pull requests. At the repository for this book, you will find Rmd files for each chapter, and as a GitHub user, you can simply edit the Rmd file and submit the changes. If I am happy with the changes proposed, I will merge your content with that of the book and add your name to the Acknowledgements. One of the amazing potentials for bookdown books is that all the files for this book are hosted in a repository on Github. You have the opportunity to fork this repository and write your own version for a different discipline, a different language or for a different region of the world. It is also my hope that this guide can grow to become a community of practice for those conducting PhDs in Biological Sciences. It will not be possible to cover every aspect of writing a PhD in Biological Sciences, but it may be that I have missed out ones that are very important to you. Equally, parts of what is currently written will become obsolete as new initiatives begin, and old problems are resolved. For this reason, this guide needs to be a living document, and anyone who wants to provide feedback or contribute new sections is more than welcome. Please feel free to open an issue, or make a Pull Request if you spot a typo. If you havent already, read the other book How to write a PhD in Biological Sciences: a guide for the uninitiated by John Measey Embarking on a PhD is intimidating as, for most students, it will be their first experience working within the academic system. The voyage of discovery is often made very frustrating as much of what goes on in academia is assumed knowledge. Academics accumulate knowledge throughout their careers, but what can be done for those who are uninitiated? What is needed is a guide that postgraduate students can refer to before, during and while making decisions about their time within academia. Note that this is not a rulebook. There are times when the guide will be accurate and others when it will be vague, but providing some insight to point you in directions where you can explore more. The intention then is to provide you with a starting point from which you can establish your confidence in the academic writing process, and build your own creativity. Creative Commons License How to publish in Biological Sciences: A guide for the uninitiated is copyright to John Measey and distributed under a Creative Commons BY-NC-ND 4.0 International License. You may freely share this content for non-commercial purposes, with a source credit to www.john.measey.com Disclaimer Although I have tried to make the information is this book as accurate as possible, it is provided without any warranty. The author and publisher have neither liability nor responsibility to any person or entity related to any loss or damages arising from the information contained in this book. knitr::kable( head(iris), caption = &#39;We must have the iris data and some R code, otherwise it would not seem right&#39;, booktabs = TRUE ) TABLE 0.1: We must have the iris data and some R code, otherwise it would not seem right Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa "],["the-reasons-for-publishing-your-work.html", "The reasons for publishing your work", " The reasons for publishing your work I assume that you will all want to publish the work from your thesis, but its worth going through the points here about why publication is so important. If your work is unpublished, then it will not be used. Without use, all the work that you put into it falls away. Your published work will become the foundation for future students and academics who are active in your field. This might well be in another country or on another continent. Your work was most likely paid for by tax-payers in the country where you studied. Publishing this work is a way of handing back the value of what you found. If it is published Open Access, the public can also read it for themselves. Other funders of your thesis work may have made publication a prerequisite of the funding criteria. It is hoped that by publishing your work it will become more accessible to the scientific community. By publishing your work you will find that both you, and your work, become known by an international community that may well invite you to participate in the academic process further (Marks et al. 2013). Both inside and outside of science as a career, peer reviewed published papers are seen as an important accomplishment in addition to the production of your thesis. The work that you have already put into your thesis (especially if you have followed the advice in this book!), will mean that you are close to having chapters that can be submitted as publications. Your advisor and lab colleagues who helped with your thesis work may depend on your publications. There is a lot of satisfaction to be had by seeing your work published. It has been argued that this depends on who you are and where you come from (Husemann et al. 2017). The satisfaction of having someone say how enjoyable or inspiring your work is to read will certainly not be as frequent as if you managed to publish a novel or newspaper column. But when it does happen, it will bring a smile to your face. This is by no means an exhaustive list, but I hope it will give you some insight into the importance of publishing your results. To counter this assertion, please be aware that there is also research that suggests that publication driven science is not healthy, and that we need a new way to motivate science (e.g. Stergiou and Lessenich 2014). Indeed, it has been suggested that the publish or perish mentality of academia has resulted in the retention (and even deterioration) of poor experimental design, and hence higher false positives in the behavioural sciences (Smaldino and McElreath 2016). We will come back to this later in part 4. However, before you can join the debate about the future, Id argue that you need to provide your credentials for the present. Given that you are reading this book, I will assume that you plan to publish your work. However, there are still some basics that I think it is worth considering in this first part of the book: What is a journal for? What is it possible to publish? What is the journal Impact Factor? Why are citations important? "],["closedtoopen.html", "Chapter 1 The transition from closed to open 1.1 Three fundamentals of publishing in Biological Sciences 1.2 Open Science - a vision of the future", " Chapter 1 The transition from closed to open There are a lot of problems in publishing in the biological sciences, but it doesnt have to be this way. The aim for this book is firstly to help you navigate the current closed system (acknowledging that parts are open), and act as a catalyst toward a more open, transparent and equal system for the future not only of publishing science, but permeating throughout the culture of the scientific project. We have all the tools to make this transition now, and I think that this change will likely come within the time frame of the careers of you as an ECR reader. But as you will see, this change needs to be driven. 1.1 Three fundamentals of publishing in Biological Sciences There are three fundamental concepts that lie at the heart of understanding of current publishing models in the Biological Sciences (Figure 1.1). In themselves, none of them should be particularly influential as they dont relate to your study, how well the study was done or what your results were. Nevertheless, these three aspects of publishing are key in your understanding of the nuances of publishing, and your understanding will likely make the difference between having publishing your work as an obstacle that is occasionally insurmountable, and finding your way with a lot more ease through the process. 1.1.1 Gatekeepers The journal editor sits at the centre of this triangle, and has the power, backed by their gatekeeping editorial board and associate editors, to continue the current model, or oversee the change. Editors make decisions, not simply whether to accept or reject your manuscript, but also to implement policies that take their journals in one direction or another. In some models, they are given this power (usually democratically) by the scholarly society that they represent, and oversight is granted by an editorial board who mediate in any dispute, but also in theory have influence over the editorial policy. Editors appoint associates that handle many of the manuscripts that are submitted, shuffling them between reviewers and authors until they feel that they are worthy of publication (or not). These associate editors are also responsible for implementing the policies of the editor, the editorial board, and the scholarly society. In models where there is only a (for-profit) publisher, the publisher appoints the editor and together they appoint the editorial board. In both models, the editorial board, editors and associate editors are thought of as being the gatekeepers to the scholarly integrity that permeates scientific publishing. FIGURE 1.1: A simple schematic for the three fundamentals of publishing in the Biological Sciences. Citations, peer review and impact factors each have direct impact on each other and your understanding of each one and how they relate to the other will be pivotal in clarifying your understanding of how to publish your work. Gatekeeping takes a lot of time and effort, and there are plenty of places where the current system lacks the transparency that is needed. Each of the three concepts in current publishing need to be changed to open up the system for a more equitable future, and eliminate the current biases that favour the select few. 1.1.1.1 Citations and impact factor The more citations a journal gets (in the first 2 years following publication), the higher its Impact Factor. Higher Impact Factor journals will want any submissions that they choose to have a good chance of garnering as many or more citations than their current impact factor following publication. This can mean that if you have co-authors that are in active groups, publishing a lot, they are more likely to have their work accepted in higher IF journals (they are also likely to have more experience at science and publishing). 1.1.1.2 Impact Factor and Citations The relationship flows in the other direction as the higher the impact factor of the journal that you publish in, the more likely your work will be seen, read and cited. Citations garner more citations, and your work bearing your name will become better known within your discipline impacting your chances of getting a job, being invited to give talks at conferences or at visits to departments. 1.1.1.3 Impact Factor and Peer Review Your peer reviewers are likely to be directed differently depending on the Impact Factor of the journal. As the Impact Factor increases, so the Peer Reviewers will be asked about the novelty and impact (i.e. citations) of your work. 1.1.1.4 Peer Review and Impact Factors The impact factor of the journal may well influence which peer reviewers are prepared to review your work. In theory, better read (usually more senior) reviewers will provide more insight and may well refuse to review for journals that they consider do not garner sufficiently interesting (novel and impactful) work. 1.1.1.5 Peer Review and Citations Your reviewers are likely to look at the papers that you cite and this will inform them of the scholarly quality of your work. When you miss important citations, or omit contrasting viewpoints, you demonstrate a failure in your scholarly undertaking to read the literature. 1.1.1.6 Citations and Peer Review Peer reviewers may well suggest citations for you to consider in your work. These suggestions can be legitimate attempts to increase the value of your work, and through these citations its visibility. There are also reviewers who will suggest that you cite their own publications, and even editors that suggest that you cite papers in their journal. 1.2 Open Science - a vision of the future The way I advocate in this book is toward a vision for a future of Open Science (1.2). This future is both open and transparent. The transparency means that there is no need for this book, as there will be no hidden agendas or assumed knowledge needed for Early Career Researchers. Instead, it will be a WYSIWYG system. FIGURE 1.2: A simple schematic for Open Science. Open science relies on the open nature of publication, communication and data. This ideal world is free of the metrics that have dogged research in the past leading it into a profit making game for private publishers, and promoting the careers of a few elite scientists. The simple schema for Open Science shown in Figure 1.2 is taken from OCarrroll et al (OCarroll et al. 2017). The three areas of Open Science start with Open Data, the need to share both data, the code to analyse data, and the details for open source software with which to do the analysis all within open data repositories. The sector on Open Communication replaces the current closed peer review systems with an Open framework where all actors are named and any interests declared. These include any journal gatekeepers (if involved). Lastly the publishing of the work is Open Access for other scientists and the public. This includes both proposals, preprints and published articles. The Open Science framework is incompatible with the for-profit scientific publishing model that drives the current model (Figure 1.1). It can be hoped that the transition from Figure 1.1 to Figure 1.2 will be swift and happen within your career. However, the actors at play in this system are not neutral, and need both bottom up challenges (from yourselves as ECRs) as well as top down pressure (especially from large funding agencies). This change will be as exciting as it is challenging, and I hope that the contents of this book will equip you to participate fully. "],["whatjournalfor.html", "Chapter 2 What is a scientific journal for?", " Chapter 2 What is a scientific journal for? I think its worth reflecting on why we have scientific journals, and what they are for. Primarily journals are a means of communication for the academic community. They pass on the findings of individuals and teams of academics from all over the world. By having a date when they are published, together with the names of the authors, they record primacy [see taxonomic names]; that is who came up with the finding or idea first. Also see important arguments against the need for primacy (2012) They attempt to register legitimacy by collating and integrating comments and concerns through peer review. Lastly, they archive these findings so that in future people can build on the work. . There are so many scientists in the world publishing so many papers that its not possible for all scientists to read everything. Today annual growth in scientific papers of 5.1%, equivalent to a doubling time of 13.8 years (Bornmann, Mutz, and Haunschild 2020). Contrast this with the early days when there were only two journals and they published all of the studies that were being undertaken at the time. Over time there has developed a natural hierarchical system of what scientists will read. This is reflected in citations, and the simplest measure of journals is something called the Impact Factor which is discussed in a chapter below. It has been said that authorship is a relatively modern concept, emerging from the empiricism of Englands middle-ages (see Cronin 2001). In our recent history, it is considered to be important for individuals to record who thought of what and when. From these authors, we give societal author-ity. This gives credit where its due. In the big scheme of things of course its not important who did it. We know from historical examples like Darwins theory of natural selection and Wallaces very similar thoughts will merely be a product of many people who were thinking about these ideas at the time. Although certain authors may be ahead of their time, the majority of thoughts and ideas that come around today are a product of their time. However, for individuals and their institutions it can be important to claim credit as this may translate into some monetary value (e.g. with patents) or a prestige value. The regulated system of a taxonomy puts a lot of importance on the priority of who described what and when (you can read more about that in the chapter on taxonomic nomenclature. The system of editors and peer reviewers determining whether or not a manuscript possesses sufficient merit to be published is still regarded as the gold standard in science (Mayden 2012). As you will discover, it is often a very high bar to achieve. Of course both editors and peer reviewers are human and so the system is not perfect. Well talk more about peer review in the next chapter. Archiving the findings of scientists is perhaps one of the most important roles of publishers that we should be most concerned about. In my career I have seen the changes from strictly paper dissemination of scientific findings as it was for the past 350 years, to primarily electronic findings many of which and never printed by the majority of readers. We should be concerned about how long these records will last. If you have never thought about the longevity of data storage, then this is something that you should give some thought to. We all need to change our perspectives on long-term thinking as this impacts almost every societal function (see the Long Now Foundation). "],["peerreview.html", "Chapter 3 What is peer review? 3.1 History of peer review 3.2 How high is the peer review bar? 3.3 Who are your peers? 3.4 The role of the editor 3.5 Reviewer models 3.6 Learn more about peer review by doing it", " Chapter 3 What is peer review? Peer review is often considered to be the gold standard of science (Mayden 2012). Manuscripts that have passed peer review should be considered to have been scrutinised to the highest level. If ones peers in the scientific community consider that a manuscript is worthy of publication, then it meets the high standards of peer review. The review of peers acts as the gatekeeper to all that is good in science, and excludes all that is bad. A lot has been written about peer review (&gt;23000 articles!), and if youd like to read more (Eve et al. 2021). While the views in the above paragraph are generally held, there is also a general acknowledgement that there are a lot of problems with peer review. That this has been widely acknowledged is probably an understatement as most people who have experienced would likely already know. These problems will be address in a another chapter in the last section of this book. Peer review is a fundamental aspect of publishing, and so there are several chapters in this book that are dedicated to different aspects. In this chapter, I attempt to explain what peer review is. Elsewhere there are descriptions: what to expect from peer reviewers how to respond to peer review how to conduct peer review problems with peer review This chapter provides an overview of the topic, but you may need to refer to the other chapters first depending on what your current need is. 3.1 History of peer review The history of peer review is surprisingly modern. We have already seen that journals themselves only date back to the 17th century (see chapter in Part IV). These journals included a form of peer review in that letters concerning studies could be published, along with comments made at presentations. However, the type of systematic enforced peer review described in this book is very recent (Eve et al. 2021). The journal Nature for example only started systematic peer review for its articles in 1973, and mainstream editor led peer review only really started in the late 1940s (see Tennant 2017). Typical society journals have followed a similar form of evolution from newsletters to scholarly journals (J. Measey 2011). 3.2 How high is the peer review bar? It is difficult to emphasise how high the peer review bar is. When your manuscript is scrutinised by your peers, it is very rare that it will get accepted without modifications. This is because the experience of academics tends to be so wide, and vary so much from individual to individual, that it is almost impossible to predict what a peer reviewer will see when they read your manuscript. You should expect that your manuscript will not receive an easy ride through peer review. But you should also expect that it will be improved. As we will see later, this improvement might not be immediately obvious to you when you first read the comments. It is also important to note that as the author, you are the net beneficiary of the peer review process, and that once you press the submit button (free for the vast majority of us, but see part IV), a cascade of events happen all of which are done in the name of you and your submission. It stands to reason then that you should be sure that your manuscript is as ready as it can be for submission. 3.3 Who are your peers? Essentially the peers in peer review are people that editors find and persuade to conduct the peer review. it can be difficult to find people to conduct a peer review. Although only 2 or 3 reviews are needed sometimes as many as 20 or 30 individuals can be approached. Perry et al (2012) lamented on the increasing difficulty in persuading colleagues to conduct peer review of manuscripts. While your peer might sound like someone who is in an equivalent position to you, this may well not be the case. If you are junior, your peer reviewers may be very senior. Equally, senior authors may have peer reviewers that may be very junior. Does this make a difference? For some people it might, especially when they know the other party and assign some level of competence associated with their seniority. Of course, both junior and senior researchers are capable of getting points in peer review wrong, just as both are also capable of providing insightful feedback. The editors are those in the hotseat about what it all means. 3.3.1 Professionals Peer reviewers are normally professionals. Academics postdocs or postgraduate students. Occasionally there are amateurs who have very high academic standards and who can be contacted to conduct peer review. 3.3.2 Scholars Peer reviews should be familiar with the subject area to a good level of scholarly achievement. Undergraduates and many postgraduate students would not be considered eligible by many editors as selection for peer review. Personally I found that many PhD students, especially those in their final stages of studying are very good peer reviewers. 3.3.3 Specialists Peer reviewers should be specialists to some degree of the area on which the manuscript is based. often its not possible to be a specialist in every area of a manuscript. But in the case where you are not proficient it is important to inform the editor. 3.4 The role of the editor The editor has an important role to play (see Figure 3.1): To assess your submission Does it align with the journal? Is it sound enough to send to peer review? Whether to use a specialist associate editor To choose the peer reviewers Without potential conflicts of interest Who can cover the content of the manuscript Who agree to doing the review within the prescribed time To assess the reviews of the reviewers Mitigate for potential bias in the reviews Judge what is in the manuscript against what reviewers have found Determine whether sufficient merit remains in order to undergo a decision (including more peer review) Write the decision Section to write - Associate editors, Editorial board &amp; the gatekeepers of science who are the gatekeepers? (Willett 2013) (Braun and Dióspatonyi 2005) (Goyanes and Demeter 2020) When you bear in mind that the decision is likely to involve some arbitration between different reviewer opinions, and to direct the authors about what changes need to be made to a ms in order to make it acceptable, the decision is not a simple exercise. Making an editorial decision will require careful reading of the manuscript, as well as looking past potential biases of reviewers. FIGURE 3.1: A simple schematic for one round of peer review. In this figure, you (yellow circle) start by submitting your manuscript (ms) to an editor of a journal (pink circle), who assesses it and send it out to 3 reviewers (green circles). Each reviewer independently generates an opinion in the form of a review (rev). They each pass this back to the editor, who then makes a decision on your ms. Each light grey arrow going out may be quite quick (a few days or weeks), but the dark grey return arrows might take a long time (often counted in months). Reviewers come in different flavours (see below) All of the above processes need to be worked around the editors existing job, professional and research commitments (i.e. the day job), and their home life. 3.4.1 What do editors get out of participation? The prestige associated with editing a journal Increase your network By being a good editor, youll increase your soft power Participate in the production of knowledge Give back to a system in which youve benefited as an author 3.5 Reviewer models Reviewers themselves come in different flavours that are (mostly) predetermined by the journal regulations. 3.5.1 Blind reviewers Blind reviewers know who the authors are, but are anonymous to the author, but known to the editor. This can be considered the standard model in peer review. There are plenty of problems with this model as reviewers may use their anonymity to hide their biases and are even known to become abusive. Although reviewers may be anonymous, sometimes communities are so small that authors might guess who these people are, simply by their comments and suggestions. Although this is the most common type of review format it is the least recommended. If you feel that there may be potential reviewers who bear a grudge to your laboratory, your institution or your work then it may be better to avoid this kind of review system. 3.5.2 Double blind reviewers Double blind reviewers do not know who the authors are, and are anonymous to the author, but known to the editor. The double blind model was conceived to remove some of the potential biases (particularly around gender, nationality and race) that might come about through the identification of the authors and their addresses. Again, it has been mooted, and it is my also experience, that in a small community one tends to know who authors and reviewers are simply by the subject of the manuscript and the comments (see also Eve et al. 2021). However, even when groups can be identified, it is not always possible to determine the author or author combination, and so biases around gender and race may still be avoided with this model. 3.5.3 Tripple blind reviewers In theory, it is possible for the editor, after having chosen the reviewers, to be blinded from their identity once they submit their review. This may prevent the editor putting more importance to a more senior reviewer, and ignoring more junior viewpoints. 3.5.4 Open reviewers Open reviewers know who the authors are, and are known by the authors and editor. Note that this is a simplification of a complex set of potential openness. For a thorough discussion see (Ross-Hellauer 2017). The open reviewer model does encourage good behaviour (or the avoidance of some of the worst problems) on the part of reviewers. However, reviewers remain brutally direct even when they are named, such that these comments may be construed as bruising by the authors (Eve et al. 2021). 3.5.5 Public reviewers Public reviewers know who the authors are, and are known by the authors and editor, and their names (and often their reviews) are made available to the public. This model is relatively recent, and comes along with the possibility of making the reviews with their own DOIs available along with the accepted manuscript. It is worth noting that, to date, reviews for manuscripts that are rejected do not get posted using this or any other current publishing model. It does exist in the world of preprints. This could be considered the most transparent system for any journal. It has also been called Open Evaluation (OE) by Kriegeskorte et al (2012). PeerJ and ELife are among a very small handful of journals that have tried to instigate this model. Nevertheless it can be very difficult to find reviewers who are prepared to reveal their names to the authors. A study that compared PeerJ publications in which reviews were made public, compared to those that authors chose to keep closed, suggested that the subsequent number of citations increased by a third for open reviews (Zong, Xie, and Liang 2020). It is only possible to speculate about why this might be. The decision at PeerJ to open reviews is made first both by reviewers (who opt not to be anonymous), and then by authors (who opt to open reviews). In studies where both groups co-operate, we might hope that this results in a higher quality product. Indeed, public reviews tend to be longer, although positive comments are more frequent in closed reviews (Bornmann, Wolf, and Daniel 2012). It is equally possible that authors who choose to open their peer review are more progressive and active within research (leading to more citations). 3.6 Learn more about peer review by doing it As an early career researcher, you may well be asked to conduct peer review of an article in your specialist field. If you have never been asked, then tell your mentor to recommend you (usually when they turn down an opportunity to conduct peer review, they have an opportunity to name someone else. If you have told them that you want some manuscripts to review, it should be straightforward for them to add your name when appropriate. When you register in the editorial manager software for journals that you submit to, there is often an option to state what areas of your field you are particularly specialised in, and whether or not you are interested in conducting peer review in these areas. This is also worth doing if you want to generate requests for conducting peer review. Another way of getting noticed to to sign up to society training programmes for peer review. These might happen at conferences, or could be web based courses. Although it should be noted that such courses may have little impact to improve peer review (Schroter et al. 2004). You will need to register to conduct such training, with the result (sometimes) that your name will be entered into the editorial management software, together with your trained status. Some courses actually have live mentors who read through and critique reviews that you conduct. All of these are a good idea, but be sure to check out the time commitment required before you start. Good reviews get noticed by editors, and it is a good way of increasing your network through soft power. We will look in more detail about how to conduct peer review later in this book. 3.6.1 What do peer reviewers get out of participation? Reviewers receive: the opportunity to increase their networks (particularly important for ECRs) participate in the generation of knowledge generate some soft power (especially if you renounce your anonymity) learn about new and upcoming literature give back to the community what they expect to receive (i.e. they are also authors and will benefit from peer review) learn about the inside of the peer review system (particularly important for ECRs) Note that what reviewers get out of participating in peer review is almost identical to editors. Editors benefit at a higher level, mostly as their names are seen more often by more people, but with the drawback that they do a lot more work than the peer reviewer. I have heard some members of the community claim that they will continue to accept peer review requests until these cover what they are demanding of the community (i.e. reviews offered per year = submissions per year x ~2.5). Although this sounds very fair, I would suggest that the reality is more subtle. You shouldnt be accepting to conduct peer reviews for articles where you feel that you lack specialist knowledge. Neither should you be conducting peer review when you feel that you have a conflict of interest. For me, this eliminates around a third of my invitations. If you do have to turn down the invitation of peer review, then do it as soon as possible, and do suggest someone else that you think could do it. "],["transparency2.html", "Chapter 4 Transparency in publishing 4.1 Removing the prejudice around confirmatory bias 4.2 Introducing transparency in peer review 4.3 Removing profit from academic publishing", " Chapter 4 Transparency in publishing There is a great need for transparency in science, and one of the ways to achieve this is through preregistration of your research project to avoid confirmation bias. In order to make this effective, we need our journals to support the preregistration of research hypotheses and methods. Right now, journals should be openly advocating and encouraging preregistration with a plan to transition their journal in future. However, many editors are resisting this move as they feel that there is no support from the community. This may well be the case, but as we have seen, inequalities in science, and particularly in publishing (see Part IV), mean that editors can either be instruments of change, or at the heart of inequality in publishing. Either our editors will lead us toward transparency, or we as a community simply need to demand that they change their practices. Where it is happening, editors are responding to calls in transparency by making small steps (for example asking for open coding: Powers and Hampton 2019), rather than adopting transparency wholesale through the badge system set up by Kidwell et al (2016). 4.1 Removing the prejudice around confirmatory bias Confirmatory bias is the phenomenon increasingly seen in science that most studies published accept the alternative hypothesis, even though this is the least likely outcome of any experiment. Confirmation bias happens in publishing as editors prefer to accept papers that have a positive outcome. It has been suggested that this leads to a culture of bad science, and even fraud. One convincing set of evidence of confirmation bias is the decline of null results over time (Fanelli 2012). 4.1.1 Accepting the alternative hypothesis At the outset of our scientific research we pose a hypothesis with the expectation that we will be able to accept or reject our null hypothesis. We often think of rejecting the null hypothesis as the only result that we are interested in, but if we only ever reported these results we would not be responsible in moving our field forwards. That is, in a world where we only report significant results (i.e. reject the null hypothesis) we would necessarily keep repeating experiments where the null hypothesis is accepted, because there would never be the evidence that the hypothesis had been previously tested in the literature. This is called confirmation bias, and its actually practised by the majority of scientific journals who wont consider a null result. Its easy to see why this is a bad policy, but it is the prevailing culture in science. If journals only publish manuscripts that reject the null hypothesis (cf Franco, Malhotra, and Simonovits 2014), researchers are more likely to mine their data for positive results (P hacking), or re-write their hypothesis in order to reject the null (HARKing) (J. Measey 2021). Deceptive practices such as p hacking and HARKing are not in the interests of any journals (Forstmeier, Wagenmakers, and Parker 2017). 4.1.2 Inadvertent bias But positive results dont only come from deliberate manipulation of results. As humans we are predisposed towards positive results (Trivers 2011), and these can come about through deliberate manipulation of results, there are plenty of reasons why researchers might reach a false positive outcome. Forstmeier et al (2017) draw attention to cryptic multiple tests during stepwise model simplification, and the two types of researcher degrees of freedom (sensu Simmons, Nelson, and Simonsohn 2011): stopping rules and flexibility in analysis. Cryptic multiple tests during stepwise model simplification relates to the way in which adding predictors to models inflates the total number of models to test, making it necessary to adjust alpha accordingly (for repeated tests). However, Forstmeier and Schielzeth (2017) report that even with Bonferroni adjusted alpha levels, using random data they found that models with one significant effect happen around 70% of the time. The only way to keep this under control is to use sufficient sample sizes to maintain the power to distinguish between true positives and false positives. A handy rule of thumb from Field (2013) is that sample size needs to be 8 times the number of model predictors plus 50. Better would be to run a power analysis on your study design, and to critically reassess your predictors to eliminate as many as you can before you begin your study. Researcher degrees of freedom is the way that Simmons et al (2011) described ways in which researchers may inadvertently increase their chances of getting false positive results during analysis. The first is simply the way in which researchers decide to stop collecting data. Clearly, if preliminary collections showed a trend, but not a significant result, then collecting more data sounds like a good idea. However, as the collection of data is not independent (the first set is kept) then the first test is not independent of the second, and so the chance of getting a Type I error is cumulative. Even if multiple datasets are collected, those that are insignificant should also be considered and reported in order to get an unbiased estimate. The second major way in which analyses can turn out with false positives is through potentially infinite flexibility in analyses. There are lots of ways to analyse your data and given enough trials, it is quite likely that youll find one that gives you significant results. Moreover, on the road to conducting the test, there are many options that can change the outcome of the analysis: Inclusion or exclusion of an outlier Inclusion or exclusion of a covariate Transforming dependent variables. Inclusion or exclusion of baseline measures Controlling for sex (or another variable) as a fixed effect Excluding individuals with incomplete datasets The potential list of ways in which the outcome of your analysis could change quickly grows as the number of ways in which you could analyse the data also grows. But dont despair. Transparent help is at hand. 4.1.3 Novel research One criterion for many journals is that the research should be novel. This is increasingly practiced by journal editors as you move up the Impact Factor levels (see below). Novelty sells (just think of the meaning of new in newspaper), and thats the basis for selling higher stories from higher Impact Factor journals. We have already seen in part 2 the perils of testing unlikely hypotheses and how this inflates Type II errors as well as increasing the proportion of Type I errors. Novelty also stifles repeatability. If we can never repeat studies in science, then a fundamental tenet of the methodology is repressed. Reproducibility in science has received a lot of attention recently, as attempts to reproduce the results of highly cited research have failed (cites). This has been followed by general outrage among scientists that things should change (M. S. Anderson, Martinson, and De Vries 2007; Marcus R. Munafò et al. 2017), including a majority of those in biological sciences (Baker 2016). The irony that these reports and requests are published in exactly the journals that will refuse to publish research that seeks to repeat work (is not novel) is clearly lost on the editors. However, more nuanced views are also coming forwards to actively introduce variable conditions and sampling of biological variation into the study design to more fully represent the nature of biological variation making studies more likely to be replicated (Voelkl et al. 2020). 4.2 Introducing transparency in peer review As you will have already seen (above), the way in which editors choose and interpret reviewers can either reinforce their own prejudices, or help to make publication more open and transparent for everyone. The first step along this road is to move from double-blind review to triple-blind where editors cannot make decisions with prejudice towards certain reviewers (see above). Next is the need for open reviews with DOIs that allow open assessment of what reviews contained. For more details about problems in peer review, see above. In order to change this culture to a more transparent selection of scientific studies for publishing, we need journals to sign up to be transparent. Sadly, when most journals are approached, the editors either ignore the email or make an excuse about why it is not possible (see here). Of course, some journals have adopted the road to transparency, and we should be encouraged by the fact that they still exist, and that we could build on these initial front runners. 4.3 Removing profit from academic publishing Taking out the profiteering from publishers will take a more concerted approach. But the reality is that we have only ourselves to blame. The publishers are able to prey on us, as biological scientists, because we are used to getting all of the frills associated with their publishing model. This includes the designer layout, custom websites and editorial management systems. But the reality is that we really dont need any of these frills, and if we cared more about our science and less about the prestige that publishers have worked so hard to con us into thinking that their products have higher value, wed all be better off. Mathematicians and physisists are way ahead of us. Given that theyve shown the way, its simply up to us to follow their models. "],["whattowrite.html", "Chapter 5 What can you publish? 5.1 Reviews 5.2 Commentaries or Opinion pieces 5.3 Letters 5.4 Editorials", " Chapter 5 What can you publish? As you become more and more familiar with the academic literature you will quickly realise that actually you can publish just about anything. In this part of the book Im going to talk about some of the most common articles that you can get published but dont feel constrained. Indeed when it comes to publishing the skies the limit and youre only constrained by your imagination. As an early career researcher, you will have a body of work from your thesis that you may have already published, or be in the process of publishing. These likely contain a number of data chapters that will be published as a series of papers in scientific journals. However, its worth reflecting here about what it is possible to publish and how this might complement your existing and future publications, as well as increasing your publication portfolio with which to further your career. Certainly, having more publications is likely to increase your visibility in your community, as well as giving you more practice in academic writing. When considering the way in which citations work one of the things that you should notice is that reviews and in particular meta-analyses are cited way more times than most individual papers. For this reason one of the best things you can do is an early career researcher is to author a review on the topic of your thesis or even better a meta-analysis. 5.1 Reviews I provided an in-depth chapter on how to approach writing a review including different aspects of meta-analyses in another chapter of this book. The importance of a timely and much used review can be seen in a lot of citation maps such as in Figure 5.1. This was the first comprehensive review that sums the knowledge to that date on invasive fishes in South Africa, and so was cited most times that anyone published anything on invasive fish species in the country thereafter. Because this subject was the focus of a lot of research that happened in the area, you can see that it would logically sit at the centre of this subdiscipline. If you are unsure about whether or not a review is needed in your subdiscipline, then constructing a citation network such as that in Figure 5.1 might well be useful. FIGURE 5.1: A timely review can be at the heart of a citation network, such as this one on Invasive fish AND South Africa. In this citation network, you can see that the best cited paper (largest circle - green and centre) is a review by Ellender &amp; Weyl (2014). It has good connections with all of the three subject areas of this citation network, and although it was published in 2014, by 2021 it had been cited 111 times. Drawn with VOSviewer (Eck and Waltman 2010). 5.2 Commentaries or Opinion pieces Your opinion is important, or at least as important as anyone elses. Critical reading is a very important part of science and something that you should maintain throughout your career. From time to time you will come across articles and papers that you know are wrong. Many journals will accept commentaries or opinion pieces based on articles that they have already published. This is an opportunity for you to make a correction to something thats already published in the literature. Please know that here we are not talking about anything you think might be fraudulent for that there is another process (see here). There are several things worth considering before putting pen to paper on your commentary and sending it to the editor. If the people that wrote the article are in your network when a network close to yours then consider approaching them first about what you see as their error. You may end up getting along with them much better when you seek a solution together than writing something that antagonizes them. Even if they arent in your network you may find a way to increase the influence of your network through soft power instead of with a commentary. Check with your mentor that your interpretation of their error is correct and that pointing this out will have some value. Always try to do more than just say: no it isnt. Many journals wont be interested in a commentary that does nothing more than show an error. If possible try and include some original data or some original analyses in your response. Remember that your commentary will likely be sent immediately to the authors that youre commenting on before it is accepted by the editor. This means that they will also get a chance to comment on your commentary. However you will not get a chance to look at theirs. Have a look through at some instances of where this has happened in the literature in your field. If you can talk to the people involved and try to find out whether things worked out positively for them. Although I do not want to say that you shouldnt do this, you should know that what youre doing is not going to backfire on you especially as an Early Career Researcher. If you do decide to go ahead with this then consider asking other members of your network to join you. Although its not a sheer game of numbers it may help you to gauge a better and more equitable stance on your commentary. The other option you have is publishing a commentary that is very positive about the findings of a particular paper. Some journals published such commentaries about the contents of their journal as well as the contents of journals outside. Again this may be a better way of influencing soft power. There are also lots of possibilities about publishing pieces on what it is like to work within your area of the biological sciences. This could be about towards your experience as an early career researcher, but may take on just about any stance that you feel is important in your area of biological sciences (e.g. language, covid, racism, colonialism, etc.). 5.3 Letters These are generally very short pieces that you can write, often to high profile journals with letters pages. They can be used to raise the profile of all sorts of issues within your subject area or profession. Letters are going to have to be super polished and concise in order to get your point across in very few words. 5.4 Editorials You are unlikely to be able to publish an editorial without first being an editor, but there may be a potential for you to become an editor, associate editor or junior editor in a number of society or publishers journals. Once in position, the editorial is a powerful place to launch your opinion to subscribers. There are such things as guest editorials for special issues and special issues are particularly useful if you are an early career researcher. If you want to edit a special issue of a journal in your area then approach the editor well and advance of when you want to do it (possibly more than a year in advance). Its often good to have these things linked to an event like a symposium that you are organising. Once all the contents of the special issue are in you can put an editoriall together to explain what the idea was of the symposium and co-authored along with your other symposium organisers. Special issues of symposium often get cited more than other articles just because it is a collection of similar things altogether in one place. "],["impactfactor.html", "Chapter 6 What is the Impact Factor of a journal, and why is it so important? 6.1 From a simple score to a way of life 6.2 5 Year Impact Factor 6.3 What can you do if you publish a journal with high IF? 6.4 Why is it so important? 6.5 Editors try to increase IF 6.6 Push back against IF", " Chapter 6 What is the Impact Factor of a journal, and why is it so important? The impact factor of a journal relates to the number of times each publication from the journal gets cited in the two years preceding the date of the Impact Factor (IF) (Equation (6.1)). Thus, if you are thinking of publishing in a journal that has an IF of 1 you might expect that In the two years following the publication of your article you may get one citation. But this is not necessarily true for your paper. As discussed elsewhere you might be very good at publicising your work and have it extensively cited. One or two extensively cited papers might even change the impact factor of the journal without too many publications per year. As IFs are calculated on average for all papers published in that journal. If on the other hand you are thinking of publishing your article in a journal that has an IF of 5, you might expect that your article will be cited 5 times more than if you published in the first journal. Its a relatively simple calculation as seen in equation (6.1): \\[\\begin{equation*} \\frac{Sigma citations in journal X for year Y}{(Number of publications in journal X for year Y-1) + (Number of publications in journal X for year Y-2)}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x) \\tag{6.1} \\end{equation*}\\] Because all citations for year Y are needed before the IF can be calculated for each journal, IF for the preceding two years is typically not released until June of Y+1. Impact Factor is calculated by Thomson Reuters based on their Science Citation Index now called the Web of Science. This means that if your journal is not even listed in the Web of Science then it will not have any Impact Factor. The Web of Science is continually policing the quality of the journals but it includes and this means from time to time channels are excluded. This tends to happen at the lower end of the Impact Factor scale. But recently it happened to some very well known journals and there was a big stink. You can read more about this here. Note that there is a large conflict of interest here. A publisher, Thomson Reuters, owns the Web of Science and thats the means to decide whether or not a publication can get an Impact Factor. Is it more likely that journals published by Thomson Reuters will be included in the Web of Science? Previously the Science Citation Index was a not-for-profit organisation. Now the organisation that is used by many of our employers in their means of evaluating our effectiveness is owned by a private company. This is certainly cause for concern. There is a group of people who are trying to replace Impact Factor with a group of other metrics, so perhaps by the time you read this Impact Factor will no longer be relevant. If youre interested read more here. Do remember that there are a number of other citation indices including Scopus and Google Scholar. Google Scholar doesnt currently calculate the Impact Factor for all journals, only the top 100. 6.1 From a simple score to a way of life Like nuclear energy, the impact factor has become a mixed blessing. Eugene Garfield (1999) When IF was originally devised by Eugene Garfield in 1955, it wasnt supposed to govern the lives of academics, it was simply intended to be a way of deciding which journals to include in the Science Citation Index (Garfield 1999). I then became useful for librarians to help them decide which journals to keep and which to ditch under ever constrained budgets (caused by publishers ever increasing prices). But along the way, this very simple index is now considered by many people to be a measure of quality, prestige and even academic success (Garfield 1999). Many people have highlighted how wrong these beliefs are, but the growing trouble is that not only have many academics been misled, but so have administrators responsible for hiring and promotions. In a paper by McKiernan et al (2019), they found that this metric features in the guidelines of many university panels responsible for the fate of academics jobs and therefore lives. Worryingly, many of these institutions dont actually talk about what IF measures. Instead they equate it with values and qualities that it certainly does not represent. Thus you may find that your career is influenced by a simple metric that almost all who use it dont actually understand what it means. The undue influence on lives of scientists that IF has led directly to the San Francisco Declaration on Research Assessment (known as DORA) in which many institutions and publishers signed up to. You should read this very simple declaration and find out whether your institution is a signatory. The Impact Factor now dominates many aspects of life for Early Career Researchers, where the pay-off for a high impact publication might make the difference between having a job or leaving science altogether. The pressure is so high that it leads to misconduct and fraud. 6.2 5 Year Impact Factor Many journals report their 5 Year Impact Factor in addition the the standard 2 year timeframe (as seen in equation (6.1)). This is because many disciplines, such as biological sciences, dont have maximum impact of articles within the first 2 years of publication as do subjects like medicine and physics. Although the 5 Year Impact Factor might be much more appropriate, most people do ignore this statistic. Although this statistic might be more appropriate, because of the bad ways in which people have used impact factor, it is probably better to push back against this metric as you should others. 6.3 What can you do if you publish a journal with high IF? Very high ranking journals for Impact Factor are publications like Cell, Nature, Science and PNAS. This is because these publications are read by a very great number of people, and so are widely cited. Articles that get published in them receive a lot of attention from the press and media. This results in the prestige that a hiring institution might be looking for. If your academics publish in this journal, your institution may well receive lots of positive publicity. In some countries, notably China, there may be a cash incentive towards publishing in a journal with a high IF (Quan, Chen, and Shu 2017). One frightening trend that we are seeing in biological sciences is that the higher the Impact Factor the more the journal will charge you to publish in it. At the time of writing in November 2020 nature has just announced that they will charge $9500 to publish in the highly-ranked journal (see part 2). This is more money than it cost to publish in any other journal at the moment. 6.4 Why is it so important? Academics are measured by= their productivity but also about the quality of their output. Because there are so many different academic disciplines the bean pushers who administer us need some way of ranking academics against each other. This is why they use the Impact Factor of the journals that the academic publishing in order to determine the quality of their output. Even though there are other metrics of the actual quality of an academic, most administrators continue to cling to IF and their beliefs of what it stands for (see blog post here). Some countries reward their academics if they publish in high ranking journals. This can result in a salary bonus. It may also help with promotion, getting tenure or even just getting an interview for a job. If youre going to publish and you want a career in academia then you need to be aware of Impact Factors and what they mean to different stakeholders. Many people will complain that their particular sub-discipline has a range of very low ranking journals with low impact factors. Others complain that journals with high impact factors tend to be edited by an old boys club that facilitates the members. In some cases like PNAS this is certainly true. 6.5 Editors try to increase IF Its important to remember that editors care about Impact Factor (see J. P. Ioannidis and Thombs 2019). There are several reasons for this. Firstly, as the editor the impact factor of the journal can be used (by the publisher or society) as a simple measure of how well the editor is doing. Secondly, the higher the impact factor of the journal, the better quality of submissions of manuscripts to publish. Being the editor of a journal with a low (or no) impact factor can result in a lot of mediocre manuscripts that are being submitted. Poor manuscripts take up much more time than good ones: more rounds of review, more disagreements among reviewers and more time spent making editorial decisions. Thus, by increasing the IF of the journal that you edit, you are likely to increase both the number of submissions (allowing you to reject more poor ones) and retain better ones. All this means that if they think your paper will not garner the same or more citations in two years as the current Impact Factor they are likely to reject it often without even sending it out to review. Editors also have been known to manipulate impact factors and there are a number of established ways of doing this (see Metze 2010; Martin 2016): Ask authors to cite publications from your journal published within the last 2 years. Ask reviewers to suggest publications from your journal published within the last two years to authors on which their review is conducted. Encourage submission papers from laboratories with high output and citation rates Reject papers that are likely to have no citations. This effectively reduces the size of the denominator in the above equation Publishing issues in January means they have a maximum period of the year to get cited. This is now being inflated to having issues published online well ahead of the January date all the time gathering citations. Encourage review articles Editorials that cite every paper in the journal. This tactic is frequently used in special issues. Just like any metric, Impact Factor is liable for abuse. You need to be aware of how IF is used and abused by many people in the academic community. You also need to be aware of what the rewards are for these individuals. Our problem with Impact Factor is not really the way in which it is manipulated by individuals to achieve their own ends. Instead, we should be worried about the way in which it leads the scientific community towards bad science and dishonesty. Moreover, that this happens not to our benefit, but for the benefit of the publishing industry who uses this metric (that they now own and police themselves) to extort money from taxpayers earmarked for research into their own pockets (more on this in Part IV). 6.5.1 Negotiating your IF As the number of citations from your published content is divided by the number of papers, one way of improving the IF of a journal is to reduce the number of papers that are counted towards the denominator in the calculation made by the citations database. It has been known for some time that those journals with the highest IF negotiate the removal of all of their editorial and news content from their denominators, making the number of publications much smaller and hence the IF larger (Adam 2002; Garfield 1999). On the other hand, if any of these news or commentaries get citations, these are included in the addition to the numerator. Thus our favourite high impact journals, Nature and Science, can publish very citable news at the front of their magazine, but negotiate with the commerically minded Thomson Reuters about exactly which of their content counts towards their IF (Brembs, Button, and Munafò 2013). Later, we will see evidence of the financial leverage that these negotiations can reward the top tier journals (see Part IV). 6.6 Push back against IF One very simple way that you can push back is to calculate IF scores for your papers and show how they relate to the IF of the journal that you publish in. In this way you are simply comparing your actual citations in the 2 years after your paper is published with the mean for the journal. There is a good chance that you generally get more citations than the mean for the journal, and with some statistics you can convincingly show that your citations are significantly higher than the IF. For this to be true, you might need to help your work get cited. Thats the subject of another chapter. "],["authors.html", "Chapter 7 When should you be an author? 7.1 Ghost authorship 7.2 Honorary authorship 7.3 A need for transparency - DORA 7.4 Who should be an author? 7.5 Rescognito, ORCID and the CRediT Contributor Checklist", " Chapter 7 When should you be an author? Who should be an author is being increasingly regulated because of widespread abuse, including honorary authors or excluding ghost authors. Back in the day there were people that used to add fictitious characters to their author line (including their dogs!) as a joke. These days we have such a thing as ORCID that attempts to register all authors, turning them into numbers (see part 3). One of the benefits with the ORCID system is that you can have your name the way you want to have it, even if it is not a standard western style surname (Goyes Vallejos 2021). The need for all this regulation is because publications have turned into a kind of currency for academics. And when there is currency involved, abuse quickly results in human systems followed by the need for regulation. Hence, one of the results of going transparent is that we all become registered numbers, and our dogs wont get authorship anymore. Perhaps this is just the loss of an age of innocence (at least on the part of our dogs!). A lot of the literature on the subject of ghost and honorary authorships has come from the medical profession, perhaps as this profession is prone to ghost authorship via the pharmaceutical industry (Matheson 2016), and honorary authorship from heads of large research groups (see Rennie and Flanagin 1994). 7.1 Ghost authorship Ghost authorship is when people are not included in the author line although they have not contributed to the study (Matheson 2016). Note that ghostwriting outside science is usually when someone who has the talent to write, writes the ideas of someone who doesnt for a fee, and in return the latter takes the author line. This may well happen in science (especially when you consider the world of translation companies), but this is not really the meaning that we are discussing here. There are many potential sources for ghost authors, including past students whose thesis work is taken by unscrupulous advisors, and published without their inclusion. More commonly, I believe, is that those who contribute substantially are not included as authors for political reasons (they have fallen out with those who are the authors), or they are simply forgotten because they have moved away from the institution. Ghost authorship is a land of the disenfranchised. This is becoming increasingly prevalent in the world of contributions of data, which is also freely accessible. Some authors will take and use the data, only referencing the doi for where they obtained it. Others will include the original people who created the data as authors because they value their continued insight and input. Where the situation becomes very messy is when some people are included and others are excluded. This is my experience where a paper simultaneously contains both honorary and ghost authors. A study by Wisler et al (2011) found ghost authorship in medical publications at 7.9%, although Id argue that their methods (contacting corresponding authors) mean that the real levels are likely much higher. While the world of inclusion (see below) has a warm and friendly glow about it (everyone appears to benefit), exclusion is characterised by lack of information contact and reasoning. If you are excluded from a publication even when you have contributed, you will not be getting an email from the authors detailing their decision. Youll be lucky if they even send you a copy once its published. Meanwhile, those who are included will remain in the loop. 7.2 Honorary authorship Honorary authorship happens when people who have not contributed meaningfully to a study are included in the author line. If publications are the currency of science then you can see how being added to other peoples publications increases your apparent productivity. While this might sound surprising to you, you should know that does happen and might be more common than you think. The Wisler et al (2011) study found that honorary authorship was as high as 17.6% in medical publications. Its worth noting that this may vary between disciplines as there are various traditions in some disciplines whereby the head of a large team may always be included as an author of a paper that emerges from the team, whether or not they were involved. In biological sciences, teams tend to be quite small with a single or rarely multiple Principal Investigators (PIs). This means that your PI will likely be directly involved with your research and therefore also an author. Imagine a very large team with multiple PIs working under a head who insists that they are an author on every publication. This could add up to hundreds of publications in a year (e.g. Yuri T. Struchkov is currently credited with &gt;1600 publications on Scopus), and such prolific authorship has been questioned (e.g. Rennie and Flanagin 1994). However, there appear to be very different levels of what could be considered credible and what incredible (e.g. 25 papers a year: E. Wager, Singhvi, and Kleinert 2015), and I respond to this, and the general question of how prolific authors are becoming, below. In the biological sciences, the area of molecular phylogenetics has traditionally honoured those who collect tissue samples with authorship on the resulting phylogenies when published. As I mentioned above, this is not always equal and has also been used to politically honour or ghost. The reason given for honouring contributors in this way is that the studies could not have been done without the tissues. On the other side, some people have long lists of publications based on tissue donations and very little else. 7.3 A need for transparency - DORA Given the problems with both ghost and honorary authorship, there is clearly a need for transparency about who the authors are and what they have actually contributed. This was recognised by the Declaration of Research Assessment, which has a growing number of signatories as well as some solid ideas on the way forward in assessment of research and researchers. In particular, DORA is against the use of Impact Factors (see below) and other journal based metrics, and instead assesses the research on its own merits. DORA also encourages everyone to embrace the opportunities offered by online publication, including colour figures and unencumbered word lengths. DORA also encourages specific information to be published about individual author contributions. In short, DORA stands for transparency and it would be worth you looking at their statement and finding out whether your institution is a signatory. There are no universal rules about what or how much you should contribute in order to become an author of a scientific paper. However, some journals are independently initiating their own standards, and this might become mainstream. Thus, it is worth discussing the criteria for being an author with your advisor preferably in a lab meeting so that everyone knows where they stand. theres a chance that your thesis chapters (when they are published) will be authored only by you and your advisor. But this can become much more complicated if you collaborate with more people in order to do the work. In turn you may (or may not) be invited onto their papers as an author. Confused? Then lets look at this more closely. 7.4 Who should be an author? There is an increasing number of journals that now give clear instructions on who should author a paper, and these have been formalised by the International Committee of Medical Journal Editors (ICMJE), and this has been rapidly evolving (Baskin and Gross 2011). For some time, I have explained to my lab members that authors need to participate in at least three of the following five points before they can be considered for inclusion in the author line. initial conceptualisation for the work (hypothesis and/or question) raising of money (which often involves writing and submitting several research proposals) conducting the field work or experiment (the hard slog that many people will recognise) analysing the data (often much more difficult than anyone realises) writing it up (see lots of chapters of this book about the many requirements of writing) This was a relatively simple scheme in which authors needed to be able to tick 3 of 5 boxes to be included as an author on a publication. At first glance it might look fine, but as ever the devil is in the detail. For example, this scheme does not stipulate how much one needs to contribute at each level. For example, is it enough to simply ok the final manuscript in order to tick the box that states that you helped write it up? Could you have been present in the room when the conception for the work was thought up, and present at the field site when samples were collected? To help with these issues, some people have proposed a points scheme so that each person is allocated a number of points from a total for each level of the process, and then at the end points are totalled and a known threshold gives each person the right to be mentioned in the acknowledgements or be added to the authorship line. The idea for a points scheme comes from the psychology lab of Kosslyn (see here). It is not entirely appropriate for biological sciences, and so it cant be adopted without modification. 7.5 Rescognito, ORCID and the CRediT Contributor Checklist A new initiative under the name Rescognito has teamed up with ORCID to formally list the ways in which researchers are recognised per publication. Rescognito maintains the Data Availability Checklist, Contributor CRediT Checklist and Funder Information Checklist. The CRediT Contributor Checklist contains 14 fields. Visit their website to learn more about these fields and to see whether or not your role qualifies. see part 3 This field appears to be moving quickly with new initiatives and registries opening up quickly. We will see how many journals adopt these and what becomes of existing initiatives in the future. 7.5.1 If you suspect irregularities in authorship The Committee on Publication Ethics (COPE) has published a useful flowchart to guide researchers on how to recognise potential authorship problems (COPE 2018b). Or more specifically, how to recognise ghost, guest, or gift authorship in a submitted manuscript (E. Wager 2006b). "],["citations.html", "Chapter 8 Citations and how to get them 8.1 What are your citation metrics? 8.2 How to increase your citations 8.3 Well cited articles are likely to be cited more", " Chapter 8 Citations and how to get them Citations matter as they reflect the number of people who found your research useful. Getting your research cited is not always straightforward. We have already mentioned here about publishing your research in journals with higher Impact Factors. This will likely help you get your research read. But there are lots of other tactics and here I have produced a list although I imagine it is not exhaustive. 8.1 What are your citation metrics? A number of different databases compile metrics which you can access. In addition, they compile a bunch of extra performance metrics that you would have to pay to access, and in general these are available to a select number of recruitment staff at your institution. Here I will talk about Google Scholar, Scopus and the Web of Science (see an article on their differences here). In summary, for Biological Sciences, the Web of Science and scopus are likely to give you very similar statistics. Scopus favours social-sciences a little more, so if your subject area does cross-over then you might see some extra cites there. Google Scholar is going to give you the highest metrics, but it doesnt mean that they are particularly false (although this is certainly the not the best curated database). The joy of Google Scholar is that it is much more cosmopolitan on the journals and theses that it includes. So it actually gives you a better idea of who is using your research. It will also pick up grey literature and predatory publishers, so you should interpret the outputs with care. Each of these databases offers you the opportunity of curating your own author profile that (in the case of Scopus and WoS) will link with your ORCID, and (in the case of WoS) link with your Publons account. Your institution may want you to actively curate your profile to help them with assessing your institutions metrics. It is surprising how bad these are when left to the bots, especially if you have your name recorded in more than one way.I also think that its worthwhile creating and curating a Google Scholar profile. As an editor, this is one of the easiest ways of looking up an author or potential reviewer. For anyone that uses Google Scholar, your name will then be underlined, and they can quickly find your other published works. Google Scholar also indexes preprints, which may be a boon to you as an Early Career Researcher. Because all of these indices are cumulative, you can expect that anyone who started their career before you will have higher numbers. It is also worth being aware that some fields get higher citations because there are more people working in them, and therefore more articles being published. 8.1.1 Total Citations Your total number of citations is simply the total number of times that anyone has cited one of your works within the respective database. Note that, the cited article itself doesnt have to appear in the database in order to be counted in total cites, but (clearly) the article that cites it must. For this reason, you may well have a different number. 8.1.2 H-index Very simply, the H-index is the ranked count of the number of your publications that have received at least the same number of citations (Hirsch 2005). The easiest way to calculate your H-index is to have a list of all your papers and their citations in a list, ranked from the highest to lowest cited (see Table 8.1). Counting down from the highest cited paper, you stop when the number of citations reaches the same as the numbered citation in the list. For example, your H-index will be 5 if you have authored 5 or more publications with 5 of them having received 5 citations or more. If 6 have received 5 citations, youll still only have an H-index of 5, because for the H-index to grow to 6, the top 6 articles will need to be cited 6 times or more. TABLE 8.1: A table of fictional papers ranked by their citations to show how H-index is calculated. In this Table, the H-index is 5 as the 5th paper has 5 or more citations, and no other lower ranked paper has been cited &gt;5 times. Note that the H-index is not 6 even though the 5th paper has 6 citations. Once the paper currently ranked 6 receives one more citation, the H-index of this author will rise to 6. Rank Title Cited By Year 1 A review of most important findings 48 2017 2 The first paper I presented at a conference 19 2017 3 Another significant finding 8 2018 4 First Open Access paper with snappy title 8 2020 5 This paper spent a long time online first 6 2019 6 Another review receiving some attention 5 2020 7 A paper that shows important findings 2 2020 8 Obscure note that I managed to self-cite 1 2018 9 The only citation is my own 1 2019 10 Hot off the press 0 2021  Total Citations *98  Your H-index will grow very quickly as you publish articles from your thesis, but the growth slows as the H-index grows as it requires more citations of particular papers (of your top cited papers). Growing an H-index is therefore very difficult, and its probably one of the hardest of these metrics to manipulate. Because the H-index is cumulative, people with very large H-indices (&gt;100) are usually very senior academics with very good networks, and low R numbers. Note that while the H-index is usually calculated for individuals, but groups of people can also have an H-index, such as a department, a school, faculty or even university. Indeed, you can calculate an H-index for any set of articles using the citations that they receive. 8.1.3 Normalisaing the H-index and other citation metrics The H-index (and other indices) are sometimes normalised for field of study (fixed - dynamic; broad - narrow), types of citing documents and year of publication (see J. P. A. Ioannidis, Boyack, and Wouters 2016). You can expect to see some of these field normalisations, for example by Dimensions (see Figure 8.1 who provide you with, Total citations (as the name implies), Recent citations (citations within the last 2 years), Field citation ratio (comparing the article to ones of a similar age in in a similar field), and the Relative citation ratio (relative to 1.0, this gives you an idea of how well cited the article is compared to others in its area of research). As an Early Career Researcher, you may feel that your H-index is not particularly impressive (Table 8.1), in which case, you may want to consider some of these normalised metrics if they show your articles in a much more favourable light. Normalising citation metrics. Some databases will provide you with normalised values for citations, like the one shown here by Dimensions for a paper cited 45 times, and 8% of these citations are from the past two years (normalised for time since published). The Field Citation Ratio (FCR) of this paper is 4.07 times more citations, when compared to other papers in the field. The Relative Citation Ratio (RCR) compares this paper to other NIH funded publications in the same area of research and year, where they will be the same as the mean (at 1.0), more or (in this case) less at 0.57.\" width=\"50%\" /> FIGURE 8.1: Normalising citation metrics. Some databases will provide you with normalised values for citations, like the one shown here by Dimensions for a paper cited 45 times, and 8% of these citations are from the past two years (normalised for time since published). The Field Citation Ratio (FCR) of this paper is 4.07 times more citations, when compared to other papers in the field. The Relative Citation Ratio (RCR) compares this paper to other NIH funded publications in the same area of research and year, where they will be the same as the mean (at 1.0), more or (in this case) less at 0.57. 8.1.4 G-index The G-index is similar to the H-index, but places more emphasis on the actual number of citations in your top cited articles (Egghe 2006). To calculate this, you will need to organise your publications by the number of times that they have been cited. For ease of explanation, start with your H-index, and add up citations to all of the preceding articles (1st, 2nd, 3rd, 4th &amp; 5th). In order for your G-index to be 5, all citations up to 5 will need to be more than or equal to 25 (52). For your G-index to increase to 6, the sum of all citations to your first 6 papers will need to be equal or greater than 36 (62). Because the G-index uses all citations in your top cited articles, not simply the minimum used to obtain the H-index, your G-index should always (at least) be equal to your H-index and will often be higher. This is because of the phenomenon that articles that get cited more, continue by getting increasing numbers of citations (see below) Therefore, you may favour using the G-index if your top papers are particularly well cited. 8.1.5 R-index Your R-index is a measure of your active network (J. P. A. Ioannidis 2008). It is rather like the H-index it that it records the count of the number of people that youve collaborated with on a number of papers. But these need to be the same people. This is then divided by your total number of papers. For example, if your thesis produced 5 papers with the same 5 authors and this is your total number of papers, your R-index will be 1. However, if two of the papers lacked one of the people, your R-index will drop to 1.66. If you dont work with those 5 other people again, then your R-index will grow continuously until you have another productive network. see Part I for a fuller explanation of the R-index and the importance of networks. 8.1.6 a-index The a-index is calculated from the total number of citations divided by H2 (Sidiropoulos, Katsaros, and Manolopoulos 2007). In the example given in Table 8.1, Total citations is: 97. H2 is 25 (52), and so the a-index is 97/25 = 3.88. This index gives a measure of how top-heavy someones citations are. The a-index gets larger as the highest ranked papers receive a disproportionate amount of citations. This is known as the Matthew Effect, and this is a general feature of a lot of researchers citation ranks. 8.1.7 i10-index Your i10 index represents the number of articles that you have written which have been cited 10 times or more in that database. The i10 is often expressed over a time frame (for example the last 5 years) which may well exclude papers that you write that have an immediate but not a lasting impact. 8.1.8 Other metrics There are more metrics for authors behind paywalls, but there are also metrics on social-media sites such as ResearchGates RG score. The way that ResearchGate calculates its RG score is rather opaque and is not simply done on publication metrics, but on the way that you interact with your ResearchGate community. Similarly, many publishers will grant you metrics that will be boosted by the number of times that you publish with them. There are also Altmetrics handed out as a means of showing the alternative impact for articles that youve written. These are explained in Part III. 8.2 How to increase your citations Increasing your total number of citations is likely to impact positively on all of your metrics, but this is not necessarily true, and hence why you may be assessed on more than one metric. 8.2.1 Media release Some journals will want you to write a media release that they may use to promote your paper. You can also proactively write a press release and send it to your Media office at your institution. Writing a release for the media is very different from most of the writing that weve talked about so far and you can find a guide in a chapter below. 8.2.2 Social media Social media is another way of getting your article to the attention of more people. Twitter has been adopted by many scientists and tweeting out an article that gets retweeted by the right people can get you tens or even hundreds of thousands of views. This is likely to be far in excess of anything your article will get by passively sitting on the journal website. 8.2.3 Popular articles Writing popular articles is a good way to ensure that your paper gets some media attention. There are outlets like The Conversation that specialise in publishing popular articles written by academics. But you might also find that academic societies that you belong to have newsletters that you can contribute a popular article to about your paper. As long as the circulation of these newsletters is big it should enhance the numbers of people that eventually read about your work. 8.2.4 Self-citations Self citation is when you cite a paper that you or one of your co-authors have written or co-authored. This is probably one of the oldest and most widely practised ways of increasing citations to your articles. It is generally frowned upon to have gratuitous self citations. However, it is also true that you are more than likely to cite your own work because you have probably published in the same area previously. By the end of your PhD you will already be citing publications that you produced at the beginning. There is evidence to suggest that the proportion of self citations will change in different disciplines, and that they will increase with increasing numbers of collaborative co-authors (Davarpanah and Amel 2009). How do you make sure that their citations are not gratuitous? Simply by only citing a work when you need to. Note that many citation indices will provide your citation scores both with and without self citations. There are some metrics that suggest within what bounds self-citations are reasonable. A study of Norwegian scientific papers found that the mean rate of self citations was 36% (Aksnes 2003), which seems very high. 8.2.5 Organising symposia and having special issues Having your research published in a special issue is a great way of getting citations. This is because special issues have research on a theme and so many people will be drawn to the issue and are then more likely to see your work. This includes other people who participate in the special issue and are de facto already interested in this line of research. Special issues are often edited by people who have an interest in pulling together this kind of research. They may encourage other authors to cross cite articles in the special issue, and may write an editorial that includes citations to yours and other papers. Of course the best position to be in is when you are one of the organising members. Your name will be associated with the special issue as well as your contribution. This means that when the special issue is published, each of the papers in it will already have citations leading to a positive Matthew Effect from day one of publication. Probably the easiest way of pulling together a special issue is to organise a symposium at a conference and ask those participating to contribute to the special issue. If this is done long enough in advance and you are good at organising then it can work very well. Talk to your adviser about the possibility of their help in organising a symposium. 8.2.6 Traditional Media To get your work cited you need to get people reading it. As scientists read the traditional media it can be a way of bringing your work to their attention, and result in additional citations. There are other benefits of having your work highlighted by the traditional media then you should always make sure that you get a plug in for your institution and any prominent funders. There are now additional metrics (e.g. Altmetrics) that track traditional and social media and in the future you might be able to use these to your advantage in getting a job, a promotion or tenure. 8.2.7 Not so legitimate ways of increasing citations As well as the legitimate ways of increasing citations and visibility of your work that Ive listed above there are other illegitimate ways that I have heard about. I have heard of certain laboratories that have quid-pro-quo arrangements where they agree to cite each others publications (see Ritchie 2020). Another way of increasing citations might be to have a co-author that is very well known. Certainly having a co-author that is very well known is likely to increase your citations but only if they actually do something to contribute to the work. See comments about ghost authorship above. Journals have also been known to manipulate citations in order to increase their Impact Factors and therefore their perceived level of standing. A group of physics journals from Romania were found to have clearly manipulated self-citations to increase their own impact factors (see Heneberg 2016). There can also be a level of coercive pressure from journal editors to cite papers from their journals published within the 2 year citation window (Chorus and Waltman 2016). Such practices are now systematically analysed by the larger literature databases, and clear levels of Impact Factor manipulation result in losing the journal listing in the database (see part 2). 8.3 Well cited articles are likely to be cited more Articles that already have a lot of citations are more likely to pick up extra citations than the ones that have very few. This phenomenon, sometimes referred to as the Matthew Effect (see Teixeira da Silva 2021), is exaggerated by search engines like Google Scholar that order the results of searches by the number of times an article is cited. Like people looking for a website, academics looking for a paper are more likely to choose one on the first page of Google Scholar than to keep searching through Google Scholar until they find your study. In effect, this means that those that already have large research groups and that can generate initial citations, will get more citations and increase their own standing. Or, in other words, those that are already in a commanding position will automatically generate more (Casadevall and Fang 2012) - the winner takes it all. As you read through papers in your specialist area you will notice but there are some papers that seem to get cited over and over again as standard examples of a particular phenomenon. These are often some of the first examples published and also being published in high-ranking journals. If you are the 20th person to have shown a particular phenomenon then it is unlikely that your paper is going to end up being cited the most. There have been investigations into what makes certain papers more likely to be cited further. One of the factors that appears to be significant is the small-study effect - low precision studies that produce large effect sizes, either spuriously (i.e. a Type I error: (Forstmeier, Wagenmakers, and Parker 2017)), or genuinely (Fanelli, Costas, and Ioannidis 2017). "],["advisorless.html", "Chapter 9 Advisor-less in the academic world - growing your network 9.1 What to look for in a mentor? 9.2 Questions to put to your mentor? 9.3 The importance of networks in your academic career", " Chapter 9 Advisor-less in the academic world - growing your network During your PhD you will have had an advisor who would have been central to many of the decisions that you made. Dont give up on that relationship, it is something that you have at the heart of your network. Therefore it is worth maintaining in the best condition possible as this is someone that you will need to go back to (probably lots of times) for references and other professional help. In short, always keep your advisor sweet. Having said this, as an early career researcher, you are now advisor-less, yet it is likely that you will still need advice from someone more experienced. Hopefully, there is always your advisor, but the chance is that you may well have changed institutions, and so they may not be so close or easy to contact. This is a good reason for expanding your network by looking for a mentor to your role as an early career researcher. Increasing numbers of institutions are now recognising that early career researchers need mentors to advise them about how to move forwards within their academic field. 9.1 What to look for in a mentor? The first thing to look for in a mentor is someone that you feel you are able to talk to easily. As you will see, there are a wide range of topics to discuss in terms of building your career, and you will need to find someone that you feel you can talk to about nearly everything safely and without fear that it might be used against you. The mentor should feel happy to talk and spend time with you. They should be someone that is genuine in their desire to help you and your career. You wont have a fruitful relationship with someone that doesnt really like you, or doesnt want to spend time talking to you. Next, your mentor should be someone who is already well established within an academic network that you want to (or already are) a member of. You will need to have common ground to talk about, and getting their advice on building your network will necessitate talking about how to manage others in the network. The personal touch is nice to have, so if you can find a mentor who has an office in the same building, or on the same campus, then its great to be able to meet up and chat. However, your mentor doesnt have to be in the same institution, or even in the same country. In these days of post-COVID communication we are all a lot happier hooking up to meetings online. If you still have choices, my suggestion would be to look for someone that you share non-academic interests with. For example, you may both enjoy playing squash together, attending opera or scuba-diving. Meeting outside academia will make your mentor-mentee chats easier for both of you. Otherwise, try not to make your meetings with your mentor a burden on their work time. All academics are busy and core-working hours are hard to come by. Instead you could suggest taking your mentor out for a coffee or a sandwich in which to have your chat. Note that a mentor doesnt have to be someone that is particularly senior, although they should be well connected. Having said this, they are likely to be at a more advanced career stage than you. 9.2 Questions to put to your mentor? Your mentors time is valuable, so always have an agenda when you go to talk to them. Have ideas that you want to pitch and get feedback from. Have some way of making notes about what they say, especially if you meet over a beer. You dont want to have to go back and ask them again for the same advice. Be prepared to get the answer that they give. This seems an odd thing to say, but they may not always like your idea, and you should be prepared to listen to their advice whatever it is, not only when it agrees with your own ideas. Typical things to discuss with your mentor are: Where to publish What meeting to attend How to extend your network Whether (or not) to write a reply or commentary on another groups work Whether to respond to a call for grant applications Whether to apply for another job You may also want to share some of the more exciting aspects of your work, your findings and how you interpret them. Try to keep away from moaning about other academics, the amount of administration you have, teaching burdens, etc. Make your discussions as positive as possible so that your mentor is more likely to want to maintain and grow your relationship. 9.3 The importance of networks in your academic career There is clear evidence that researchers with good networks collaborate more, publish more and are better cited (Parish, Boyack, and Ioannidis 2018). Your mentor can be one way to increase your academic network. Perhaps more importantly, they can be a guide to help you through the network that you are both involved with. There is a good chance that you are already in a network where your advisor, and perhaps some members of your thesis committee sit at the hub of an extended network that you have had partial exposure to during the course of your studies. If you havent realised already, these networks are of profound importance in every step of your academic career. Benefits of a good network include: - increased citations for your work - better chances that your work will be edited or reviewed by a member or an associate of your network, resulting in a higher chance of publication or a grant application accepted - increased potential to be nominated for an award - increased potential to be invited to give talks at conferences - invitation to apply for positions and jobs in the labs of partners at institutions in the network If you are already in a network, you should be thinking of ways in which you can get more from your network now that you are an early career researcher. If, on the other hand, you are not in a good (sizeable and supportive) network, you should be thinking about how to join an existing network or how to form a network around yourself and your work. In many cases, managing your network is about providing opportunities for yourself and others in your network. There are many ways in which you can do this, but you should be prepared to put in a lot of work from your own side. Potential initiatives include: writing a grant application that involves others in your network leading a piece of written work that includes others in the network a review a commentary on another article (not from your network!) a viewpoint or position article on an emerging topic organising a symposium aimed a central or emerging question within your network organising a special issue of a journal (potentially as a result of the symposium) Your chosen mentor is the best person to discuss how to make waves in your network. Remember that relationships have already been forged in networks and you should never try to destabilise these. Instead, you should aim to become another node of the network by growing your own usefulness as a positive force for new and interesting initiatives that others will want to join. Because you are new, dont expect to be included in every initiative. If you feel that you are being left out of other initiatives that youve heard about unnecessarily, ask your mentor whether or not it is appropriate for you to bring this up. Always bridge and build relationships. As you should have become aware by now, there are many potential ways of becoming involved in combative elements of academic life. Your own sub-discipline will likely have groups of people that write commentaries about the work of other groups. Networks are powerful places to be, but they can also become destructive when another network opposes a position. I have seen this type of behaviour happen within and around my own limited subdisciplines. One group will publish a major finding in Nature or Science and a week or two later, the other group will publish a commentary pointing out what are (to them) flaws in the first groups publication. I always have a sneaking admiration for those individuals that appear to swim between these groups, always maintaining good relationships with both sides. Theirs is really an interesting, but perhaps precarious, position. If you feel that you dont have any network, then I think that you should reassess your position. You likely do have people that you talk to and interact with that are already part of a network, but your question is how to increase the size, and potentially scope, of your network. One point that you will will see in Part IV is that everyone will have their own path through their career. There really is no one size fits all way. Growing your network is similar in that each academic will do this in ways that are unique to them. 9.3.1 Calculating the size of your network A simple metric for your network is the number of co-authors that you have. Clearly, as you increase the number of people that you work (and hopefully) publish with, you will have a bigger, better functioning network. However, scientometricians have their own ways of interpreting and mapping networks (see Figure 9.1). FIGURE 9.1: An author network for the Web of Science search for Invasive fish AND South Africa. In this author network you will see my friend and colleague, the late Olaf Weyl, who is at the centre of a large group of people who worked on invasive fish in South Africa. Olafs wasnt the only research group, but certainly the most influential and joined up. Olafs collaborations were extensive. Drawn with VOSviewer (Eck and Waltman 2010). If you arent sure about whos in what networks within your own researcher area, you can use keywords appropriate to download literature within the area that you work, and plot (using VOSviewer) a similar author and co-author network. This can be very revealing, and while you should be well aware of the big names in your area, some of the people that span areas and sub-subdisciplines might well be worth seeking out. Another method for determining the size of your network, or those of potential collaborators around you, is to calculate your R value (J. P. A. Ioannidis 2008). R is made up of two figures, I1 which is the number of authors that appear in at least I1 papers, divided by Np which is the number of papers that the author has published. I1 is a little like the H-index in that it increases each time you a person in your network. For example, to have a I1 of 4, you need at least 4 publications in which you and the same 4 other authors occur. Parish et al (2018) show that as I1 grows, so the value of R decreases and researchers become most productive as R approaches 1. Once you start to calculate your own value of R, you will appreciate that not only are large networks important, but that it is useful to start these networks early and maintain working with an every increasing group throughout your career. 9.3.2 Using social-networks to grow your nework I think that the ways in which you can grow your network have never been so great. Social networking is a massive way to reach other researchers and you dont have to wait for a meeting to do this. The #academictwitter groups are already very large and established. Investing time in getting connected is worthwhile, especially when you can meet up in person through conferences and symposia. I dont want to make out that Twitter, and (no doubt) other social networking is easy, but it is a good way of hooking up with a whole lot of other people without having to leave your desk. You can pitch ideas, and get collaborations moving in your area. Once you have it working for you, it is very empowering. If social networking is your thing, then Id suggest trying to find yourself a social networking mentor - someone that already has a good following and can guide you through the various nuances of rules that happen on these platforms. "],["preprints2.html", "Chapter 10 Preprints 10.1 What are Preprints? 10.2 Who posts preprints on bioRxiv? 10.3 Why might you want to post a preprint? 10.4 Upload newer versions 10.5 Will you have to post a preprint? 10.6 If we all post preprints, do we really need peer review? 10.7 Could these comments pages really replace peer review? 10.8 When should evaluation end? 10.9 Are preprints published? 10.10 But if they are fundamentally flawed, shouldnt everyone be able to spot it? 10.11 Preprints are here to stay 10.12 The exciting new world of Overlay Journals 10.13 Peeriodicals - another twist on the idea of an Overlay Journal", " Chapter 10 Preprints 10.1 What are Preprints? So far in this book I have explained about the process of peer review how important this is and why its the gold standard in science. Preprints came to us from the world of physics. An academic world that is moving so quickly that many inside it dont want to wait for peer review before making their work public. They date back to 1991, and were the brainchild of Paul Ginsparg with his preprint server, arXiv. Today arXiv hosts nearly 2 million articles in 8 subject areas: Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering and Systems Science and Economics. In addition to making your work open access, it allows anyone to read and review it. This is unlike the traditional publishing model where editors invite selected reviewers. Many consider preprints as a kind of open peer-review system. The life science community needs to return to a culture of evaluating scientific merit from reading manuscripts, rather than basing judgment on where papers are published. Vale (2015) In biological sciences the most prominent preprint server is called bioRxiv. 10.2 Who posts preprints on bioRxiv? In an analysis by Abdill and Blekhman (2019) back in 2018, there were 37648 preprints uploaded to bioRxiv. But in the world of preprints, this information is quite dated as back then there were only ~2000 uploads each month. Luckily, these same authors regularly scrape data regarding submissions to bioRxiv and Im able to reproduce these live data below. It is interesting to look back at the concern back in 2015 that preprint servers like bioRxiv might not catch on in the biological sciences (Vale 2015), and it is still true to say that the number of preprints in the life sciences is still dwarfed by the annual number of publications, whereas physics has seen the opposite trend. FIGURE 10.1: The growth of bioRxiv submissions in time. Note how the rate of submission rocketed at the beginning of the pandemic lockdown, and has remained high ever since. What you see is a doubling of bioRxiv submissions dating back to May 2020 (Figure 10.1), a few months after the start of the global COVID pandemic. (Go to the RXivist website to see the incredible spike in medRxiv data at the same point in time.) Many scientists had spent a few months working from home. Some had been productive, and many decided to move this productivity for the first time onto bioRxiv. In answer to the question above, just about everyone now posts preprints on bioRxiv. Those that dont likely use other preprint servers, or are not moving with the times. The preprint revolution has not gone unnoticed by the tech giants. Back in 2017 the Chan Zuckerberg Initiative made an undisclosed donation to bioRxiv. The advisory board also has the architect for Google Scholar, Anurag Acharya. 10.3 Why might you want to post a preprint? One of the advantages of posting a preprint is that it gets a DOI (digital object identifier). You can then use this DOI to refer to your work even though it is not published in a peer review journal. For example imagine that youve just finished your thesis and only one of your chapters is published. How can you show to prospective employers how good your work is? Or if you are applying for money how can you refer to your work even though its not published? A preprint is a simple solution to this problem. Other benefits include having a wider scope of peer reviewers. if you know that in your subject area there are many people who may want to comment on your work constructively then this would be an opportunity to give them access. Importantly in a preprint because it has a DOI your work is not vulnerable to theft. It also allows you to stake your claim on the work that youve already done even though there may be a lag time between this and it coming out in a journal with full peer review. If you do want feedback on a manuscript that you have posted as a preprint then you will need to tell people about it. A good example of this would be after providing a talk, or a poster, at a conference you might show a QR code where people can read your manuscript as a preprint. you can also publicise it to your community on social networks like Twitter. If you get lots of feedback on your manuscript then you should expect to incorporate it. So be careful what you wish for, because you could be opening yourself up for a lot of comments. Posting a preprint on bioRxiv is also a shortcut to submission to a growing number of traditional journals. Manuscripts and Supplementary Information can be transmitted directly from the preprint server to many journals without the need to upload the files and metadata a second time. 10.4 Upload newer versions If you, or others, spot errors in your preprint, or you find new literature to cite, you can update your manuscript with a new version. Indeed you should do this for as long as your preprint remains active. Once published, make sure that there is a pointer from your preprint to the published version. 10.5 Will you have to post a preprint? This field is moving quickly. In December 2020 at least one journal (eLife publish then review) announced that they wont accept a submission until a preprint has been registered. Thus all reviews are made on preprints. Other journals, like PLoS, are announcing in house preprint servers. You should expect this area to rapidly change in the coming years, so no matter when you are reading this, you are more likely than ever to need to submit a preprint. At the time of writing, there are still some journals that make it a condition of submission that there is no preprint. Make sure you check within your target journal list. If you choose to publish in an overlay journal, then youll have to deposit your submission onto a preprint server. 10.6 If we all post preprints, do we really need peer review? As far back as 2002, William Arms (2002) suggested that openly soliciting comments on the web might be an alternative for peer review of scholarly articles. Sixteen years later, this has come to pass in the form of preprints. There is a growing trend for publishing preprints. Preprints are simply manuscripts that are submitted to an online server and available for all to view. Physicists started first with this phenomenon, but biologists have been hot on their heels and there are now a number of prominent preprint archives including BioRxiv. Each of these sites maintains the open access manuscripts, and allows other users to post comments (partial or complete peer-reviews) of these online manuscripts. There are problems in the world of publishing. Mostly related to the greed of publishers who demand large sums of money for content that they do not pay to produce, but charge for access. We must look for alternatives to the current model, so could we replace publishing with an open platform like BioRxiv? 10.7 Could these comments pages really replace peer review? Peer review is held as a gold standard in scientific publishing, and theres certainly a lot to that. It ensures that published material has been read and its contents assessed independently. But peer review is fallible, because scientists are humans. Not all reviewers can assess all parts of a paper, especially papers that cover several disciplines Not all editors will choose reviewers that are independent and objective. Depending on the framework set up for the journal, friendly reviewers can be chosen or critical reviews removed. Perhaps the inverse is more common, although you are less likely to see these manuscripts published. Poor peer review is a growing problem. Lastly, and not least, there is an increasing difficulty in finding peers who are prepared to review manuscripts. (See the Perry et al (2012) editorial, which was a plea to the herpetological community to accept reviewing as a necessary duty). In 2003, Stefano Mizzaro proposed changing peer review to the format that we now see in preprint journals. Let every reader become a reviewer. Another take on this same theme is provided by Heesen and Bright (Heesen and Bright 2020) who argue for a more subtle change in the date of publication (prior to peer review as seen in preprints) instead of after peer review. Here their emphasis is on removing the wasted time spent reviewing and then rejecting manuscripts that will never be published. Their discourse is very persuasive, yet given that both models currently exist we need more ideas on how we could drive a preprint model forwards. More ideas do exist, and I encourage you to explore those proposed in a special issue edited by Kriegeskorte et al (2012). In the preprint model, the first three problems (above) might all be overcome as no-one chooses the reviewers. Instead they choose themselves, and are motivated to do the work. Their competence to cover all aspects of the manuscript is not assured, but one assumes that independently motivated reviewers will only comment on parts that they are able to assess. All of this is very good, but will people actually read and comment? A quick look at the sites will tell you a lot about the level of reviewing that is currently going on in biosciences preprints. A quick look through the top 10 articles on BioRxiv zoology section confirmed my suspicions. Plenty of tweets about the articles, but none of them had any comments. Indeed, a further trawl through PeerJ Preprints also found no comments. Further, Id suggest a greater move to this culture might produce comments for well known labs, a certain amount of trolling for labs with ongoing disputes or rivalries, making this kind of comment review a sort of trial by popularity. But I dont see a situation where potential reviewers will take time-out once a week (for example) and hunt for manuscripts that have received no comments. It seems far more likely that the authors will have reciprocal agreements with other groups to review each others manuscripts. This nepotistic tendency then puts us back into the area of peer review that weve been working hard to overcome now for sometime (double-blind reviewing, editors codes of ethics, etc.). 10.8 When should evaluation end? One point raised many times in the special issue edited by Kriegeskorte et al (2012) is that evaluation should be open ended: ongoing evaluation. There was a consensus to see reviewers continue to question the contents of papers long after publication. But these authors dont appear to have a realistic perspective on the time of authors to defend their work. Imagine the effort that you currently put into a rebuttal letter (see chapter above). Now consider that your first rebuttal might come after a few months, and then you need to compose another after a few years. Perhaps you are the only author still working (especially if it is the work of students). Perhaps all of your co-authors are dead! Suddenly you are called upon to defend your work, potentially decades after completion. Can you do it? Would you want to do it? What would be the consequences of not doing it? While I am regularly the first in the queue to criticise the current peer review system. I am also very grateful that publication represents a line in the sand under which I wont have to continue working on a project. In a world in which I had continually documented every step of every experiment (see part 3), I can imagine that it is potentially possible to find a defence for every step in a protocol. But the painstaking nature and time involved in going through old work would be an added burden that I cannot welcome with any enthusiasm. Personally, in a world when I have the option of working on a new project or endlessly and repeatedly defending old ones, Id pick the new project every time. 10.9 Are preprints published? As they each have a DOI (Digital Object Identifier), they are in their own way already published. Another point is that these articles are picking up citations. And there is a new concern that these articles are being cited, even when they are subsequently available through a published journal. This is one of my personal concerns with using a preprint service. Im happy to put the paper out there for public comment, but the idea that itll remain there and that readers wont necessarily be redirected to the peer-reviewed version does concern me. Another question is what happens to manuscripts that are placed on preprint servers, are then sent out for review but not published because they are fundamentally flawed? Its not as if the reviews are not made, but there is no automatic link to the reviews by the journal that conducted them. Whether or not there is a paper inflation, there is certainly an ever increasing number of papers. The rejection rate is not insignificant, and while many of the papers are not rejected because they are flawed (they may well go on to be published in another journal), there are certainly a lot of manuscripts out there with fundamental flaws. These are often sent for peer review, but those reviews pointing out the errors wont necessarily make it back to the comments page on the preprint server. I think that this is a serious problem. The reviewers have spent time and effort and the very reason they do this is so that manuscripts with fundamental flaws dont find their way into the literature. However, preprint servers have, perhaps unwittingly, found a loophole that allows manuscripts that are not scientifically robust a backdoor to citations. 10.10 But if they are fundamentally flawed, shouldnt everyone be able to spot it? No. Reviewers are chosen by an editor with great care because the area is in their particular domain. They have insights that not everyone will be aware of and these are an important aspect of the purpose of peer review. I edit for the journal PeerJ. Although there can be various reasons to be rejected from PeerJ, normally it means that your paper is not scientifically sound. As PeerJ has no selection for impact, rejection does not normally mean that it can be simply submitted to another journal. I have noticed that manuscripts that I have rejected from PeerJ are still available as PeerJ-preprints without any comment on their failure to go through peer review. In my opinion, this is not good as it essentially ignores the input given by both reviewers and editors. The article appears as if it has had no comments or attention, when this is not the case. In a system where we move to relying more on preprints, why would we want to ignore chosen peer reviewers for whom this article was within their specialist area? Moreover, I note that the preprint in question is also receiving citations (according to Google Scholar), again raising concerns that rejection by peer review is not a hurdle to entering the scientific literature. 10.11 Preprints are here to stay It is clear that preprints are with us to stay. The year of the COVID-19 pandemic (2020) saw an explosion of preprint papers on the topic, but also saw the misunderstanding of what these articles mean by the press and general public alike. Rapid sharing of results via preprint servers has already been put in place following the outbreak of Zika virus in South America (back in 2015-16), but the global nature of the Covid public health crisis saw much larger numbers of preprints being placed online. But the value of preprints will always be limited for as long as there is no peer review. Moreover, comments wont suffice for peer review as there is no editorial oversight. As youll read elsewhere, the role of the editor is pivotal in publishing. 10.12 The exciting new world of Overlay Journals Having said that preprints wont replace the role of peer review, what if we did have good, editorially coordinated peer review of preprints. What if, instead of these manuscripts effectively leaving the preprint system, they were updated together with the reviews that prompted the updates, each with their own linked DOI. What if the journals themselves were simply pointing to collections of papers that had been curated in this way? Simply a website that throws a veneer of a journal as waypoints to peer reviewed journals? This world has already been imagined and is functioning in mathematics, where Overlay Journals have begun to prosper. According to Brown (2010), the idea of overlaying has been with us for some time, and exist as websites that offer a series of links to other papers. In this way, a review article could be considered an overlay paper, the contents of Web of Science as an overlay database. But, for me at least, this is not where the real potential lies. Instead, imagine the overlay journal as a way in which academics entirely remove the need for publishers. The need for this is increasingly evident as we become more familiar with the ways in which we rely on traditional publishing models to pervade our scientific project with confirmation bias. Overlay journals no longer require a publisher to store the publication. This is done at the preprint server. The reviews are housed at the same arXiv site (or would be in an ideal and transparent version)(Rittman 2020), as is the manuscript in its final form after being accepted by the overlay journal editor. The authors themselves are responsible for the final layout. The Overlay Journal co-ordinates the reviews and conducts the editorial work, and then simply acts as a pointer to the finished product: no papers, no publishers, no editorial management software, no costs and all papers are Diamond OA! The journal Discrete Analysis (indexed in both Web of Science and Scopus) was the first of these new arXiv overlay journals (since 2017), and following on this link will allow you to quickly appreciate what an Overlay Journal is. Each published paper still sits on its original preprint server. The overlay journal itself offers a brief editorial summary of what youll find if you click through to the paper. This is a fantastic idea in that it pitches editors back into being responsible content curators. As an editor Id want to be motivated to publish a paper that I liked in order to write an editorial summary about it. Because the only the accepted version is provided with an article number and the style file of the journal layout, the author then produces the final version of record (VoR) of the accepted manuscript by running the style file with LaTex. All of this is possible with free software, for example by using Rmarkdown (Xie, Allaire, and Grolemund 2018). Using preprint servers also allows the entire process to be transparent, very quickly becoming associated with other great initiatives like the Centre for Open Science - OSF. 10.12.1 What do traditional publishers think of Overlay Journals? Surely, the onset of Overlay Journals should have publishers quaking in their boots? Strangley not. But their response should really be enough to wake us up. Theyre probably only going to succeed in disciplines where a no-frills approach to publishing is acceptable. Anonymous from Highwire Press Inc. 2017 But they do see that theres a possibility of disruption: I think that the real threat to our traditional model if Overlay Journals have Impact Factors and can provide the same services, and they are free then I think that that does pose a threat. As this has already happened, it would be interesting to know how traditional publishers are going to prevent an Overlay Journal take-over. 10.12.2 What is happening in biological sciences? One of the original electronic journals, Journal of Medical Internet Research (JMIR), announced in 2019 that it will launch an overlay journal covering biology, a so called superjournal, JMIRx (Eysenbach 2019). This overlay journal operates by editors choosing preprints that they want to publish (editorial prospecting), and then approaching authors and reviewers, and also by authors pitching their preprints to the editors. Today JMIRx|Bio accepts any preprint published on bioRxiv. Although JMRIx|Bio, and sister journal JMRIx|Psy, were launched in 2020, I cannot find any articles submitted (by mid-2021). The sister journal JMIRx|Med, launched at the same time and in the same area as other JMIR journals, has a rapidly expanding publication base. Theres an excellent tie-in here with transparency. Because preprints are Diamond OA, and reviews are OA, the process is all transparent. A nearly overlay model is the Peer Community in Evolutionary Biology, launched in Janurary 2017. This comes very close to the arXiv Overlay Journal model described above. These preprints are submitted to PCI-Evol Biol, and are reviewed and (if they arent rejected), a recommendation is given. The site then publishes the recommendation from peers as well as pointing to the preprint. However, unlike Discrete Analysis, the preprint remains unpublished despite the peer review and can then be taken onto a traditional journal. There is a growing list of journals whose editors will accept recommendations from PCI-EvolBiol, and may use the reviews when appropriate. However, its also worth noting that there are a small number of journals that will not accept preprints recommended by PCI-EvolBiol. While Peer Community in Evolutionary Biology does not publish their peer reviewed articles, another initiative from Peer Community In takes a step backwards to get a step closer. The journal eLife is also taking steps toward becoming an Overlay Journal, with their implementation of a preprint only submission route (Eisen et al. 2020). Although eLife appears to embrace all the advantages of transparency in their use of preprints, there is still a significant barrier that has recently jumped from $2500 to $3000 for the privilege to publish (eLife has an APC waiver system which is not seen by editors). Again the question of what exactly scholars are paying such high fees for comes to the forefront. 10.12.3 Preregistration and a commitment to publish Another initiative from Peer Community In is the possibility of submitting to their Registered Reports, which goes much further towards removing the confirmation bias. The Registered Report (RR) is in effect the registration of a proposal (i.e. preregistration) with review. If the RR is approved by reviewers then the study is, in principle, given the green light for publication whether or not the hypothesis posed is accepted or rejected. I say in principle because those same reviewers are shown the ms again once the results are in. They need to check that the methods proposed were followed, the analyses were conducted in the same way they were proposed, and that the conclusions are justified by the results. In terms of figure 27.1, Peer Community In are offering to organise the two yellow review arrows. In addition, there are a bunch of journals that have already signed up to accept RRs that are signed off after completion (notable among these is PeerJ). To me, this represents an important step in the right direction toward transparency, and the elimination of confirmation bias. What would be great to see is the number of conventional journals sign up with RRs based on the quality of the study design and execution, and the concomitant abandonment of Impact Factor as a driving force in publishing. 10.12.4 Beware of publishers preprint servers Publishers have a lot to be worried about preprint servers as they have the potential to take away their business. For this reason, you will see that some publishers have launched their own preprint services. Dont be lulled into submitting to the preprint server of a publisher. There are plenty of preprint servers that have nothing to do with publishers, including the most prestigious. These are non-profit transparent organisations, and we all have an interest in them staying that way. Simply put, theres no need to use a publishers preprint server (this is the same principle as your data, see here). 10.13 Peeriodicals - another twist on the idea of an Overlay Journal The launch in 2018 of Peeriodicals puts another twist on the idea of an Overlay Journal. This time, the Peeriodical is a site where anyone puts together a collection of any published papers or pre-prints that they curate themselves on a topic. They dont pass them out for any further review, but they are in effect another kind of curated Overlay. "],["review.html", "Chapter 11 Writing a literature review 11.1 Having a purpose 11.2 Systematic reviews 11.3 Using Google Scholar 11.4 The meta-analysis 11.5 Dont try to do too much 11.6 In summary", " Chapter 11 Writing a literature review The first chapter of many PhDs is often a place for a literature review. Writing a review of the literature is actually a very useful task to undertake during your PhD, preferably towards the beginning. Firstly it will get you familiar with all of the relevant literature in your field. It will give you some idea of the historical context of your subject area. And its especially good to help you spot gaps in the literature that may not have been realised before. Reviewing the literature should make you familiar with the bigger questions in your subject area. This will make it easier for you to introduce each of your subsequent chapters. 11.1 Having a purpose Writing a literature review is easiest when you have a clear purpose. The objective can be particularly tight, or can aim to use the literature in order to answer a broader question. Either way having a clear purpose for your literature review will help you to define exactly what literature youre looking for. Without an aim a literature review can be extremely daunting. There will be literally no end to the literature that you could include and it may well overwhelm you. If your question is more broad it will help to define a clear time period in which you are searching for literature. For example you may want to just consider the last 10 years. Remember that the amount of literature is increasing almost exponentially and so if you are covering the same ground as a previous review a lot can happen in 10 years. If your aim is quite narrow then you can legitimately cover all of the literature. This may require delving back more than 100 years. But as we know from previous chapters the first journal only began around 150 years ago. If you want your review to have an objective or statistical angle on the literature then consider writing a systematic review or a meta-analysis. 11.2 Systematic reviews I prefer to conduct a systematic review. This is where you define your search criteria and the databases that you want to use and then include all of the literature that comes out. You will need to provide clear criteria for the inclusion of literature. As well as explaining exactly how you decide to include or exclude papers that result from your search terms. Systematic reviews require a flow diagram to show how this literature was included or excluded. This means that you have to be systematic in how you record weather a paper is included or excluded. Im my opinion, a systematic review is less subjective than a review where the author is essentially cherry picking the literature in order to tell the story as they see it. It also allows you to conduct statistical tests in order to answer some of your questions (a meta-analysis). Lastly, it avoids one of the oldest problems in science: confirmation bias: Simply looking for articles that back up your own view. Too many old reviews are really just written by academics seeking to confirm their standpoints, and so moving forwards we must place the emphasis on being objective through systematic reviews. This view is now growing so that increasing numbers of journals will only accept a review if it is systematic. 11.3 Using Google Scholar Google scholar has distinct advantages over other literature databases as it searches words inside the contents of an article, not just in the title, abstract and keywords (like Scopus and WoS). However, the output style of Google Scholar is infuriating as it resists being able to capture search results into a simple table (database) format. In addition, it does not support the boolean search operators (see part 2), and has a far broader range of literature that is included. Help is at hand for those of you who would like to use Google Scholar and get a database output with the publication of Publish or Perish software (Harzing 2007). The original purpose of this software was to calculate personal research metrics for promotion purposes, and it still does all this. But it also provides a single platform for searching many different literature databases: Scopus, Web of Science, Microsoft Academic, Google Scholar. Google Scholar has an important attribute over many other databases in that it returns results in languages other than English. Using only English to provide the basis for your review might lead you to draw an unreasonable conclusion with a literature bias (see Nuñez &amp; Amano 2021). Language is only one of several potential biases in a literature review (see Amano &amp; Sutherland 2013). 11.4 The meta-analysis A meta-analysis is a type of systematic review that uses the results of all of the studies included in order to provide a synthesis. While more powerful than a systematic review alone they take an awful lot of work. If you are expecting to get a lot of literature then consider putting a team together in order to conduct a meta-analysis. Once written they can be very rewarding as they tend to attract a lot of attention and citations. 11.4.1 Combining topics by combining people The literature review that you conduct for your PhD will likely only have you doing the bulk of the work. But reviews become especially insightful when you combine topics together. To do this you may want to find somebody else who is an expert on the literature in that field. This might be somebody in your lab group. It might be somebody who is also just starting a PhD and is writing a literature review. This brings me to another very important point. Share your enthusiasm for your topic. Remember to talk to people around you both in your laboratory and in your department about the work that youre doing, and tell them about the interesting things that youre finding. If they also tell you about their work then you may find that you have somebody to combine your literature review with in a novel angle thats never been thought of before. The paper that results could be a smash hit. 11.5 Dont try to do too much Whatever your aims were before you started compiling the literature, remember to remain flexible as you proceed. its hard to know exactly how many papers you will encounter on a particular subject unless you already know it very well. If youre prepared to remain flexible while conducting your review it may save you from overreaching. Always be open to reducing the scope of your review or seeing particular questions or issues while youre reading that may be better than your initial idea. 11.6 In summary if you come to the end of your PhD and have not yet done a literature review then now is the time. You should already know a large chunk of the literature in your particular area and you will be looking for future questions to tackle in a postdoc. Conducting a literature review at this stage in your career will not only help you to highlight unanswered questions and interesting topics, but it will get your name out there. Once youve done it youll be glad you have. "],["submitting-your-work-to-a-journal.html", "Submitting your work to a journal", " Submitting your work to a journal Part 2 of this book is all about submitting your manuscript to the journal of your choice. It will then take you through what happens to the manuscript and give you insight about where you might want to publish, how to choose the journal. "],["formatting.html", "Chapter 12 Formatting your submission 12.1 Must do check-list before submitting your manuscript: 12.2 Mistakes people make:", " Chapter 12 Formatting your submission Lets face it, after spending so much time writing your manuscript, its worth making sure that you dont make silly mistakes in finalising the manuscript. 12.1 Must do check-list before submitting your manuscript: I am very fond of check lists, and their utility has already been proven many times (Haynes et al. 2009). I have developed this check list of things to go through before I submit a manuscript. The journal that you submit to is likely to have their own, so you should add that onto the end. Plus, in your subdiscipline there are likely to be some extra points that you can add, so I suggest that you add to this list when making your own. Spell check - yes, it sounds obvious but doing a final spell check is a good idea. Not only this, but take the time to have your word processor ignore or add all of the special words (e.g. species or site names) that it doesnt otherwise recognise. This will ensure their consistency throughout (within and between chapters). Make sure that your language settings are set to UK English (or the English setting for where you are based). Remember that the journal that you submit to may well be in a different region to your own (so you might need to change your spelling settings) Look out especially for words that have different accepted spellings like those ending in -ise or -ize. Decide which you want and be consistent. Consistency is king! Capitalisation of common names, place names and not adjectives. For example, South Africa has two capitals, but southern Africa only has one. Grammar check - always good to take a final look, especially for chapters that you wrote some time ago. Use the word processor automated options to help you. Have your computer or another device read the text so that you can hear anything obviously wrong. Pay attention if you have used we or I and make sure they are consistent in your manuscript. You are likely to have used I in your thesis, in which case you will need to change to we if there are multiple authors. Page layout. Really important to get this right in your template. Make sure that your template has: Correct paper size (A4 and not US letter - or visa versa!) Margins Line spacing Page numbers Line numbers (really helps your reviewers - add these even if the journal adds their own) Headers and Footers. If you can manage a chapter specific header, its useful to show your name and a short chapter title. Sections and subheadings. Check with the journal instructions to authors about what sections they allow and where. Figures - many journals charge for printing colour figures. This does not mean that you have to reformat your figures to be in monochrome. You will have an option of submitting colour figures for online use only (in pdf and online), while the limited print run will have them in monochrome. You should make sure that your figure is still understandable when printed in monochrome. Acknowledgements - this is your time to say thank you to all the special people that have helped during your study. There are probably more than you realise, but in addition to your friends and family (who most people dont forget), think about the people who administered the work, lab mates (past and present) who were always there to help, and people who gave permission at study sites. References - probably one of the most dreaded sections of any manuscript preparation, but they do have to be done. If youre one of these people that has everything in a database, then youll be laughing or cursing your database throughout. While it might be tempting to only look through the data within the database, spend some time to see how its displayed in the manuscript. A mistake in the reference database will be multiplied many times in the manuscript. Remember that examiners love to take a random look through the reference section to make sure that its all good. After years of painfully entering references themselves, they know just what to look for. Now go to the website of the journal where you want to submit your manuscript and check to see their submission guidelines and whether or not they have a checklist. 12.2 Mistakes people make: Other than the obvious things, all mentioned above, here are some of the mistakes Ive seen. Submitting the wrong version (yes this does happen!). Probably worse if having a mixture of right and wrong versions for different chapters (worse because it takes longer to sort out) Last minute additions to text with incorrect spelling and or grammar Two correctly spelled synonyms sitting next to each other when only one is desired (probably came about when editing) Forgetting to check for plagiarism (see here) Comments and or edited text (especially when its marked as being by someone other than the student). Page numbers that start again and again at different sections Lots of blank pages or spaces (avoid blank pages if you can, and try to limit the amount of blank space (never &gt;half a page). Leaving important people out of the acknowledgements, especially your funders! "],["letter.html", "Chapter 13 Writing your Cover letter 13.1 Do editors read cover letters? 13.2 What not to do in your cover letter", " Chapter 13 Writing your Cover letter Many journals require that you write a letter to the editor on submission. Each journal should tell you what this letter should contain. This will vary from journal to journal as some may have a set of check boxes that cover some points, while others may want a written declaration. It is very important that your letter contains all of the information required by the journal. If not, it could lead to a swift desk rejection. Some journals have a text box in their submission software for you to paste the text of this letter. Others expect you to upload a pdf letter on headed paper from your institution. Make sure you know what is required and that you are prepared. The reason for a formal signed letter on headed paper is that in some submissions, this letter is used as a legal declaration. Your cover letter is a professional and formal letter, and should be written as such. Use the conventional letter writing format, including addresses, date, signature, etc. If you are unsure what this looks like, there is some great advice on the web, including templates to use (see here and here). Address your letter to the journal editor. One of the nice things about academic titles is that they are gender neutral, so use them: Dear Dr. Jones, or Dear Prof. Smith. Even if this person has an office down the hall and you see them every day, keep the cover letter professional. The following points should be covered (where relevant) in the order given as a default. Any content and style requests from the journal about how the cover letter should be written clearly takes precedent. The title of your manuscript, the type of submission (review, research article, letter, etc.) and the name of the journal that you are submitting to. Note that it is all too easy to forget to change the journal name when you are submitting to another journal. In my time as editor, Ive seen some very nice letters explaining how the manuscript is appropriate to a completely different journal. Not a good start! Statement that your manuscript has not been published or submitted elsewhere, and that all authors have approved the submission. There are other statements that are required by certain journals, and sometimes the journal requests that you copy and paste their text as the cover letter is kept and used as a legal declaration. Also it may include information about ethics clearance and any permits required having been obtained and available should the paper be accepted. Note that you dont need to include all of this information unless the journal that you are submitting to requires it. Include information about why your research is suitable to the scope the journal that you have submitted it to. This requires you to have checked the scope of the journal itself and have thought about exactly how your paper aligns to this. Bear in mind that this is a real problem. Editors get far too many papers that do not fit the scope of their journal, and it takes time to process and reject these (so they are not appreciated). Novel and innovative research. For journals where the impact factor is significant, you may want to emphasise what is novel about your study, and therefore deserving of the impact. Important information that the editor must know. For example, if the manuscript was previously rejected with an invitation to resubmit (then also include the manuscript number that it was given previously). Or (rarely) if you (or others) have previously retracted a similar study, but and reasons why this manuscript is not affected. Connections to other ongoing research. If relevant, state what other manuscripts are already submitted to this or other journals. For example, is your work part of an ongoing consortium or research programme? The idea here is to demonstrate to the editor that your manuscript will be cited in a timely manor. A final brief statement to the effect that: We declare that we have no conflicts of interest. 13.1 Do editors read cover letters? This is a moot point in that you will never know. Where they are legal requirements, its not likely that editors will read them, but editorial managers may well make sure that these are present in order not to get a pre-review (desk) rejection. Chief editors will likely read parts of the cover letter along with the abstract before deciding which Associate Editor should be assigned. Some chief editors will even leave this role to the Associate Editor. The Associate Editor should read your cover letter in full, together with the metadata and other salient information therein. They should also read the entire manuscript. 13.2 What not to do in your cover letter Try not to make your cover letter too long. A single page should be enough to cover all of the points above. Dont copy and paste your abstract. There will be a place for this metadata on the submissions site. Avoid specialist terms that the editor may not know. Dont try and oversell your study, or make excessive claims. Avoid first ever claims, as they wont impress the editor. Dont suggest potential reviewers unless the journal rubric specifically requests this in the cover letter. Similarly, dont suggest people that you dont want to review your article, or start any history of why your submission is complicated by third parties. Keep to the formal letter style. Have spelling and grammatical errors. Format the letter in a way that might make it difficult to read: Dont be tempted to reduce font size to get more in (keep to Ariel 11 point) If you need more space to keep your letter to 1 page, change the margin sizes Dont fully justify text (left justify only) If you are recycling your letter, check that you have changed everything. "],["whichjournal.html", "Chapter 14 Choosing the right journal 14.1 Step 1: Indexing 14.2 Step 2: The Subject Area 14.3 Step 3: The Journal Scope 14.4 Step 4: Current Contents 14.5 Step 5: Society journals 14.6 Step 6: Transparency credibility 14.7 Step 7: Knowing the journal from the inside 14.8 Step 8: Financial considerations to publishing 14.9 Step 9: Type of peer review 14.10 Impact factor 14.11 No Impact factor journal 14.12 Shortlist", " Chapter 14 Choosing the right journal In this chapter I give you a list of steps to go from a potentially very long list of journals where you might publish, to choosing the one where you will submit your manuscript first. As you work through the list keep notes on why you exclude journals at each step. You may want to revisit these criteria later, or explain to your advisor why a particular journal was not considered. This chapter is geared toward the current model in the life sciences of journal title as a measure of quality. The reality is that this model is shifting, and we may well end up with another (better) open model in the future based around preprint servers and overlay journals. The current reliance on journal titles is driving a toxic culture in biological sciences that is becoming increasingly recognised, even by those who are gatekeepers for this model (see Part IV). To reflect this viewpoint, and help drive a culture of change, I have placed Impact Factor outside of this list of steps. In doing so, I acknowledge that you and your co-authors may well be operating inside the current publisher driven model advocating for Impact Factor as a step with high priority. Im going to suggest that you keep a spreadsheet with the answers to the steps below as columns, and different journals as rows. 14.1 Step 1: Indexing You want other people to be able to find the work that you publish, and so selecting a journal that is already indexed in one of the major literature databases (Web of Science or Scopus) is important. Be aware that when new journals are indexed, they are usually done with their entire back catalogue. Thus, if a journal advertises that it will be listed by one of major literature databases, your submission will likely be listed eventually, even if not immediately. 14.2 Step 2: The Subject Area No matter what your paper is about it will fall within an existing subject area. A good way of determining your subject area is to look at a literature database like Web of Science or Scopus. These databases have subject areas which contain groups of journals. You can look through the journals that you cite in your references, then check with Web of science or Scopus to see which subject area the majority of them are grouped into. Journals have different hierarchies of scope. Some journals attempt to take on the full gambit of science (e.g. Science and Nature) while others are only interested in a particular taxonomic group. In general, the impact factor of the journal is likely to be linked to the diversity of the scope. This is not always the case. There are some taxonomically specific journals with high impact factors, and there are some general journals with low impact factors. See chapter below for the importance of the Impact Factor. Once you have determined your subject area make a list of the journals within this area. Based on your reading of literature pertinent to your manuscript, try to decide whether your manuscript is likely to be accepted by a journal with a high ranking Impact Factor, a medium ranking journal, or a low-ranking journal. Sort the list of journals within the subject area by impact factor and then select the ones that are either high (&gt;10), medium (&gt;4), or low (&lt;4). 14.3 Step 3: The Journal Scope Every journal has a scope that is stated on their website. Your manuscript must fit into the scope of the journal that you select. In order to get your candidate list of journals you now need to visit their websites to look at their scope in detail. If your list is long, I suggest that you start with the journals whose articles you have already cited in your manuscript. Your manuscript should clearly fit within the scope. If you are not sure then it probably doesnt fit, but try asking your advisor. In the journals that you enter into your spreadsheet, quickly summarise the scopes of your choice journals and make some notes on how your manuscript fits them. This will help when writing your cover letter. 14.4 Step 4: Current Contents Now that you have a shorter list, its time for you to look at the current contents of the journals that are on their website. The contents for the last 2 years should reflect the policy of the current editor for accepting manuscripts. You should be looking for papers that look similar to your manuscript in their scope. If you see papers that look directly comparable to your own then make a note of what they are. Your list of journals should now be less than 10. 14.5 Step 5: Society journals Academic publishing started with society journals, and I think that they are still worth supporting if you can. Your advisor or co-authors may be members of particular academic societies, and may have a preference therefore to publish in their own societys journal. See below for other potential advantages in publishing in a society journal. 14.6 Step 6: Transparency credibility As we have already seen (part 2), transparency in science is very important and should be part and parcel of your own work. When publishing your work where you have made a real effort to be transparent, you should look for journals that do the same. There is a badge system used for transparency in science Marshall and Strine (2021). You can find a list of journals that have been approached to join the transparency movement here. Its interesting to see how many have rejected the idea of transparency, and why! 14.7 Step 7: Knowing the journal from the inside Your advisor or co-authors could be an Editor or Associate Editor (past or present) of one of your target journals. Or there may be someone in your department or institute that you could consult. I am not suggesting that you use their influence to help you get published, this is strictly prohibited by most journals. Instead, these people can help you decide whether or not your submission will be welcomed or rejected without review. Reject without review is typical for manuscripts whose authors have not followed steps 2 to 4. It can still happen, even if you have. Reject without review is such a waste of everybodys time that you should avoid it if at all possible. 14.8 Step 8: Financial considerations to publishing In an ideal world, there wouldnt be any more barriers to you publishing your contribution to the collective of scientific knowledge. Not only is it not an ideal world, but I would argue that there has never been a less ideal time for publishing science. Greedy publishers have taken publicly funded science and made the public pay for it time and again. Read more on this in chapters below. The way they scam taxpayers is called Open Access: 14.8.1 Open access Some journals are exclusively Open Access (OA) meaning that you will need to pay in order to publish your accepted manuscript (author pays). Different types of OA are covered in the next chapter. Your university may have a deal with some OA publishers so its well worth making a note of this. If in doubt, talk to your librarian. However, watch out for manipulative publisher deals that make you more likely to publish OA when your institution has a read-and-publish deal. Remember to ask yourself your motivation for why you are choosing your journal. Choice by publishing company should never be high up on anyones list. 14.8.2 Page charges Note that some journals that remain behind paywalls still demand page charges. These can be quite substantial if you come from a lab with no money for publishing costs. In my experience American society journals regularly have page charges. 14.8.3 Fee Waiver Note that with all of the above you may be eligible for a waiver to page charges or Open Access fees. See the chapter below about who gets a waiver. 14.9 Step 9: Type of peer review Another factor that may influence your choice of where to publish is the type of reviewing done by each journal. These reviewer flavours are discussed in detail elsewhere. Single blind review Double blind review Triple blind review Open review Public review See a full description of these types of peer review in part 1. 14.10 Impact factor The impact factor of the journal may be an important motivation in your choice, or that of your advisor. Ive left it off my list of stepwise criteria as I hope that its not going to influence you according to the San Francisco Declaration on Research Assessment (known as DORA). If Impact Factor is important to you, include it in the list that you produce and make a note of the most recent impact factor for each journal. Theres more about the impact factor in another chapter. 14.11 No Impact factor journal Theres no problem to publish in a journal that has no interest in impact factor. Indeed, it can be seen as the right thing to do, with respect to confirmation bias. See chapter below. However, if you are submitting to such a journal, then you should be aware that this is what their speciality is: an emphasis on the technical soundness, rather than whether or not a significant result was found. The list of no impact factor journals is growing, and they tend to be online only, open access and carry substantial article processing charges. 14.11.1 PLOS ONE A new experiment in a journal without impact. Unwritten section 14.12 Shortlist Once you have your shortlist of journals to consider, take it to your advisor. Together with your advisor rework your list into something that you both agree with and then propose it to your co-authors. Rank your list by journals that you want to try first and those that are your last options at the end. Keep the list so that if you are rejected by the first journal on your list you know where youre going to next. "],["suggestreviewers.html", "Chapter 15 Suggesting reviewers 15.1 Who should you not suggest? 15.2 Who should you oppose? 15.3 Who will the editor use?", " Chapter 15 Suggesting reviewers You will often be asked to suggest reviewers as you submit your manuscript. This can be part of your cover letter, or data that you need to fill in during the submission process. Keep in mind that supplying a name alone will not be considered sufficient, you will need their name, the name of their institution and their email address. Some journals will not accept addresses that do not come from institutions unless they can be verified. The reason for this is that there has been an outbreak of fraudulent reviewers, where authors suggested fake reviewers or gave email addresses that they manufactured (see Brainard and You 2018). Following the spirit of peer review, you should suggest people that you think will provide insightful reviews. These could be people that work in the same area (but that arent involved in your study). Personally, I would be likely to name the same set of people that I would invite myself if I were editing. People that I believe would provide a constructive and unbiased review. 15.1 Who should you not suggest? Anyone who is an author or in the acknowledgements Anyone else you feel may have a conflict of interest connected with the work but not an author someone who was on your review committee Someone in your department or even at your institution (there may be exceptions here, but often journals will not consider people with matching institutional emails) friends, labmates or even relatives (even if you genuinely think that they would do a good job) people who are regular co-authors (grant panels specifically ban you from naming these people as potential reviewers. If you have a large network, this can be problematic) 15.2 Who should you oppose? In addition to allowing you to suggest reviewers, many journals allow you to oppose reviewers. I usually leave this blank. If you have a particular lab or persons who you know will not follow the spirit of peer review, you could enter them here. 15.3 Who will the editor use? It is worth bearing in mind that whoever you suggest, the editor may not use them. I have talked to editors who will never consider anyone recommended by authors as a matter of course, because they assume that these people will be positively biased towards the authors. This same editor said that theyd always use at least one of the opposed reviewers. This rarely fits with journal policy. As an editor, I will often use one of the reviewers suggested by the authors if they fit my (following) criteria. I will make sure that I balance this with another reviewer or two not suggested by the authors. To select reviewers, I will read the submission and look for citations of similar studies, or techniques (depending on the type of paper). From the citation, I will find the paper (preferably published in the last 3 years) and use the corresponding authors address. I will also try to visit the website of the senior (last) author to see whether they have a lab that is still active in this area, and especially I am looking for post-docs or Early Career Scientists who cover the same topic. If they are there, I will invite them. If not, I will write to the lab head in the hope that they may well recommend one of their post-docs. This process can take a long time, especially hunting down email addresses that constantly bounce back from the journals editorial manager software. I will also use people that I know in my own network, especially an extended network. People whose conference talks Ive seen or other papers in my area that I have read or cited myself. I try not to bombard my own close network too much with demands for reviews. I try not to use reviewers auto-suggested by editorial management software. In my experience, these are not suitable people. Whether this is the same for other editors, I cannot say. If the manuscript is a resubmission, I will try to use the same reviewers that made previous reviews. This isnt always possible, and I know that it is a source of upset for authors when they receive new reviews on a second or even third round of review. I dont think that any editors will do this deliberately, but reviewers do have the option of indicating that they are not willing to read a resubmission. If this is the case for most or all of the reviewers, then you are likely to face an entirely fresh round of peer review. "],["openaccess1.html", "Chapter 16 Open Access or Paywall for your manuscript? 16.1 Closed Access: i.e. The Paywall 16.2 Gratis or Libre OA 16.3 Green OA 16.4 Bronze OA 16.5 Delayed OA 16.6 Gold OA 16.7 Hybrid OA 16.8 Platinum or Diamond OA 16.9 Black OA 16.10 Grey OA 16.11 Supplementary Information and Data 16.12 Unsure what you can legally do with published paper?", " Chapter 16 Open Access or Paywall for your manuscript? There are many well established benefits to publishing an Open Access (OA) paper where there is no pay wall to any readers. These include, increased citations, increased exposure and coverage by the media, not to mention increased interactions with the public and the moral and ethical duty to be able to share research as widely as possible. Many studies are now suggesting that the advantages go even deeper (see a collection of studies by Tennant 2017). However the current reality is that most publishers will then require you to pay in order to produce your publication open access. There are chapters later on in this book that discuss the importance of open access. In this chapter, I review the different OA models offered by different publishers. At this period in time, the names are somewhat fluid, and you may not find the specific term mentioned here on the publishers website. FIGURE 16.1: The world of Open Access (OA) is built on shaky foundations. Much more of journal content is still behind a paywall, even for journals that practice Hybrid and Bronze OA. When you are inside your institution, you may not notice the paywall due to seamless integration with many literature databases. You will be far better acquainted with the paywall if you are from a smaller institution or trying to access literature from outside your institution. Once you are the wrong side of the paywall, your options for most content will be Grey and Black OA. There are regular assaults on these two initiatives by publishers. 16.1 Closed Access: i.e. The Paywall This refers to the need for your institution or you personally to be subscribed to the journal in order to access the content. This is the traditional model in academic publishing. If you are a member of an academic society then you may get access to their society journals through your membership. This is still effectively a paywall that is maintained by the publisher and the society together (Figure 16.1). It is sometimes hard to know if there is a paywall if your university subscribes to the publisher or the journal that you are interested in. There has been a lot of headway made in having seamless integration and access to articles behind paywalls from within university IP addresses. If you try working from home then you will quickly find out which journals exist behind paywalls. See later chapter for ideas on how to get around the paywall if you need to. Although publishing an article behind a payroll is often frowned upon these days it usually means that therell be no cost for you as the author, and so for many academics is still the only real option in terms of publishing their scholarly work in an academic journal. There follows a brief description of each of the OA models. See Piwowar et al (2018) for a historical review of these different models: 16.2 Gratis or Libre OA Some definitions of OA extend beyond simply being allowed to read the text (Gratis OA) to it bearing a CC-BY Creative Commons license (see here). This Libre OA means that in addition to being able to share, redistribute or copy the content, the CC-BY (4.0) licence allows others to remix, transform, and build upon the material for any purpose, even commercially. A good example of this would be my ability to publish the following figure (Figure 16.2) from Piwowar et al (2018) as the content of PeerJ is published under CC-BY licence. FIGURE 16.2: Figure 2 from Piwowar et al (2018) shows the increasing number (A) and proportion (B) of a random sample of 100 000 papers published with a CrossRef DOI shows an increasing trend in gold and hybrid OA publications since 2005. 16.3 Green OA This is an option no matter what journal you publish in (including the paywall). You take the accepted manuscript before it has been typeset, and you deposit it in your institutional repository; usually your library hosts this. This is sometimes referred to as a postprint (manuscript with changes made following peer review) - the same version that has been accepted by the journal. Once your paper is published by the journal anyone can access the manuscript that was accepted because it is free from your institutional repository. However the typeset paper will remain behind the publishers paywall. 16.4 Bronze OA Bronze Open Access is an option at the discretion of the publishers. Only some publishers do this for some of their content. For example, they may decide that a certain thematic issue should be open access, an editorial, or review article. There is some debate about whether this bronze model is truly OA as it often still carries copyright restrictions. 16.5 Delayed OA Some journals choose to have their archived content available for all readers without a paywall. Like Bronze OA, there is some debate about whether delayed OA is truly open as it often still carries the publishers copyright restrictions. 16.6 Gold OA In a journal with gold open access it is compulsory for you to pay the open access fee in order to publish your paper. These fees can be very large, so if your choice of journal is gold open access then make sure that your advisor knows. Examples of gold open access journals are PLoS one and PeerJ. The advantage to these journals is that as soon as you publish your work in them, everyone will have access to it without any paywall. The disadvantage is that you may not be able to afford to publish there. The disadvantages of these journals are now becoming very prominent in the Biological Sciences, such that you may be excluded from increasing numbers of journals in your field. Alarmingly, journals with higher impact factors are also charging ever increasing sums to publish Gold OA (Gray 2020). Gray (2020) makes the important point that prestige (often confused with Impact Factor) is being allocated a higher price in Gold OA, that is likely to disadvantage and disenfranchise scientists from less wealthy institutions and countries. This is likely to reinforce an increasing dichotomy between rich and poor researchers. We will take another look at who pays for OA in part 5. Watch out for predatory journals amongst journals with Gold OA. (See chapter on predatory publishing in part 5). 16.7 Hybrid OA Hybrid OA journals are increasingly the norm. You can decide upon acceptance of your manuscript whether or not you want to pay the fee to make your article open access. Again note that your institution may have a deal with the publisher that means that anything you publish there is open access. It is well worth knowing these things in advance before you submit. If you cant afford to pay the open access fee then your manuscript will remain behind a paywall and be only available to subscribers. A slight variation on hybrid OA is when you are a member of an academic society that allows its members to publish open access without extra payment. As a student you are likely to get very discounted membership to an academic society Which might make it very cheap for you to publish open access with them. 16.8 Platinum or Diamond OA These journals are very rare but they do exist. In a platinum or diamond open access journal you do not have to pay any money but everything that is published is open access. In order to do this these journals are often subsidised by governmental or philanthropic agencies. Some university presses are also in the habit of publishing platinum or diamond OA when it meets with their stated mission. Another great new model that is diamond OA is the concept of Overlay Journals. Although there arent any overlay journals in the biological sciences at the time of writing, I think that its only a matter of time. 16.9 Black OA This refers to the placement of published material onto a pirate website such as Sci-Hub. Sci-Hub is considered by most governments to be illegal and may be blocked by your institution or country. However they do a great job in making scientific applications open access and need to be supported for that. Many scientists all over the world depend on Sci-Hub in order to access literature and therefore conduct research. In addition, there are a number of other Black OA sites: Unpaywall.org, Open Access Button, freefullpdf. See part 2. 16.10 Grey OA You can find grey OA repositories of published material on Academic Social Network sites in which you need membership to access such as ResearchGate and Academia.edu. The legality of such sites is regularly questioned (see Piwowar et al. 2018 for more details). There has been legal action with thousands of members being issues with take-down notices. 16.11 Supplementary Information and Data Whichever route you decide to go for your manuscript, please do not place your data with the publisher. There are some examples where publishers choose to place both data and supplementary information deposited with them behind a paywall, even if the article is available Open Access. We also need to ask whether the publisher has the long term vision to curate data, especially when the expense associated with this will rise over time as datasets accumulate behind their paywall. See part 3 for some suggestions about what to do with your data to make it available for all. 16.12 Unsure what you can legally do with published paper? If you dont know what level of copyright exists on something that you have published, then you can find an aggregated set of publisher policies at Sherpa Romeo. This is a really nice database which provides a very simple summary by journal. You can also use this to check out a journal that you are thinking of publishing with. "],["preprint.html", "Chapter 17 Should you submit your manuscript as a preprint? 17.1 For: 17.2 Against:", " Chapter 17 Should you submit your manuscript as a preprint? Later on in the book (part 5) there is a chapter that deals with preprints, explaining what they are and how they function - essentially a place for manuscripts prior to peer review. However, the question of whether or not you should submit your paper as a preprint is relevant now. Essentially, there is no right or wrong answer, and its entirely up to you, your advisor and your team of authors. Here are some reasons for and against submitting your manuscript as a preprint: 17.1 For: Your manuscript needs to be cited by another that you are submitting and you are worried that the peer review process will take too long. You are applying for a scholarship, a grant or job and want to be able to show that you have a body of work that is ready to be published, even if it is not formally published yet. Using preprints, you can allow the hiring committee or potential employer access to your work. This is really much more impressive than claiming manuscripts are in preparation on your CV. You are submitting a grant application and want to demonstrate that you have sufficient data, although it isnt yet published You are aware that another lab is working on a similar project and are worried that submitting to peer review will scoop your findings. Your work has immediacy that it might not have after (potentially) 3 months of peer review. It may be that by releasing your preprint you can contribute to an ongoing debate that otherwise youll potentially miss. Its free. No APC or other fees are involved with depositing your preprint You have the potential to increase your network when people you have never met read your work. You are concerned that youve missed something important or perhaps analysed something in a novel way that others might be able to help with. You want this chance at feedback before submitting to peer review. Your manuscript crashed out of peer review with comments that you felt were unfair or unsubstantiated. You are looking for more balanced comments. In the above case, you might be able to use your preprint as leverage to persuade an editor that your contribution should be fast tracked into their journal. If you can generate enough buzz and positive feedback, you might be able to get leverage on an editor for submission to a journal with a higher impact factor. You have a working group that you actively want to share your publication with, even before it is published This is the only submission route for Overlay Journals PCI-Evol Biol in Biological Sciences JMIRx|Bio accepts any preprint published on bioRxiv since 2020 This is the only submission route for some other journals (e.g. eLife Eisen et al. 2020) 17.2 Against: Any of your co-authors dont want the manuscript submitted as a preprint before peer review You feel that public access might mean that your results are misinterpreted this should be on you to get it right before you submit it There is a real chance that others can use the access to your work and publish it before you Its worth adding here that while you might believe that there are lots of people out there who might want to steal your work, this is a general paranoia that is very common in early career researchers. Few fields in biological sciences really have valid examples of data theft or idea theft. Preprints are another example of how everything is too rushed these days. Ive heard this opinion, but wonder why these authors wouldnt simply hold onto their manuscript until they feel that its ready. I cant really come up with a lot of reasons against submitting a preprint (Ive had to add some I have heard other people saying). This is possibly because Im broadly in favour of preprints and see that there is value there. However, Ive done it with only a fraction of papers submitted in the last 5 years. Why? My experience of preprints, in terms of feedback and reviews, is disappointing. Although these get widely shared on social media, and garner a large number of downloads, they dont generate comments from colleagues. Even when we have sent links of preprints to colleagues asking directly for feedback, weve received little to nothing. This does not mean that preprints are worthless. I think that they have great potential, and they may work better for you in your field than for me in mine. Moreover, preprint servers now hold the potential to free academics from the tyranny of profit hungry publishing houses (more on this later). At this point, I should say that I have not (yet) made any public comments on a preprint. When I have looked at preprints, I (generally) have downloaded them in order to look at some of the details (often the methods or analyses), when theres a dearth of peer reviewed (published) material. There are a few references to preprints in this book. Ill replace them if I find that they have been published. But what should I do if the published version doesnt contain the point that Im citing on? In this case, Ill delete the citation and no longer make the claim because there is the chance that the result did not stand up to the rigours of peer review. "],["submit.html", "Chapter 18 Submitting a paper to a journal for peer review", " Chapter 18 Submitting a paper to a journal for peer review This chapter deals with the process of submitting a manuscript to a journal (Figure 18.1), and what to expect once this is done. It takes time to submit a paper using most editorial management software. Most of the information they require is easy enough to provide, but the insist on having it in such an unfriendly formula, that it makes it all very painful. Believe it or not, they have improved over time. As this work is so tedious, its worth reflecting why they need all of this information upfront before anyone even decides whether or not they want your paper. Sadly, the reality is that all of this metadata (daa associated with your manuscript) is really only of use if the manuscript is accepted. Otherwise, you are really just stuffing the database of the publisher full of information that they may (and likely will) use to spam you in the future. The only data that they must have on submission is your name and contact details, and the verification that youve adhered to the journals ethical requirements (which you could do in a letter to the editor). Some of the rest will be of use to the editor when deciding who to allocate your submission to, but the vast majority of the metadata are only used when your article is accepted - and then they become vital. Metadata about your manuscript lie at the heart of the ability for CrossRef to link you, your co-authors and their ORCID accounts together with your manuscript. All of this information is held in a header file of the published webpage so that Google Scholar can scrape it into their database. Its also used by all of your automated referencing software plugins. Having this data accurately means that the rest will flow nicely. Doing a sloppy job will mean that those who rely on such services might well mis-cite your paper, get your name wrong, or one of lots of other potential issues. Most of the major publishers now use this metadata to make up the author information (and addresses) on the front page of the typeset paper. Be aware that when they appear wrong on your proofs, its likely because you (or the corresponding author) didnt enter the metadata correctly. FIGURE 18.1: This schematic demonstrates the editorial work-flow of a typical journal. Be aware that although it does take a lot of effort to get a manuscript ready for submission, once it is submitted, there is a lot more work taken on by a large group of people who are (usually) not paid, and who are undertaking the work associated with your manuscript in addition to their day jobs. Targeting journals for submission: there are a lot of journals out there, and you need to make sure that you are submitting your paper to a journal in the right subject area (there is a detailed chapter on this subject). Remember to keep your ordered list of journals that you prepare so that you can refer back to this in the case of rejection. Prepare your manuscript (ms) according to the journal guidelines: this may require a lot of work especially if the journal requires full formatting on first submission. Some journals require additional items such as graphical abstracts, so make sure that you know what is needed. Very important to note are any word limits (including for the abstract), and potential caps on number of citations. After approval from your advisor, circulate this final version among your co-authors. This is a good time to gather the needed meta-data for submission. Youll (usually) need a letter to the editor, key-words, recommended (or opposed) reviewers, and addresses (with ORCID) for all authors. These should all meet the approval of your co-authors. For the purposes of this chapter, I am assuming that you are the corresponding author. This is something that you should learn to do, but check with your advisor about whether or not they think it is a good idea for this submission. Being the corresponding author carries some extra duties as they are responsible for making sure that all the other authors are in agreement about the contents of the paper before submission. They are responsible for gathering all of the necessary information about each of the authors on the title page. Most of the following principally concerns the corresponding author. If thats not you, then you get an idea here of what is going on. Uploading your ms to the editorial management software requires time and preparation. Give yourself a good couple of hours for this process, as it can be frustrating. Friday afternoon might not be the best time. You may well need to refer back to your advisor and any other authors if you dont have their relevant information (see 2c). Once submitted to the system, your manuscript is usually checked before being passed to the editor. You may get it sent back if the meta-data is wrong. As corresponding author, it is courteous at this point to send a copy of the submitted version (usually the journal provides a pdf of the submission) to all of the other authors for their records. Inside the management systems, there are various workflows, and here Ill describe something typical, although others do exist. Once the editor (often Editor-in-Chief) has your ms, they will decide which Associate Editor (AE) will handle it. The AE should read the ms and may reject it if they feel that it wont make it through review. An AE rejection isnt great as they dont always have the best experience in knowing what will and what wont make it through. The editor usually has more experience. Hopefully, this wont have taken long (1-2 weeks) and so wont be very painful. This rejection may be fair or unfair, but its done and theres nothing much you can do except return to step 2 (above). Normally, your ms will be sent out to review and you can expect to wait 4-6 weeks (good), but sometimes up to 3 months, for a decision. If its away for over 3 months, you should definitely make a query on the editorial management system. Unsurprisingly, authors feel more unhappy with the review results the longer the process takes (Jiang 2021). Once back from review, youll get an email from the editorial management system with the decision. If its Rejected, take the comments of the reviewers on board. Think about it for a couple of days, and then set about revising the manuscript. However unfair you think the reviewers have been, there should be some important messages for you to consider carefully and discuss among the co-authors before going back to step 2. Reject and resubmit: This is a category that means you need major revision, but the journal doesnt want the time that it takes to do this on their stats. In many journals, this result has replaced major revision. Back to step 3 with a track changes manuscript and response letter to reviewer comments. Major revision: essentially the same as 6b. Both 6b and 6c result in your ms being reviewed again. Youll need to carefully prepare both the ms and the response to reviewers as the reviewers will see both. Back to step 3 with a response letter. Minor revision: is unusual at this stage, but your ms should now only be assessed by the AE, so you should address your responses to them. Accept without revision: is practically unheard of. Possibly, your ms has already undergone some peer review (maybe as a preprint or in another journal). However, if you get this result after the first round of peer review, its time to eat cake. If you are resubmitting, aim to prioritise this to get it done in 2 to 3 weeks if possible. The reason is that the same reviewers are likely to be willing to look at your ms again within a month, and will remember all the points that they made. Similarly, the AE will remember all of the issues that they had. Its hard to stress how valuable this is, as keeping it all fresh will result in a swift response. If you dont or cant manage to get your responses back quickly, you might expect a rocky ride through the review process when you go back for the second round. The reviewers you had before might not be available, but the AE will be obliged to have at least 2 reviews again. This means that you may get new reviews. New reviewers are likely to throw up new issues, and could result in your ms getting rejected at this stage, or that youll have another major review decision, sending you back to step 3 with a track changes manuscript and response letter to reviewer comments. This drags the whole process on for much longer and reviewers and AEs are likely to look less favourably at your ms. A better result is when there are only minor revisions. In this case the ms is simply bouncing between you and the AE and even if this happens more than once, its fine as long as you can keep the response time reasonable (within a couple of weeks). Hopefully by now your ms has been accepted, and you are entering the last stages of the process. Your accepted ms should be sent to the publishers for typesetting, and you can get the proofs back very quickly (for some publishers). Most demand that the proofs are returned very quickly (often within 48 hours), and you should try to prioritise this if you can. If you can, please also send it to the co-authors. The more eyes the better at this stage for spotting errors. Dont expect to be able to change a lot in the proof process, its really just for catching errors. Carefully check all figures, tables and legends. Its not unknown that typesetters cause problems when they make proofs (tables can be disasters). Check the acknowledgements again and make sure that your funders are included. You should always acknowledge your funders for their support. I also suggest adding in the reviewers (even if anonymous) for their help in improving the ms. If you (or a co-author) spot a fundamental error with your data or analyses at this point (or any of the other steps above), you should discuss it with all co-authors and decide what to do. Its better to withdraw the ms than to have to retract it later (see part 4). The peer review process is not ideal, but it is worth remembering that its there to help improve your manuscript. Different reviewers have different styles of review, and these tend to be culturally distinct around the planet. You should be aware that apparently rude comments by reviewers might simply be attempts at humour (see chapter below). Try not to be disheartened by anything that you read in a reviewers comments. You never know the conditions that they were in when they read your manuscript, or what their day was like. This is also a point to consider when writing a review for a paper. "],["peerreview2.html", "Chapter 19 Expectations of peer review? 19.1 What are peer reviewers asked to do? 19.2 What are reviewers not asked to do?", " Chapter 19 Expectations of peer review? Once your manuscript is submitted, you can expect that you will receive a written review of your manuscript. Sometimes, you may receive an annotated manuscript back (very annoying), but you can interpret this in your own way - most likely as minor comments. It is widely acknowledged that peer reviews are likely to be biased in some way, and so you should expect this of every review that you get. Try to look over these biases and aim to receive the wisdom that they likely also contain. 19.1 What are peer reviewers asked to do? The peer review report consists of three major parts: 19.1.1 The review Peer reviewers should sum up the manuscripts in their own words to demonstrate that they have understood the contents. This is important because being able to summarise what you have read demonstrates the reviewers comprehension. If the reviewer gets this summary wrong, then it is either a flag to the editor that they lacked the necessary comprehension to make their review meaningful. Or, because there are two sides to comprehension, a flag to the authors that they failed to write their manuscript in a way that made it easy for the reader to comprehend. The reviewer should then provide a general critique including positive and any negative aspects of the manuscript. They should provide detailed information on exactly how the manuscript should be improved, including any significant literature that might be missing from the manuscript. Lastly, they can provide a list of minor comments along the length of the manuscript that require further attention from the authors. When I undertake this last part, I tend to do it with page and line numbers (which is one reason why submitting a manuscript with line numbers is so important. If the minor comments get too numerous, then I tend to stick with major comments. 19.1.2 What do good reviews look like? Good reviews are those where authors improve their manuscript. It may be that the good review doesnt immediately show the way on the first reading (although clearly the best ones should), but it may be that the authors require some work rethinking their manuscript before they understand the comments of a reviewer. I would say that usually on first reading, even a good review might not sound that good. 19.1.3 The myth of the shit sandwich The shit sandwich is where a review where the beginning and end are generally positive, while the very critical appraisal happens in the middle. Although the shit sandwich might be seen as a way for a reviewer to sugar coat their negative message, an analysis of PLOS ONE reviews by Eve et al (2021) suggests that some of the best reviews (think Minor Revisions) actually have this format. Here the reviewer will be positive in the outset and the summing up, but then in the middle have a set of issues that need correcting. Hence, they found that the shit in the shit sandwich wasnt that bad. In the same analysis, Eve et al (2021) found that truely bad (i.e. Reject) reviews could be bad at any point in their length. 19.1.4 The confidential comments to the editor Im not a big fan of confidential comments but sometimes they are warranted. The reviewers are provided with a box where they can write to the editor without text being seen by the authors. 19.1.5 Their opinion of what the editorial decision should be In many journals, the reviews are directly asked whether the manuscript should be rejected and resubmitted major or minor revisions. Personally I dont think that reviewers should be asked these questions as this is a decision for the editor after having read the reviewers comments and the manuscript. 19.2 What are reviewers not asked to do? In their analysis of PLOS ONE reviews, Eve et al [@-eve2021reading] found that reviewers are good at ignoring the directions that are provided to them by the journal. It is therefore necessary to be aware of what reviewers are not asked to do, because sometimes they do it anyway! 19.2.1 Peer review is not a trial by committee Those of you who have experienced manuscripts being critiqued at a book journal club will know that there are very few published papers that leave a journal club without having many negative critical comments. Instead peer review is conducted by an individual, on their own and with their own personal limitations. Peer reviewers are forbidden from sharing the contents of a manuscript with others, without permission from the editor. 19.2.2 Correct English grammar Its not the job of a reviewer to correct any faulty grammar on a manuscript. similarly it is not up to the reviewer to correct stylistic aspects of the manuscript. However, as English is such a subjective language, it is important that ambiguity is removed, and grammatical aspects can be important for this. I have noted that some reviewers have become quite obsessive about things like the Oxford comma - insisting that the Oxford comma should be inserted at every possible juncture. Eve et al (2021) call these reviewers peer copyeditors. They are likely to comment on your split infinitives and may be pedants for all grammatical concerns. I would say that it is up to you as an author to decide whether the suggestions from these peer copyeditors are warranted. At the same time, the comments from these same people might drastically improve the readability of your manuscript. 19.2.3 Tell the authors to cite their papers Sadly, this is something that a lot of peer reviewers do. At most, the reviewers own work can be cited, but only when relevant. 19.2.4 Tell them to cite other papers from the journal This also happens see chapter on Impact Factor often at the request of the editor. 19.2.5 Justify comments with their own beliefs and opinions Peer review should always be an objective critique of a manuscript. Its not really the place of the reviewer to express their opinion or their beliefs about a particular study that they are reviewing. Reviewers should stick to the evidence that theyre provided with. If they are not provided with sufficient evidence then they should draw attention to the lack of information rather than extrapolate to what they believe might be the case. Authors should be provided the benefit of the doubt and opportunity to respond to such criticisms especially when information is missing. Its unfair for reviewers to act as judge and jury. This is the job of the editor. 19.2.6 Assess aspects of the manuscript that are beyond their competence Some manuscripts are cross-cutting across several subjects or may contain analyses outside it with the experience of a reviewer. In these cases reviewers should not attempt to review areas that are beyond their competence. Instead they should bring these aspects to the attention of the editor when they are submitting their review. 19.2.7 Ignore what is good Is often thought that peer review provides only negative criticism (see Eve et al. 2021). This should not be the case as peer reviewers should also be able to accentuate the positive aspects of manuscripts that they read. Even if a manuscript is not considered publishable the positive attributes should be bought the attention of the editors as well as those that are negative. It is important for authors to understand what aspects of their manuscript are good. This kind of feedback from peer review will influence future versions of this manuscript as well as future studies from these research groups. "],["rebuttal.html", "Chapter 20 Responding to reviewers comments with a rebuttal 20.1 What to expect in your decision letter 20.2 What to do when you receive your reviewer comments 20.3 What if you dont agree with a reviewer? 20.4 When reviewers dont agree 20.5 What if you feel that your reviewer is being unprofessional? 20.6 Appealing against a decision that you think is unfair", " Chapter 20 Responding to reviewers comments with a rebuttal Peer review is the basis of guarding and maintaining quality in science. If youve just got a decision from a journal, youll need to respond to the comments. This to and fro between authors and reviewers usually doesnt exceed two rounds. As you approach the comments, there are several points that its worth bearing in mind. Reviewers comments can come across as harsh, upsetting, rude and even arrogant. While it isnt ok for reviewers to be rude, it does sometimes happen (see Part IV). I think that the reason why we find the comments so harsh is usually because we put so much effort into the writing process that it feels very personal whenever we receive criticism. Indeed, I think that there might be a correlation between how much effort you put in and how harsh the reviewers comments seem. Another study suggests that authors consider the competence of their reviewers to be closely aligned to the editorial decision (Drvenica et al. 2019). Just be aware that this is normal. Remember that the reviewers are humans, and they have sat down and given freely of their own time to read your work. The most important thing to be aware of is that all they had was what you had written. No background information, and possibly no information about the species or the system involved. They will be experts at some level, but perhaps not the type you might expect. Importantly, the editor asked them because they thought that their opinion would be of importance in helping them make their decision on your paper. This means that you also need to respect their opinion and comments, even if you dont agree with them or find them to be offensive, arrogant or even rude. Remember also that some apparent rudeness may just be a reviewer who has a sense of humour that you dont understand. There are lots of examples of this at ShitMyReviewersSay. So no matter what you think of each comment, you should respond to it in a professional and courteous manner that shows that you are a professional scientist. If you already know what its like to receive reviewer comments, but struggle to understand why reviewers say what they do, then its time for you to start reviewing papers. You can ask your mentor to mention you as a potential reviewer (especially if they are going to decline because they are too busy). But probably the best way to get started is to participate with your lab or journal club in the review of a preprint (see part 4). This has the advantage that you are not the sole reviewer, but will be in a group. Your group will get credit for their review (via a DOI). You will get to discuss the finer point of reviewing with your team. Especially, you will likely hear remarks that might come across as insulting or unprofessional and itll give you a chance to challenge these at source. Why do scientists make disparaging or unprofessional remarks to their colleagues in peer review? Whenever two or three scientists get together, you hear tales of recent woes associated with peer review. The retelling of such stories is all part of the collective, cathartic unburdening of what can be a traumatic experience especially when we put so much effort into each piece of work (see Hyland and Jiang 2020). Reading through a lot of these reviewers comments, I can see that there is an attempt at humour (see here). This humour is not appreciated by those who receive the reviews. Perhaps I understand the humour, because I also come from that same culture that dominates STEM, but that is not understood or even recognised as humour by others. Writing humorous reviews is unprofessional, especially if it is used to accentuate negative aspects. Needless to say, we could all do without unprofessional reviews. 20.1 What to expect in your decision letter When you finally receive it, the email will contain some stock text about the overall decision, some information about how to resubmit your revised version (if you have this as an option), and a time-frame. After the editor has signed off, you will find comments first from the Associate Editor (AE) who handled the review, and then from (typically) two reviewers, but sometimes three (or even more). Dear Mr Another: Thank you for submitting your manuscript entitled An appropriate title for a reasonable manuscript to The Best Journal. All manuscripts are assessed by a specialist member of the Editorial Board, who decides whether the manuscript is suitable for The Best Journal. Unfortunately, your manuscript has been rejected at this stage of the assessment process. Competition for space is currently extremely severe, and we receive many more manuscripts than we are able to publish. On this occasion it was felt that your manuscript was unlikely to be able to compete successfully for a space in the journal. Please find below the specialist Board members comments. I hope you may find these useful should you wish to submit your manuscript elsewhere. Sincerely, A.N. Earnest-Editor Editor in Chief The Best Journal Rejections are harsh, but totally normal (Day 2011). You will feel bad, and this is also normal. You will need to pick yourself up, and take your manuscript back and try again. Learn as many lessons as you can from your rejection and quickly move on. Certainly, never dwell on a rejection and feel that this is anything more than a minor setback. All of us have been rejected, and continue to deal with rejections throughout our careers. If you receive a Reject decision, then some journals will want you to submit to another journal in the same stable. Typically, these are Open Access No Impact Factor journals where you have to pay an, often hefty, APC to get published. This is rarely a good idea. The standings of these journals is (typically) not great, and youd probably be better off going back to your original list and selecting the next journal there. 20.1.1 Time take to receive your decision Usually, you will receive a decision letter (email) after ~60 days. This depends on the journal, editors and reviewers, but its worth checking with the editorial team after 60 days if youve heard nothing. Time to first decision in the Life Sciences was found to average 11 weeks and 25% receiving this within a month (Huisman and Smits 2017), and that sounds oh so slow, but this is relatively quick when compared to the 18 week average first response in economics. It is worth bearing in mind that authors generally feel more unhappy with the reviewer comments they receive the longer they have to wait (Jiang 2021), while fast turn around times produce more content authors even in the face of rejections (Huisman and Smits 2017). Clearly, the difference is in the resentment of time wasted, especially for a desk rejection, or even for poor or feeble reviewer input with a rejection. If you feel particularly unhappy about long waiting times, then you could consider releasing your manuscript as a preprint. Otherwise, theres little that you can do, and it can simply be bad luck when you have to wait a long time for a review. In my experience, every manuscript is different and its very hard as an editor to determine how long it will be to find reviewers, or how long those reviewers will take to produce their reviews. Just because reviewers accept to undertake reviews, does not mean that they will do them timeously, or even at all. After a failure to review on time, a good editor will follow up to seek out other potential reviewers. But there are other reasons why decisions may take time. In the case that the editor found no reviewers after looking for some weeks, one option is for them to make a desk reject and encourage resubmission. In the rejection, they may point out a number of potentially minor faults. For the editor, it takes the heat off of their desk. They may not be allocated the new ms after resubmission. For the authors its just frustrating. If you suspect this has happened then consider another journal (with a clear editorial stance on peer review), or provide more potential reviewers. It is worth remembering that certain times of the year are likely to take longer than others for peer review. Editors find it more difficult to find reviewers in the summer months when many biologists are in the field or on holiday (remember that summer occurs at different times in northern and southern hemispheres). The start of the academic year is also a particularly busy time for most academics (editors and reviewers), and you might expect waiting longer (although academic years start at different times in different countries). In general, academics are busy and finding reviewers is difficult (Perry et al. 2012). 20.2 What to do when you receive your reviewer comments Your reviewer comments will arrive in an email when you are busy doing something else. If you have time to read them the same day, then my suggestion is that you read without trying anything further. Remember to forward them to your co-auhtors as soon as possible. Simply read the comments and then close the email and mark it for further attention the next day. Your writing is very personal to you, and you might be surprised at just how hurtful it can feel to have someone critique your writing (and your experiment) without holding back. If youve not experienced this before, then prepare yourself. No matter how much effort you put into your text, sending it out for peer review is a really high bar. Make an appointment with your co-authors so that you can discuss the comments together. Whether good, bad, or bizarre, it is best to set aside some time to read through the comments carefully, so that you can respond. Dear Ms Another, Your manuscript has been reviewed for The Best Journal by Dr. Fitz Wilklewood, one of our Handling Editors, who made a recommendation to reject this manuscript with which I concur. As a result, I am unable to accept your paper for publication in The Best Journal. However, both Dr. Wilklewood and the reviewers felt that there were exciting and interesting aspects of the work and that if you could address the concerns outlined below, this manuscript could be appropriate for The Best Journal. Thus, I would be willing to entertain a resubmission of this manuscript if you can address the concerns described below. If you choose to resubmit, the revised manuscript will be assigned to the same Handling Editor for further review. This decision does not guarantee that a revised manuscript will eventually be recommended for acceptance; indeed a significant fraction of resubmissions are rejected after revision. The comments from Dr. Wilklewood and the reviewers are provided below. If you wish to submit a greatly revised manuscript, address the points raised in the reviews and then resubmit your manuscript by 28 Apr 2021 to https://www.managereditorial.com/. Please provide a detailed response to the previous reviews in the respond to reviewers text box. I expect to return the manuscript, along with your response to the original Handling Editor. Please review our detailed author instructions for proper manuscript formatting: The Best Journal Author Instructions General (Manuscript guidelines) and The Best Journal Author Instructions Figures (Artwork instructions). These files are located at Please make sure to submit editable source files (e.g. Word). We will return manuscripts which do not follow these guidelines. Thank you for considering The Best Journal as an outlet for your research results. If you choose not to undertake these major revisions, then I wish you the best of luck in finding a more suitable outlet for your work. Sincerely, A.N. Earnest-Editor Editor in Chief The Best Journal Comments to Authors from Handling Editor and Reviewers: Handling Editor: These are the comments from the handling editor - in this case the esteemed Dr. Fitz Wilklewood. If you dont get any comments from the handling editor, I take this as a bad sign for the journal and their editorial regime (see chapter below). Reviewer #1: Comments from reviewer number 1 follow. The order of the reviewers is not really of any consequence, although it does reflect that order in which they accepted to undertake a review. Hence, most often Reviewer #1 will be more positive than subsequent reviewers. The evidence for this comes only from my experience, and if theres not been a study done yet, then I think that it should be. Reviewer #2: Of equal importance to Reviewer #1, but numbered just to make it easier for you to respond to. Reviewer #3: You may or may not get three reviews. The reviewers are usually given two boxes to write comments in. One pertains to the comments that you receive in your letter, and the second are confidential comments to the AE. Remember that the AE is acting on both of these sets of comments, and so the decision may reflect something that is said in confidence. This is not really in the spirit of transparency for peer review. The best peer review systems are open and online. Once youve found the time in your week, sooner is better than later, sit and read the comments again. Normally, they will sound much better, and less harsh, on the second read (if not, try third or fourth). They will seem far more approachable than when you first read them. Most reviews will have a set of major (when applicable) and minor comments that you need to address from each of them. Try sketching a few responses down to the major revision comments before your meeting with your co-authors. The easiest way to do this is to copy all of the comments from the email (together with those of the editor), and paste them all into a fresh document. Use a different colour text or a clear set of symbols (e.g. &gt;&gt;&gt;&gt;) to indicate which text is your responses and which is the reviewers or editors. Or number each comment and reply. If it isnt clear enough, then the editor may well get confused about what is the comment and what is the rebuttal. One of the best ways Ive seen of doing this was to make a table with all the comments in one column (each on a separate row), and the author responses in a new column. Sketch out your responses to the major comments, and use a tick if you are happy with making the suggested minor comments. If there are comments that you dont know how to handle, simply leave them with a question mark. By making this start before you meet with your co-authors, you will have an idea of what is likely to be difficult to tackle in the revision. Even if youve received a rejection with reviewers comments, its well worth having this same meeting with your co-authors so that you can decide together what to do next. Skipping on comments from reviewers during a rejection appears to be very common (Crijns, Ottenhoff, and Ring 2021), but is a very uncollegial way of moving forward. I have personally reviewed manuscripts that were rejected, only to see them again as a reviewer in another journal with all of the same errors, even down to ignoring relevant publications. Make a plan of how to handle all of the comments, or where to go, what to read or who to talk to (perhaps another co-author), to sort out those you dont know. Decide whether you need to send out the journal decision to co-authors now, or wait until you have your rebuttal ready to circulate. For me this decision is largely based on how much time the revision is likely to take: if its quick, rather send the revision and rebuttal together with the decision. Next, when you sit down to write the rebuttal and revise the document, you need to make sure that you have pressed track changes on the submitted version of the manuscript. I find it easiest to have both the rebuttal letter and the revised manuscript open side by side on the screen. As you revise the manuscript in response to the comment, make a note to mark that its done in the rebuttal letter. Mark any comments that you dont do. Your revision is written as a rebuttal to the editor. While you dont write your comments back to the reviewer, it is worth bearing in mind that the reviewer is likely to read them. Three watchwords should be your guides for your response to the reviewers: professional polite precise In addition to these, make the entire process easier for everyone by: Do make a note of the line number where the revision is made (note that these can shift around in the revision If you have reworded the text, do copy and paste that rewording into the rebuttal using quotes and corresponding line numbers. Simply use a word like done to indicate changes on Minor comments. Do be polite with your responses, but you dont get any extra points for wordy thankfulness or praise. So keep it succinct and to the point. Signal that you agree with the comment and that you have made a change to the text. Reviewers sometimes use a chatty style, and it may appear to you that they are asking you a question. For example, they might ask you exactly how accurate a piece of equipment you used to measure your organism. Intuitively, it seems like the right thing to do is to simply answer them in the rebuttal. But they expect you to make a change to the ms, and not simply to give them an answer in the rebuttal. Otherwise, it would have been pointless in making the comment. Do bear in mind that your reviewer is a human, and was likely operating under less than ideal conditions when reading your manuscript. They could have been getting constant interruptions. They could have been reading it after having read another three manuscripts. They could suffer from insomnia and read it in the middle of the night with no sleep for a week. Give the reviewer the benefit of the doubt. Do remember to thank your reviewers and editors in your acknowledgements. Theyve been working and doing the best for your manuscript without any thanks other than what you will give them. So give them a boost and help make their day that much brighter. 20.3 What if you dont agree with a reviewer? Most of the time, reviewer comments are sensible, helpful and genuine attempts at improving the quality of your contribution. If you dont agree with particular points, try skipping them and moving ahead with the easy points or those that you do agree with. Discuss any points that you dont agree with your co-authors. Try to get another perspective on the comment. Do your best to try to see the comment from the reviewers standpoint. For example, a reviewer might ask for details on a point in the methods, but they are mentioned in another section of the methods. This is a cue for you to add a flag to that point in the manuscript. For example, write: see section 2.2.3 for an explanation of how this was done. If a reviewer has made a comment that says that they dont understand something, this means that you need to make a change in your text so that the text is easier to understand. If they dont understand, then it could be that more people dont understand and you want your text to be understood by all people that are reading it, so make a change. If you and your co-authors dont agree with the reviewer, then make it clear what exactly you dont agree with. Again, try to see it from the reviewers perspective and write a courteous and clear explanation of why they might have misunderstood or misinterpreted what was written. Back up your comments with citations, even if these arent cited in the paper. Provide full references for any citations you give. The more thorough your explanation, the more likely the editor will side with your perspective on the point that you dont agree with. You may find that you want to include some of this text in the ms, or that you offer to provide it in the Supp Info (if theres a word limit on the ms). Remember that the reviewer is likely to read exactly what you write in your rebuttal. Your job is to professionally explain why you dont agree. Forget any of the emotions that you might believe to be there. Revert back to professionalism, because you are a professional. 20.3.1 When reviewers ask for additional analyses or experiments It is not unusual for reviewers to suggest additional or different analyses, or even experiments. It will be important for you, as author, to differentiate between requests that are reasonable and stay within the original bounds of your stated hypothesis, and those that do not. Because there are so many ways in which to analyse data, it is not unusual for a reviewer to suggest you use their preferred method over the one that you submitted. Such suggestions are made with good intentions, and unless there are clear reasons for not undertaking these analyses (such as you have already preregistered your study or they are inappropriate), you should attempt the analyses and then make a call on whether or not they improve your work. Even if you decide not to include the results, you can present them to the reviewer/editor in your rebuttal, together with your reasoning for not including them. It is important to be aware of p-hacking even in your rebuttal. Improving your work through peer review should not result in changing the focus of your work, or even including a co-variate that you did not plan to use. Many authors feel pushed into conducting extra analyses for fear of having their manuscript rejected (Hopewell et al. 2018). Although its impossible to determine every potential scenario here, if your work was well prepared and conceived, you should not need to conduct extra experiments and there should be journal policy to prevent this. Exceptions might include when journals ask for independent experimentation to determine a mechanism detected (or specualted on) in the manuscript. Including multiple lines of evidence is likely to have your article accepted with higher impact. You may or may not have the option of doing this kind of extra work, and may therefore need to settle for another journal. In all cases, discussions with your co-authors should help you decide on the best course of action. 20.4 When reviewers dont agree Normally, you will have two reviews (possibly three depending on the journal policy) and comments from the Associate Editor (AE). The AE acts as a judge given the opinions of the reviewers, and so if the reviewers disagree, the AE should suggest the correct direction for you to take. Sometimes this means that the AE will consult a third reviewer (and occasionally even more reviewers). See the chapter below on why it is important for editors to read your work. If the AE gives you no direction (as is increasingly the case) then make this decision with your co-authors and indicate to the AE the conflict between the reviewers and the reason why youve chosen the direction you have. 20.5 What if you feel that your reviewer is being unprofessional? If you really feel that a reviewer is being unprofessional, it is worth flagging this with the editor. I would say that Ive never had to do this myself, but I am aware that there is some unprofessional behaviour out there (Ive seen it on ShitMyReviewersSay). Discuss it with your co-authors, but here are two potential options: If its just one or two comments, then simply state that you dont feel that you dont know how to respond. Ask the reviewer to try again, or ask the editor to interpret the comment for you. If it is every comment from one reviewer, write an email to the handling editor and ask for their guidance. You should find their email address in the journal submission site. They will flag it with the editor and come back with a solution for you. 20.6 Appealing against a decision that you think is unfair From time to time, a decision comes from an editor that is clearly unfair. Ive had a few. As Ive mentioned before, scientists are humans and humans do have biases that manifest into their professional lives. This is the reason for double-blind review. Scientists in STEM are predominantly white and male, and express the views of this minority but powerful group. Their prejudices do manifest in their decisions, and it is important to push back against this when you feel that this is the reason for a decision. Most (good) journals will have an appeals process and you should look this up and see whats involved. While doing this, it is worth reviewing the journals policy on how they handle manuscripts; again good journals should have a clear policy. Of all the rejections and poor decisions Ive had on my manuscripts over the years, Ive only felt that decisions were unfair and worth appealing less than a handful of times. Normally, an appeal is made to the editor in chief. Be very clear about why you are appealing and what in the decision does not tally with the journals own policy. Remain professional and detached from the decision itself, and instead appeal on how the journals own policy was not followed. For example, a journal may have a policy that the editor will sum up the reviewers comments and use this as the basis for their decision. If the editor seems to have sided with one reviewer while not considering others, this can be the basis of an appeal. Any appeal should be agreed with your co-authors before sending it. "],["editors.html", "Chapter 21 Why should an editor read your submission? 21.1 Why is reading so important? 21.2 If you are going to be an editor, then you must be prepared to read 21.3 Ive been on the other end too 21.4 There is worse that goes on in economics 21.5 Summing up on editorial blunders", " Chapter 21 Why should an editor read your submission? There is a worrying increase in poor editorial decision making, without any basis, because editors are not reading submissions. When a manuscript is submitted to a journal, the submission goes to either the editor-in-chief or a handling editor based on the key words or journal section implied during submission. In some journals (like PeerJ) the submissions are offered up to a whole group of editors who can take their pick. It seems that the next thing that happens is that the manuscript is sent out for peer review. But stop. Thats not correct and its really not a good way to proceed. Before sending it out, the designated handling editor needs to read the submission. 21.1 Why is reading so important? The title and abstract really dont allow a handling editor to decide whether or not a manuscript should go out to review. There are a lot of manuscripts out there that should not have been submitted, because their authors do not have sufficient judgement of their own or because they believe that there is a reason to just chance it. It is very important that handling editors read the submission, because without that they are moving editorial responsibility from themselves to the peer reviewers. Some years ago, I co-authored a series of articles (Perry et al. 2012) that were published across many journals about how peer review was becoming very difficult for editors because so few colleagues accept to do reviews. This was a problem then, and its still a problem now. Ive recently sent out manuscripts to more than 15 people before getting two reviews. That peers are not prepared to review, or in many cases even to respond to the request, is very poor. However, more recently Im experiencing a sharp increase in manuscripts to review that should never have been sent out. My time is precious, and its becoming quite expensive for my employers. I am happy to conduct peer review because it is an important part of the scientific publishing process, and I expect others to review my own work. However, I expect that any manuscript that I receive is worthy of my attention and time. If the handling editor has not read it, they cannot decide this and I really wonder what makes them think that they can send it to me (and presumably others) to read while they dont feel that they have time to do it themselves. Moreover, this appears to be a trend among younger less experienced editors (often associates) that have either not received any guidance in what their job as editor is, or they should not be editors. 21.2 If you are going to be an editor, then you must be prepared to read I must admit that Ive done it. Ive sent out manuscripts to be reviewed as I didnt have the time to properly read the article, but a superficial skim suggested that it seemed fine. Not good. Its embarrassing to handle manuscripts that should be rejected without peer review. In the case Im thinking of, once Id read through the manuscript later on that day, I realised how bad it was and immediately wrote to those Id asked to do the reviews and asked them not to. The article was rejected. I only do this if theres no science contained therein. Its horrifying how often thats the case, but Id rather take on this burden as an editor than burden two or three times as many others to make the same call. Sometimes, its not clear whether or not a manuscript will pass muster. Articles can stand or fall on good or bad single judgements of the authors. But misjudgements arent always obvious to editors. Thats why peer review is important, and thats why its hugely important for editors to send manuscripts to appropriate reviewers that have some expertise in a subject. For example, if I receive a manuscript about the calls of East Asian frogs, I shouldnt only send it to people who work on African frogs. Its really important that someone familiar with the animals reads the manuscript. This is because they might know something that others would miss. If they spot an error in the identification of the species call in the manuscript, the entire premise of the science might fall apart. As Ive discussed before, science is built on the work that others have done before, but basing your work on what someone else has written will mean that you have a good understanding of what they have done and how they have done it. Assumptions have to be made to get anything done, and its a good exercise to sit down with a published paper (or even a manuscript of a colleague or your own) and read through listing all the assumptions that are made. Physicists might have a very long list if they read a biologists manuscript, but with some practice you learn to see the assumptions that the authors have made when designing their experiment, or going out to the field to conduct their study. An incorrect assumption could lead to the entire manuscript losing its value. In my example above, the authors might assume that they had correctly identified the species when recording its call. Such assumptions should be backed up with museum and/or tissue bank accessions. But when they are not, the assumption that the authors are recording what they think they are, is vital. If this is placed in doubt, then the entire premise (description of a call to distinguish this species in the field) simply falls apart. In a case without vouchers, the assumption needs backing up by someone who knows the identification from another study, or without any foundation it becomes worthless. 21.3 Ive been on the other end too Ive submitted manuscripts to journals where the editor clearly never read the manuscript. Editors who have made a decision without any guidance of their own gives this away. If your decision comes as a single sentence that asks you to revise according to the reviewers comments, then you can be reasonably sure that your editor hasnt read the manuscript (and possibly not even the reviews). Its not surprising that the editors have little to nothing to say; without reading the manuscript, the reviewer comments arent really very helpful. Without reading, the editor has no idea whether the reviewer is biased or (as is sometimes the case) deluded. As an editor, you simply have to read. And if you dont have time to read, you shouldnt be an editor. 21.4 There is worse that goes on in economics If the above makes some editors in Biological Sciences look bad, then I apologise. Being an editor for a journal is a pretty thankless task and there is no financial gain to do an editorial stint. However, if youre going to do it, then you must do it well. The half measures that I describe above are simply not good enough. But biological journals are a huge cut above those in economics. Ive always had my doubts about economics as a subject. Rather like theology, its based on a fanciful construct that puts its own practitioners in positions of power when wed do just as well to flip a coin. In May 2018 I was pursued for some weeks by the International Journal of Finance and Economics to conduct a review of an article submitted there. Even though I raised the flag that I was not an appropriate reviewer, the editorial assistant (not the editor) still wanted me to conduct the review. Apparently, the system recommended me and this was enough for me to be selected. It appears that the problem of non-expert reviewers is on the increase. Consider this blog post from the authors of Retraction Watch who were invited to review papers on COVID-19! Essentially, this is the result of editorial management systems auto-suggesting reviewers, and editors not doing their due diligence to determine whether any of these reviewers is worthy of conducting peer review on that submission. Clearly, selection of reviewers must be done by the handling editor, and those people must be chosen based on their expertise (not lack of it). While editorial management systems might help editors, they cant replace diligence on behalf of those who are responsible for the upholding integrity of the peer review system. 21.5 Summing up on editorial blunders The way to get round making the kind of editorial blunders I describe above is to read the manuscript. The guidance of how to read a manuscript should be explained to editors when they take up the position. There is plenty of information out there on the internet, but the journals editorial policy should be understood by all of the editors (and preferably open to authors and reviewers too), and that should include reading manuscripts before sending them out for peer review. "],["now-that-your-manuscript-has-been-accepted.html", "Now that your manuscript has been accepted 21.6 The Version of Record", " Now that your manuscript has been accepted This part of the book gives you some things that you might want to do after your paper is accepted for publication. Much of this chapter is concerned with publicising the results and content beyond academia and for non-academic audiences. Even if you feel that there would be no interest beyond your academic niche, it would still be worth making some effort to popularise your study. 21.6 The Version of Record An important concept to understand in the publication of your article is the Version of Record (VoR). This is the final typeset version of your article that is published. In this millennium, the VoR had changed from a hard copy that was printed and bound into an issue of a journal into a pdf that appears at a journal website online. In addition, the VoR no longer has to belong to a volume or an issue, and is usually the first version available online (Haustein, Bowman, and Costas 2015). The VoR can appear online long before it appears in an issue or volume (i.e. without page numbers), but still be the VoR. 21.6.1 What does this mean? This means that if you wanted to make any changes to this first printed version (the VoR), youd need to publish a separate corrigendum. The date of the VoR has an impact on primacy for example in taxonomy, if there are two descriptions of a species, the earliest one counts as the valid one. "],["accepted.html", "Chapter 22 Once your paper is accepted", " Chapter 22 Once your paper is accepted The day your paper is accepted, tell your advisor and co-authors. If they are in the same physical location as you then buy a cake and celebrate with them at tea time. If cake isnt your thing, then find another appropriate treat for you and your co-authors. Its a great achievement and something you should share together. If you arent in the same location then make a plan for next time you meet together, even if thats only online. Remember to make sure that all of your coauthors have a copy of the accepted version of the manuscript. Sometimes referred to as a postprint, you and your co-authors should submit this to your institutional repository so that the article can be reached as Green Open Access by anyone who is interested in reading it. At the same time as your manuscript is accepted, or shortly thereafter, the publisher (if you are using a traditional style publisher model) will tell you when you can expect to receive the proofs. "],["proofs.html", "Chapter 23 Take your time with proofs 23.1 The DOI for your paper 23.2 Once you have a publication date 23.3 On the day you publish", " Chapter 23 Take your time with proofs The next step in the publishing process once your paper has been accepted is that it will go for type setting. Depending on the journal and the publisher this process can proceed in several ways. Typically you will receive a notification that your paper proofs already and that you need to check them within 48 hours. If you havent checked proofs before then it is important that you read the instructions from the publishers carefully. They should tell you exactly what to do and if you are unsure about anything then talk to your co-authors. Typically the publishers will send you a set of queries that relate to your proofs. They always ask you to check every authors name and affiliation. Other typical errors are that there are citations in the text that are not in the references. Or that theres literature in the references that are not cited. The process of checking the proofs is very important. Errors can creep in during the type setting stage. Pay special attention to the tables table legends and figure legends. You may also have the opportunity to change the size or orientation of figures if it looks like they are not well presented in the proof. Especially if the journal prints into columns they may choose to put your figure in one column instead of two. Another option is to have your figure in landscape across the whole page. Journals are generally pushed for space and so may refuse some requests for more room for larger figures. But you might get lucky if you make a good case. Although the proofs are the responsibility of the corresponding author, its good to get as many eyes on them as possible in order to spot any possible errors. Some journals let you know when proofs are likely to arrive, in which case its a good idea to alert your co-authors and ask them whether they are prepared to look at them. I usually suggest that you make all your own corrections first before sending them around. Many publishers want to proofs back in a hurry (typically 48 hours). If you dont have the confidence to correct proofs yourself, or cannot pass it around your co-authors within this deadline, then you can simply write back and ask for an extended deadline for your proofs. It is important to get it right, and much better than having to correct the paper. It is important that you make any corrections needed on the proofs. They are important to get right because once the proofs are submitted and the Version of Record is produced, any changes that you may want to make will require an official correction in the form of a separate publication. Probably the easiest way of doing proofs is to print them out and go through them with a pencil first. This allows you to take your time and youre more likely to spot errors this way than on the screen. However, some publishers will require you to submit proofs in an online system (effectively working with their LaTex document). You should still have an opportunity to print and take your time with the proofs though. Sometimes, there are a lot of problems with proofs, and you may not have the confidence that the publishers will make all the corrections as indicated. In this case, you should ask to see another round of proofs before committing. 23.1 The DOI for your paper section to be written 23.2 Once you have a publication date Once your paper is published you have an opportunity to publicise it yourself. There are lots of different ways to do this, see the next chapter. 23.3 On the day you publish This is a great opportunity to contact all the people who helped you in your study and send them a PDF of your paper. The easiest way to do this is to go to the acknowledgements section and write an email that includes everyone that is mentioned in the acknowledgements. write them a nice email in which you thank them for their help and explain briefly the significance of the paper. It is a very good idea to keep all of these people informed about your publication as soon as it is published. You really want them to hear about it from you first and not from somebody else. This includes contacting any authorities that have issued permits. You may also want to contact funders. "],["pressrelease.html", "Chapter 24 Writing a press release", " Chapter 24 Writing a press release Many of the same aspects that weve already discussed both in paper writing and in writing a popular article (see below) are similar when writing a media release. Try to make your text newsworthy. Remember that journalists are looking for new things thats why its called The News. Your press release must be about something that has happened recently. Theres no point in writing a press release about a paper that was published six or nine months ago. Its very unlikely that youll find anyone interested in writing something after that amount of time. Here are 10 simple steps to take when writing your press release: Choose your hook. The paper that you wrote may have several important findings. You are going to need to choose one easy to understand finding for your media release. Its usually quite simple to decide; take the thing that would most impress your Auntie Fanny. Write your headline. Like choosing a good journal title or a popular story title the headline should try to encapsulate the study perhaps with a witty angle. Dont make it too long, 8 to 10 words at most. Most importantly your headline should connect with a wide and general readership. Theres no need to get too fond of your headline because if they take your story news outlets are likely to want to write their own. Crafting the first paragraph is important. You need to sum up the study together with the finding (just the book). Even if your reader only reads the first paragraph they should have an understanding of what youve done and found. This paragraph should not be longer than 30 words. In the second paragraph you should state who you are and where you are from, both geographically and the name of your institute. Here you need to concentrate on getting across the information on why youre finding is interesting. A typical second paragraph might read: Dr Frankella Smith from FitsSimons University found a new species of lizard when bending down to tie her shoelaces last month. She published her findings today in the journal Cobblers Saurids. In the next two paragraphs you should simply explain more about the background to your story and why the finding is interesting. Dont be tempted to deviate from the hook that youve chosen. After reading these two paragraphs your reader should be able to answer the question: So what? Finally sum up your finding with a quote from you, the author. Either use the quote to emphasise the study, or you can try and humanize your findings. This means a way of connecting with the reader, especially if you feel that the rest of your texts wont: I never expected to find such a pretty lizard in my shoe, said Frankella. I was flabbergasted when it turned out to be new to science. Include your name and contact details of the person that the press should contact in order to find out more about the story. Give the full citation to the paper with all the author names and the journal name plus a link so that any journalist can find the full text online. Include one or two photographs or relevant graphics that the press can use. If they are not taken by you then make sure that you have permission to use them. If you can, include a picture of the sunny organism, or even better of you with the study organism. Seek feedb ack. Your advisor is, as always, a fountain of knowledge in this regard, and you should always show them a copy before releasing it. Also dont forget to send the press release to your universitys press office and ask for feedback. Those are the professionals and they should be able to help you. Of course, the better your press release is, the more likely it will be that people will write about it. Remember that it also matters a lot about the subject of your paper. The media are likely to be far more interested if your work is on dolphin communication than if you are writing about caecilian communication (just like your Auntie Fanny). Having said this, never be put off just because your organism or system isnt cute and cuddly. Try asking your non-academic friends about the newsworthiness of your press release and see what they say. "],["populararticle.html", "Chapter 25 Why write a popular article? 25.1 Here are some extra reasons why communicating by writing a popular article might be right for you: 25.2 Heres a quick guide on how to get started writing a popular article.", " Chapter 25 Why write a popular article? There are many reasons why it is important to communicate science beyond your own discipline and into the wider public forum. Primary among these is that in a society based on decisions made on the basis of science, it is our responsibility as scientists to make sure that we make the findings of our work, upon which basis political decisions are made, understood to the widest of audiences. I do not mean that we are sharing science pejoratively to an ignorant public, but instead as equals in our collective scientific society. We share with a wider public in the same way that we share with those who are used to reading a well reasoned newspaper article, or listening to an informed political debate. By sharing our work, we help affirm that decisions should be made objectively, and we make the most important connection by reaching out to the rest of our society and to join them in the scientific project. 25.1 Here are some extra reasons why communicating by writing a popular article might be right for you: Inform tax-payers who funded research what you found Increase profile of your work and you as a researcher Reach other researchers (who also read popular articles) Reach other stakeholders like practitioners or policy makers Open more doors to other potentially cross-disciplinary work Gain new insights into how your work appears to the general public Public communication is a key part of social responsibility, quickly becoming a key aspect of an academic career Maintaining and furthering the Scientific Project The sooner that you come to terms with the need to communicate your work more widely, the more comfortable you will be when you are contacted by a reporter, a vlogger or someone from TV or radio. 25.2 Heres a quick guide on how to get started writing a popular article. 25.2.1 Whats the hook? Your popular article will not be the same as your chapter or paper. You should plan to have a single fact or message that you want the public to walk away with after reading your article. This is unlikely to be the same as the main result in your chapter or paper. When composing your article, you need to be single minded about achieving the understanding of your hook. The article cannot take any side roads or distractions, but must stick to the main point. Once thats done, provide the so what that allows the public to see the bigger picture, and maybe where you would go next. 25.2.2 Dont get complex or technical If your whole article hinges on something technical, you might have to start by explaining it simply. If you cant easily explain it, then this is probably the wrong subject for a popular article. Dont worry about leaving out key details, you can always refer the reader to your article if they want to know more. 25.2.3 Always refer to your published work Make sure that you always have some reference to your work thats published. Provide a hyperlink, but preferably give the full citation. Be aware that news items count towards metrics of your article, so be sure to link it correctly. 25.2.4 Pictures, videos and even sound files These are great to help readers engage with your work. Try to choose images that tell the same information as you have in your article. Try to remember that you will need these when doing your research as it will help later. "],["altmetrics.html", "Chapter 26 Altmetrics from traditional and social media", " Chapter 26 Altmetrics from traditional and social media In recent years, more emphasis has been placed on the way that scientists communicate their work. Many institutions now consider the degree to which scientists communicate their work as one of several key performance areas on which they are judged. Because administrators are always looking for simple solutions to evaluate the work of many different types of academics, commercial solutions to measuring the degree of communication for each publication have sprung up. The most ubiquitous of these in biological sciences is altmetrics (Priem, Groth, and Taraborelli 2012): alternative metrics that aim to measure activity on the internet through social media (e.g. Twitter, Facebook), online reference managers (e.g. Mendeley, Zotero) blogs and news outlets. Because of the immediacy of these activities, altmetrics tend to accumulate much faster than traditional citations, giving a near immediate impression of the interest generated in an article. A prominent company producing altmetrics for many biological journals is Altmetric. The whirls they produce, known as Altmetric badges are coloured to show the proportions of different media that have been scrapped from the web (Figure 26.1). FIGURE 26.1: In this example, a paper by Baxter-Gilbert (2020) was covered by many Tweets, news outlets, some blogs and a Facebook mention. Altmetric provides an overall score, but different types of mentions are not, so a news outlet is awarded a higher score than a tweet. Although this paper did not garner interest due to a charismatic species, the story was of general interest to the public as it centred on island dwarfism. In biological sciences, there is a traditional bias in media coverage towards species with higher charisma (Ducarme, Luque, and Courchamp 2013). This means that if you work on whales or roses, your work is likely to generate much higher altmetrics than if you conduct equivalent work on phasmids or grasses. Traditional media is starting to make an effort away from only reporting on science with charismatic species, but they are driven by a public with insatiable demand for kittens and flowers. There is a lot that you can do to improve the level of your altmetrics. I have provided this information elsewhere in this book, see preceding chapters. As communication is becoming so important in the careers of scientists, then Id suggest that you remain aware of altmetrics and how they are used by your institution. Be aware of how to influence and increase your score. For example, if you and your friends tweet about your article, make sure that there is a live link to the article on the publishers website. Similarly, if you are contacted by a news outlet about some of your research, you can insist that they place a link to your paper in their article. If the Alemetric scraper cannot find coverage on your paper, you can inform them here. "],["continuing-your-career-in-academia.html", "Continuing your career in academia", " Continuing your career in academia There is plenty more to know about the world of publishing and using the impetus that you have built up in order to further your career. In this last part of the book we will look at some of the remaining obstacles and ways in which you as an individual, as well as the community of academics, needs to overcome in order to improve our scientific project. "],["openaccess.html", "Chapter 27 Is Open Access good? 27.1 So what is open access? 27.2 So does that mean that these journals are now free? 27.3 Nature Publishing - pay for review 27.4 We need a new model for publishing without publishers", " Chapter 27 Is Open Access good? Open access appears to be a great initiative that acknowledges that everything should be free to view. Neither scientists nor the public that fund them should be barred from accessing the knowledge that they produce. What could be wrong with this? 27.1 So what is open access? I have covered the many different kinds of Open Access (OA) elsewhere in this book (see part 4). Here I concentrate on the fiscal implication of OA. Someone needs to pay for the work done. Who should pay and how? Open access is probably one of the best scams that the publishers have come up with to date. Now the scientists pay for making their own content open for anyone to read. They pay a once off fee to the publishers to typeset the manuscript and host it on their site without a paywall. And how much do the publishers want for this service. Prices start from USD 1000 and go up to around USD 12 000. More frightening, and evidence that publishers are simply taking advantage of scientists, is that prices increase with the Impact Factor of the journal (Gray 2020), although the costs involved to the publisher remain static. The money comes from the funds that would otherwise be reserved for conducting science. So now the money for research goes directly into the pockets of the publishers upfront. Money that ultimately comes from you as tax-payers goes directly to publishers. Still happy? 27.2 So does that mean that these journals are now free? Mostly no. The majority OA model (hybrid OA) means that a minority of articles in these journals are free, but the universities are expected to subscribe to those same journals at ever increasing prices because much of the rest of the content is still behind the paywall. This is because most authors cannot afford to pay the exorbitant fees charged by the journals (although some countries now have this payment as mandatory - PlanS, they and their scientists are still in a minority). There are some journals that are entirely open access (gold OA). These are (almost) exclusively online and have never been part of traditional packages that university libraries spend so much of their budget on. Hence the fact that they are entirely free does not impact library budgets. As a scientist, it will make an overall increase to papers that you can access. But paying for open access has not reduced the cost of access to scientific journals for libraries. This cost constantly goes up. Hybrid OA was a brilliant scam dreamt up by the publishers, because for much of this content we pay not twice but thrice (Buranyi 2017)! 27.3 Nature Publishing - pay for review The Nature Publishing Group has now proposed to go one step further: pay to submit your paper for review! In this new twist on the OA scam, the exclusive Nature publishing group is offering a discount to their new USD 11390 OA charge if you pay USD 2665 upfront before review. In this case, you will have the benefit of being told that your manuscript (most likely) is not publishable in Nature, but you can pay some more money to them in order to publish in one of their other journals. The most lowly (Nature Communications) would be another USD 3160, leaving you a few hundred dollars short than if you had submitted there originally. Or you could be rejected outright, and your USD 2665 is, of course, non-refundable. Are Nature Publishing Group taking advantage of authors who aspire to publish in their exclusive titles? Yes. Will they use the money to plough back to the benefit of science, scientists and the taxpayer? No. Will the cover price of Nature go down when some of the articles inside are free to read? No. Will it be cheaper for libraries to subscribe to Nature? No. Will they line their pockets? Yes. Will they pay the scientists who conduct the peer review that they want to charge for? No. Can you see the common thread in the greed of publishers and the willingness to prey on scientists who need to publish in high IF journals for their career? If not, read part 5 again. For a lot of academics there is a trade-off: vanity for cash. We know that for a lot of academics, their vanity will mean that they are prepared to find the money (even if it comes from their own pockets). However, for as long as enough are willing to pay, we will continue to be exploited. Instead, we really need a new model for publishing. For some academics they will be paying directly for a chance at getting a job or getting tenure. The chances of these individuals reaching their goal from a privaledged institution then simply becomes reinforced. This is not a system that we should ever support, and one that we should do all we can to remove for the sake of transparency and equality in the greater scientific project. 27.4 We need a new model for publishing without publishers 27.4.1 The problem There are growing problems with publishers. Publishing has become very expensive for scientists, and the public who fund science. Many funders are now unwittingly funding publishers instead of science. Ive discussed the history of scientific publishing before (here), and explained how commercial publishers have had a role right from the very beginning. This relationship continues to the present day, but while the origins saw learned societies commissioning publishers and then distributing their content, today the publishers have climbed into the driving seat, conceiving and owning many of the current journal titles. This is not to say that there are no scholarly societies that still dictate terms to publishers (The British Ecological Society, BES, do this very well), but they are few and far between, and even when society journals are involved, the Goliath publishing companies easily outweigh any control that they might have once possessed (and Im speaking from personal experience - learn about the paywall). The result is that publishers have become gigantic corporations that now dictate to the scientists that produce, edit and review all of the content. They charge incredibly high fees to anyone who might want to read the publicly funded content. The budgets of university libraries run into USD 100 000s just to access content. The result is that many universities cant afford all of the content that their researchers need. Publicly funded content, and by that I mean that you dear reader are paying for the original science of the content in your taxes (yes, you all pay taxes, even if its only VAT), and then you pay a second time for the researchers (who themselves produced the content) to access the content. Who benefits from the fact that you pay twice? The publishers. Why arent you upset about this? Probably because you are unaware. But if you are upset, then join in the discussion to decide how to emancipate ourselves from the publishers who are merrily munching on through this publicly funded cash cow. 27.4.2 What do publishers do? The publishers would claim that they do an awful lot. All they really do is pay for the layout and printing of journals. These days printing really means hosting electronic pdfs only, as theres very little paper thats printed, and you can be sure that paper subscribers now pay the extra cost of any additional fees. The layout from the manuscript (most often a MS Word doc) into a pdf does take some skill and talent, although nothing like what you might expect given how much the publishers charge. You can be sure that they dont pay much for this service as almost all layout is done in India, Bangladesh, Sri Lanka, etc. Quality can be good, but more often quality control is completely lacking. Most authors have stories of how manuscripts have come back mangled, although my own impression is that the worst days appear to be over. This is not to say that there are no skills in the publishing world. But the reality is that these days it is possible to use free software like Rmarkdown (Xie, Allaire, and Grolemund 2018) to write papers that can quickly and easily be made into any sophisticated layout using LaTex, the same language used by the publishers. Many journals allow submission of articles already formatted. I also want to make it clear that I am not condemning all those employed by all publishing houses. I have interacted with many excellent staff at publishing houses that have some of the worst practices. Its important to note that these staff do not get the fiscal benefit of the aggressive and unethical behaviour of their publishing companies. These profits are retained for the directors and shareholders. One might also question whether the sales reps of these companies who make deals with academic libraries dont also receive unethical bonuses for their undisclosed financial arrangements. But as these deals are not disclosed, who would know or admit this? 27.4.3 What is publishing then? Once publishers have printed the manuscript, they publish it by placing it behind a paywall on their website. I would be the first to admit that there are massive costs in doing this properly, and big journal companies have invested a lot to do this very well. The electronic hosting of journals is (in my opinion) truly excellent, except for that paywall. However, once theyve set this system up, adding another 10 or 20 journals comes at practically no cost compared to the revenue that each one can be expected to gain. To get behind that paywall, university libraries need to subscribe. Publishers bundle journals together and sell subscriptions at very high prices. If you are inside the university IP address, this access should be seamless. If you are outside, you might need to log in through your universitys library. There are other tactics for getting around a paywall (see part 2). So far, the publisher hasnt produced any content. The scientific content has been produced by the scientist at the cost of the public purse. The editing and peer review (see part 4) has all been done by the scientists, which has also cost the public purse but has been completely free to the publisher. OK, so there are some small costs associated with manuscript handling software subscriptions that the publishers normally pay. The publisher has also paid for the typesetting (although theyve done this as cheaply as possible - see above), and theyve paid for the servers that distribute the pdfs maintaining that all important paywall. What else? Nothing else. Now they simply charge everyone to look at the content (and because its by subscription), actually charge everyone whether or not they are looking at the content. Bergstrom and Bergstrom (2006) showed the difference between the costs of subscribing to society journals in 2005 was US$ 0.29 while for profit journals cost US$ 1.42, irrespective of any degree of quality. Fifteen years on, most society journals have now been captured by for profit publishers and now we all pay the higher price. Open access is one of the best scams that publishers have come up with But dont take my word for it. Read the excellent article by Stephen Buranyi (2017): Is the staggeringly profitable business of scientific publishing bad for science? In it, Buranyi makes the point that the profit margins of academic publishers are in excess of 40%. Something that even drug dealers, pimps and the mafia struggle to achieve. This situation seriously needs to change. 27.4.4 Are you convinced? If you are convinced that we do need a new model, then I suggest that you read about Overlay Journals. Here is a system that puts full control back in the hands of the academics, and potentially academic societies. As the authors are responsible for applying a style file to their accepted LaTex document, there is no need to pay for layout. The cost of maintaining the articles is met not by the journal, but by preprint servers - most of which are based at academic institutions. "],["problempeerreview.html", "Chapter 28 The problems with peer review 28.1 Ad hominem attacks 28.2 Demonstrated biases in peer review 28.3 All reviews are not equal 28.4 Decisions rest with editors 28.5 The social side of peer review 28.6 Fixing peer review", " Chapter 28 The problems with peer review There is already a lot covering peer review in this book, and I have placed this chapter last not because it is the least significant, potentially it is the most significant, but because I think that it is important that you appreciate exactly what peer review is, and to some extent experience it, before you begin to consider the problems with the peer review system. At the heart of the problems with peer review is that individual humans are themselves biased. Because peer review relies on a small number of individuals providing their assessment of a manuscript, it is quite likely that these biases might align, and that the manuscript is rejected along those lines, rather than being considered along purely objective lines. This likelihood of aligned prejudices comes about because the pool of people that conduct peer review in biological sciences, and in many other disciplines, is mostly white, western (i.e. Europe and North America) and male. These people hold a very similar cultural set of biases. Some people have argued that peer review is untested and that the effects are uncertain (Jefferson et al. 2002). Perhaps more worryingly, studies designed to test peer review (by deliberately sending out manuscripts with errors) have shown that most reviewers are unable to find all errors and some find none (Rothwell and Martyn 2000). If peer review was effective, then reviews of grant applications should closely align with the productivity of grants given. Fang et al. (2016) found that percentile scores awarded by peer review of NIH grant applications were poor at predicting the the productivity of &gt;100 000 grants awarded. Essentially, the major problem with peer review is that it is conducted by humans, and that like humans in societies everywhere, reviewers tend to have their own set of biases. The above sections should have given you some idea about the frailties of the peer review system. 28.1 Ad hominem attacks One of the shocking results of a very large study of peer review of PLOS ONE articles is the large number of comments that are written directly attacking the authors as a group or personally (i.e. ad hominem attacks, see Eve et al. 2021). This should not happen. Reviewers should be confining their objective comments to the work and its presentation. However, this is an aspect of peer review where authors (especially the corresponding and leading authors) will need to acquire a thick skin, because unprofessional comments are made to people across gender and racial groupings, but especially toward traditionally underrepresented groups (Silbiger and Stubler 2019). Sadly, these same groups feel that such comments disproportionately impact their productivity and career advancement (Silbiger and Stubler 2019). Reading comments that are sent to other authors can be cathartic as these allow you to see that everyone receives such negative comments. ShitMyReviewers is a good source of these, or see Eve et al (2021), or Silbiger and Stubler (2019). When ad hominem attacks are made, it would be good if editors openly and explicitly identified these as bad behaviour. It would certainly improve the understanding of authors if editors intervened when such ad hominem attacks are made. This would not necessarily involve deleting these comments, but directing authors to ignore the same. Why do academics make all of these terrible comments? I cant pretend to know the answer for all of the cases, but I can speak from personal experience that time is at a premium, and time spent reading and reviewing manuscripts tends to be quality time. If these manuscripts are not of a quality that will pass peer review (i.e. will be rejected), then this feels like an abuse of professional time - especially when editors should have spotted the same mistake in their first reading. Editors that fail to see manuscripts that should be rejected do the reviewers a dis-service by increasing the amount of work for everyone (more people and more time is involved). Resentment and frustration may follow on the part of reviewers that manifests itself in the form of ad hominem attacks. 28.2 Demonstrated biases in peer review Although Table 28.1 shows that many kinds of bias have been explicity demonstrated, thats certainly not their limit. Given that over 280 biases have already been catalogued (I encourage you to look through the online catalogue, many more different types of bias are likely to exist in peer review. Lets not forget that our biases have evolved because they are very useful. They exist as a way of shortcutting exhaustive decision making based on random variables. But maybe peer review needs some more of this. And perhaps that means that I should be tolerant when Im asked to review an economics journal, as these folk clearly werent exhibiting any biases associated with economists when they picked me (see below). TABLE 28.1: There are as many biases in peer review as there are humans that conduct them. This table demonstrates some of the biases that have been proven in studies. Bias for which there is evidence Study demonstrating bias Against female authors Tregenza (2002); Manlove and Belou (2018); Fox and Paine (2019); Budden et al. (2008) Against female reviewers M. Helmer et al. (2017) Towards author reputation, favouring acceptance of manuscripts despite poor reviews Bravo et al. (2018); Okike et al. (2016) Towards authors from more prestigious institutions, also called prestige bias Ceci and Peters (1982); Travis and Collins (1991); Tomkins, Zhang, and Heavlin (2017); Manlove and Belou (2018) ; Lee et al. (2013) Nationality and language bias Lee et al. (2013); Manlove and Belou (2018); Nuñez and Amano (2021); Link (1998) Confirmation bias (the tendency for journals and reviewers to favour significant results) Mahoney (1977); Fanelli (2010); Fanelli (2012) part I Perhaps the biggest problem facing those who wish to reform the peer review system is that it all starts with editors who are choosing reviewers. Those editors themselves have their own inherent biases. When they look for reviewers, they are likely to sample from within their own group of peers who have the same biases. Interestingly, bias (in general) is more easily perceived by early career scientists (Zvereva and Kozlov 2021). My experience is that soliciting reviews from people that I dont know and have no connection with (are outside of my field) are more likely to fail - they will say no, or they wont reply to the request (see Perry et al. 2012). This is even for academics that are publishing within the same area. Editors are the people who select reviewers, and inspection of most editorial boards will reveal that they reflect the same biases found in peer review. That is editorial boards are mostly made up of white men from Europe and North America. Rectifying this bias will take time and the acknowledgement that there is a problem together with the willingness to do something about it. In 2020, I have seen that there has been a big movement to redress the imbalance in science at all levels. I hope that this will continue into the future so that at least some of the biases in peer review will fall away. 28.3 All reviews are not equal If you are an editor and you receive three reviews from three researchers each suggesting something different, I have argued (below) that the editor should make their own decision on what action to take. But what if one of the reviewers is very negative and is a leader in their field? Should their review count equally with the others? Should their opinion be given more weight than the others? Of course, they could be using their position to influence their field, to make sure that opinions they hold are reinforced. Lee et al (2013) provide a good overview of the potential way in which influential reviewers could bias the peer review system. But the power sits with the editor to make this decision. Interestingly, Thurner and Hanel (2011) make the point using an agent based model (much as you might use in biological sciences) to show that only a small number of biased (for whatever reason) reviewers are needed to seriously degrade the quality of peer review, and thus the science system as a whole. The truth is that all reviews are not equal because some reviewers will put in more effort than others. Some will know the literature better. Some will be experts in the field that should be better placed to comment. These people are actually more likely to be less senior, PhD students or post docs. However, the importance for the editor is not to take account of the names of these people, their rank, their institution, or other demographics such as their gender, race or nationality. There are great editors out there who can do this, but my impression is that the majority fail. In this case, the only way to do this is for the triple blind method. Here the editors will invite the reviewers (by name) but the reviews that result will not be marked with the reviewers names. This will make forgetting who they are easier for 28.4 Decisions rest with editors A good editor will look at the reasoning in the reviews and make a decision in an unbiased way. A poor editor may be swayed by the perceived influence of an important reviewer irrespective of their argument. An increasing trend that Ive noticed is that editors will simply take a decision that follows the consensus of all reviewers: that is, they rate all reviewers equally (see also Rothwell and Martyn 2000). However, I would argue that this is also bad editing. Irrespective of the bias from reviewers, guarding the integrity of the process of peer review lies with editors. Today, editors are so busy with the other duties that their jobs as academics that their decisions are hurried and expecting them to take the time and space to overcome their personal biases might be a lot to ask. Instead, I think that it is time for the triple review concept to move into the mainstream so that editors can more easily not be led by potential biases of their reviewers. Another important problem with peer review comes when editors are not independent of authors. This can happen when an editor is known well by the authors. They could be in the same department or even in the same research group. Similarly, there could be a group of editors for different journals that have some quid pro quo arrangement, that might even be unstated, whereby their manuscripts do not undergo equal scrutiny to other manuscripts that are submitted. One could argue that whenever editors know the names of the authors, theres a possibility for the system to be corrupted. Despite all of the problems with peer review that are acknowledged above, we stick with it as the majority system in science. It could be that peer review favours exactly the same people who uphold the system and prevent it from moving into something more equal, just and fair. These are the editors and reviewers who have, for the most part, managed to make their careers inside the system, and have therefore mastered it to some degree. To you, dear reader, I can only suggest that you be aware of all the potential pitfalls with peer review, and never stop striving for something better. 28.5 The social side of peer review There is so much more to peer review than peer review. Being selected by an editor to review a manuscript represents an important standing amongst your peers. Literally it means that your opinion is valued. But theres much more to it. Doing a good job at peer review means that you improve other peoples work. This help can be valued to the point where those colleagues get in touch and want to work with you. That this can happen has now been shown in a study, and has been termed the invisible hand of peer review. 28.5.1 The invisible hand of peer review In another study, Dondio et al (2019) found that reviewers were more likely to provide positive review comments to authors who were close [3 steps] to their collaborative networks (see Adams 2012). In this case, a close reviewer to the author was calculated by a social network where a distance of 1 meant that they had co-authored together [1 step], co-authors of the reviewer may have collaborated with these authors [2 steps], or co-authors of reviewers and authors had collaborated [3 steps]. Surprisingly, they obtained this result even though the journal practiced a strict double-blind review system (reviewers didnt know who the authors were, and vice versa - see part 4). Referees that were not close [i.e. 4 steps] were more likely to provide more negative review comments. Those who helped authors more during peer review (i.e. asked for major revisions), were more likely to cite the manuscript, once published, and eventually more likely, than random, to publish with those same authors, even if manuscripts were eventually rejected. The authors concluded therefore that peer review may accelerate the potential for collaboration in science. This appears to be based on the fact that peer review can/should be constructive. Authors and peer reviewers are in fact collaborating to improve the quality of a manuscript. The process is orchestrated by an editor who can and should join in to improve the manuscript. Dondio et al (2019) make the point that this interaction is inherently social, and the peer review therefore has a function that develops relationships within and between networks of researchers. This evidence that peer review is a collaborative system towards the betterment of science is, to me, a sign that all is alive and well in science, and that peer review is acting as it should. However with any social network comes the fragilities of human bias. This means that while peer review may function well for some, for others it may more often than not fail. The bigger problem is that it might depend on your sex, the colour of your skin, the name of your institution, or your country as to whether you are selected as a potential reviewer (i.e. to join the club), or having submitted your manuscript, find that peer review is going to work for you. In addition, if you are never asked to review then you will never benefit from this network. Casnici et al (2017) tracked the fate of rejected manuscripts and showed that if the reviewers had several rounds of peer review before rejection, these manuscripts benefited later by being accepted to journals with a higher Impact Factor, and/or obtaining greater numbers of citations, even if the reviewers were instrumental in rejecting the manuscript. This suggests that in working collaboratively on a manuscript, reviewers are more likely to promote, cite and help authors. The alternative is that reviewers agree to re-review an article again because they see merit in it, even if they also see flaws. And having spent considerable effort on manuscript, they are more likely to remember and cite it. But this doesnt take away from the idea that reviewers and authors are collaborating in a social way. 28.6 Fixing peer review Fixing peer review will rest with the community of biological sciences, at the level of editors and the scholarly societies that they represent. To me, it is clear that we wont fix peer review by asking our peers to be less biased, or by asking them to be more rational. We should know by now that we cant fix people in this way. For example, Khoo (2018) found that there was little improvement in reviews after reviewer training courses, even when these included feedback on previous reviews submitted. Instead, we have to plot a course for peer review whereby we accept that reviews will contain bias and irrational content, and train those in editorial positions to try to spot these, instead of falling victim to them. There are lots of ways in which to do improve editorial oversight. My intuition is that the crux is to find a way that makes it more efficient and objective for the editors. For example, to try to pin down reviewers on where they find fault and exactly what that fault is. There is a difference between: insufficient information to decide whether the experimental design was faulty and needing this clarified before a decision can be made. and finding a fundamental error in the experimental design such that the manuscript can be rejected and insufficient power (in replicates or sampling) to reach the conclusion generated in the manuscript. A manuscript having each of these outcomes should have different fates: The first is Reject &amp; Resubmit, the second is Reject, while the third may warrant either major/minor revisions (depending what else is problematic), or movement to another journal. However, although the minority of peer reviewers means that at times prejudices and biases will align, a more inclusive world might mean that they diverge, prompting more differences in opinions about what should happen to manuscripts. Given that it is already quite difficult to find enough reviewers, simply asking more reviewers wont fix this. Instead, we need ways in which editors can more easily come to decisions on manuscripts taking into consideration the potential faults. This really entails journals being more transparent about what flaws in manuscripts will be considered fatal. For journals where methodological competency is all thats required (see here for commiment to publish), this is simple, but for many more journals (particularly those that are important for Early Career Researchers because advancement in their careers will depend on publishing there), there will be more ill defined, editor-centric choices that are more about fashion in Biological Sciences, than good science per se. Hence, fixing peer review comes back to fixing problems associated with the publishing culture (and all that that entails), rather than any a simple fix-all for the myriad of existing publishing options. Hence we have a book on publishing for early career researchers! "],["howpeerreview.html", "Chapter 29 How to conduct peer review 29.1 Novelty or repeatability? 29.2 Parts of your review 29.3 The spirit of peer review 29.4 There are ethical considerations for reviewers 29.5 Remain objective and rational 29.6 Remember to accentuate the positive 29.7 How long should your review be? 29.8 What to do if you suspect fraud? 29.9 Further help with conducting peer reviewn", " Chapter 29 How to conduct peer review Most modern journals provide reviewers with a guideline for the expected to do. I encourage you to read the specific instructions that are given by journals on how to conduct peer review for them. There are also a number of excellent blogs to read about peer review (including this one and this one). A systematic assessment of these requirements in biomedical journals has been undertaken by Glonti et al (2019) and Eve et al (2021). These accounts are worth dipping into for an overview on the different sorts of statements that peer reviewers come up with. You can see in this quantitative analysis that the overwhelming number of comments are those of skilled critics. This paper also makes it clear that the role of peer reviewer is often ambiguous and that reviews are not consistent in what they deliver. Essentially peer reviewers are tasked with determining whether or not the manuscript is credible. Could the study be repeated? Are the methods legitimate in order to produce the results provided. Are the results sufficient to respond to the hypothesis posed? Can it be improved? Is the content of the manuscript appropriate to the journal? Does the experimental design contain sufficient controls? Did the authors try and stretch the implications of their results beyond the credibility of the manuscript? Once you have conducted your peer review, you can log it publons in order to get credit later on. Publons also carries your publication output and citations (tied to Web of Science), so can be a useful way of keep track of your own productivity (but see). 29.1 Novelty or repeatability? At the heart of scientific enquiry is that studies done should be repeatable, with the presumption that if they have been done in the same way they should acheive the same results (given the bounds of significance testing - see (Forstmeier, Wagenmakers, and Parker 2017)). Hence, you must examine and report on whether or not the studys materials and methods are sufficient for someone else to repeat the study. This appears to be surprisingly rare in peer review (at ~4% according to Eve et al. 2021) For some no impact journals, this technical soundness will be enough to allow them to pass peer review. Many journals that aspire to increase their Impact Factor, ask for a comment on how novel the study is. This is a somewhat subjective question, as individuals have biased opinions of what constitutes something novel, noteworthy, of significance or of relevance to the audience of a particular journal. Hence, this is really going to be a point that you can decide based on your own understanding of the literature (remembering that you have been chosen because your opinion counts). You can gain important insight into what is relevant and what not in peer review from the analysis of PLOS ONE reviews by Eve et al (2021). 29.2 Parts of your review 29.2.1 A positive appraisal of the study I think that summarising the study in your own words, to the tune of a single paragraph, is a useful way to start a review. It demonstrates to the editor and authors that you have read and understood the work. If you have not understood everything, then you should concentrate on what you have understood to be reported in this section. Although this might set you up to produce a shit sandwich, this is not necessarily a bad thing. 29.2.2 Major comments The next section concerns major positive and negative comments. Try to be even handed here. This is a place to point out any major short-fallings of the manuscript, but it should also be used to point out where the authors have done a good job. You may need to resort to a list, where each major item gets its own paragraph, but these may turn into sections if your reasoning takes longer. For each major comment, give an example of what you mean with Line numbers. These should be tangible points that you can tie down to things that are present in (or even missing from) the text. In this section, I would urge you to keep away from providing subjective statements (like I think or I feel or It seems to me). If you need to voice these feelings, then keep them for a final paragraph where you make it clear that these are impressions given by the manuscript to the reader. 29.2.3 Minor Concerns List these out under a heading Minor Comments starting each one with a line number where it occurs. Figures and tables should receive their own comments (no line numbers). 29.3 The spirit of peer review At its heart a peer reviewer should be trying their best to improve the manuscript they read as much as they possibly can. This may simply represent an improvement in the way the text is worded. But it may also mean adding extra analyses or even experiments. As McPeek et al (2009) put it, the golden rule of reviewing is to do unto others as you would have them do unto you. Baglini and Parsons (2020) provide some useful insight into how to remain neutral when making reviewer comments. Again, the emphasis is on being professional. 29.4 There are ethical considerations for reviewers Reviews may not share manuscripts with other scientists unless specific permission is given by the editor. Similarly reviews should not discuss the content of manuscripts that they are reviewing Reviewers should not try to take the work presented in the manuscript and copy it for publication (i.e. do not steal the ideas). Reviews should be conducted within a reasonable time frame. No reviewer should hold on to a manuscript especially if they have a vested interest (like a rival study) in not seeing it published. This should have been declared as conflict of interest. Any other potential conflicts of interest, including those that might make you positively predisposed to the authors. Be aware of their own prejudices and biases and not bring them through to the review process Whether or not to sign your review. Given the opportunity ~43% of reviewers will provide published open reviews (Wang et al. 2016). In essence these ethical issues are overcome when reviewers conform to transparency. In order to facilitate transparency in peer review, Parker et al (2018) have produced a checklist that I encourage you to use if and when you are asked to conduct a review. 29.5 Remain objective and rational Your job as a reviewer will be to remain objective about the manuscript that you are reading, point out its merits and problems without succumbing to bias. Forming your own world view of your topic within the biological sciences does mean that you likely need to form a form of directionally motivated reasoning. For example, this is why you decide to investigate one hypothesis before another, or feel that one line of investigation is more salient to your area than another. These could be made through observations or experiences that you have had during your research, or they may come from schools of thought within your discipline. But it is important that you remain intellectually honest, to allow others to hold alternative, valid arguments. Just as it is important in your own work that you are always prepared to accept the null hypothesis as readily as you do the alternative hypothesis. One lesson revealed from reading lots of peer reviews is that reviewers find it hard to remain centred using accuracy motivated reasoning, all too often resorting to attacking the authors or their experiment (Eve et al. 2021). Your principle task it to remain intellectually honest in your review, such that you can point out faulty arguments without perverting the direction that the authors planned to take. Equally, it is important that the authors acknowledge alternative viewpoints, but not the the extent that they should be made to abandon their own interpretation. Psychologists have argued that as humans we cannot be expected to be rational, and that we are not particularly good at being objective. But this doesnt mean that we shouldnt try, and it also means that by being aware of the potential problems in peer review, we are in a better position to learn how to avoid them. Write every review as if it will be public. Ask yourself whether every statement that you make can be backed up either by other references in the literature, or with line numbers corresponding to erroneous logic on the part of the authors. Although this strategy is not gaurenteed to produce an unbiased review, it will be an intellectually honest way to approach the manuscript. 29.6 Remember to accentuate the positive Peer review is often thought of as being brutal, where anonymous reviewers have the opportunity to vent their darkest thoughts. Certainly, there are plenty of reviewers who are unprofessional in what they say (Eve et al. 2021; Hyland and Jiang 2020). When conducting peer review, you have the opportunity to be one of the goodies. You can point out where the authors have done due diligence, in their experimental design, reporting, analyses, etc. This is likely to benefit the authors far more than pointing out problems - especially those that cannot be fixed. 29.7 How long should your review be? Quite simply, you need to write enough until you have reviewed the manuscript. The length of peer review varies wildly, from 200 characters to 43000 (likely more than the article itself), according to (Eve et al. 2021). The distribution peaks between 2000 to 4000 characters, and this should be a good guide. If you submit your review to a service like publons, you can compare the lengths of your reviews get charted against those of the average reviewer, and I would suggest that you should aim to keep your reviews above average length when the extra words are used to help the authors. 29.8 What to do if you suspect fraud? The Committee on Publication Ethics (COPE) has published some useful flowcharts to guide reviewers who suspect fraud in manuscripts they are reading. A list of these is provided in Part IV. 29.9 Further help with conducting peer reviewn A number of publishers and academic institutes have provided online resources to help train those undertaking peer review. I provide links to some of these here: ACS Reviewer Lab Publons Academy Nature Masterclass. Remember that these are suggestions, and should provide sufficient instruction to get you started. Not all jouranls as the same of their reviewers, and so instructions may vary. Your review should follow the recommendations provided by the journal that you are providing the review for. "],["predatory.html", "Chapter 30 What are predatory journals? 30.1 If the line is so grey, how is it possible to tell whether or not a journal is predatory? 30.2 What do you do if you have already published in a journal that others consider predatory?", " Chapter 30 What are predatory journals? Predatory journals are publications that purport to be from scholarly publishing houses, but have little or no editorial oversight or peer review. They exist in order to extract the Article Processing Charge (APC) that is so ubiquitous in Open Access journals. They continue to exist because publishing is moving towards APCs, and there is little difference between what they do and some supposedly legitimate journals. For example, some definitions of predatory journals include that their APCs far exceed their publishing costs, but this can now certainly be said of some legitimate journals. 30.1 If the line is so grey, how is it possible to tell whether or not a journal is predatory? This is a surprisingly difficult question to answer. Predatory journals have become so sophisticated at what they do, that it can be very difficult to determine whether or not they are legitimate. Moreover, their electronically published journals can create new titles faster than the time that it takes to check that they are legitimate. An example of a publisher in the grey zone is Hindawi, that were once considered predatory but were later removed from Bealls list. At the time of writing, I considered that Hindawi still had some questionable practices and so suggested continuing to avoid them. However, in a new twist, January 2021 Wiley (a well respected publisher) acquired Hindawi for USD 298 million (yes folks, your science is big business because of the big profits that Wiley expect to make out of you and your tax paying funders). This news goes to show how quickly the publishing world is reacting to the new world of OA, but also how publishers intend to dominate the market and maintain their stranglehold on scientific publishing. Most academics have an interaction with predatory journals through email. Indeed, the numbers of emails that academics are spammed with is astounding (VanDenBerg et al. 2021), and while the best advice is to use a spam filter, I still find that too many legitimate emails got there too. These emails are not straight forward and seek to manipulate the reader into submitting a manuscript (Bett 2020). Moreover, predatory journals target the most vulnerable in the community, poorer researchers who do not have English as their first language are deliberately targeted Lund and Wang (2020). At the same time, legitimate journals have become increasingly predatory in their habits, and its difficult to tell them apart from predatory journals. There was a time when it was possible to categorically state that no journal will ever approach you with a general email that invites you to contribute. However, there are now several legitimate journals that send out unsolicited emails. Realistically then, in the current publishing world, there is a continuum from predatory to legitimate. It was not always this way, and that means that as an emerging researcher you are facing difficulties not faced by your advisor or other more senior academics. Not only do you need to avoid publishing in predatory journals, but you should also avoid citing their articles. However, help is at hand. There are some definite ways that you can determine whether you are choosing a legitimate journal. Here are my 5 steps that you can take to safeguard your submission. 30.1.1 To spot a predatory journal, use the following list in a stepwise fashion Use an index. Web of Science and Scopus both curate contents of legitimate journals. If your journal of choice appears in one of these, then it is very likely to be legitimate. Note that Google Scholar includes many predatory journals, so please never use this to determine whether or not a journal is legitimate. Note also that it takes a journal several years to gain enough kudos to get accepted onto Web of Science and/or Scopus. Therefore, it can still be legitimate and not be there. We have previously discussed how to choose the right journal for your publication (see part 4). If the journal you want to publish in is not in Web of Science or Scopus, then proceed to the next step. Ask your librarian. Librarians are fantastic sources as well as custodians of information, and journals are one of their key knowledge areas. Dont hesitate to get in touch with your librarian and ask their advice. They are likely to be very well placed to respond to your request. They may also be guardians of granting APCs at your institution, so it is in their interest to make sure that these valuable monies dont fall into the wrong hands. Ask your advisor or an experienced colleague. Its worth doing this with them so that you can see the steps that they follow. Given that steps 1 and 2 have already come back with uncertain answers, spreading your net more widely will help with step 4. However, be warned that there are increasing numbers of senior scientists that have been caught out by predatory journals, so checking their contributors is now no cut and dry way to differentiate between them and legitimate journals. Who is on the editorial board? Journals publish names of their editors, associate editors and the editorial board. Look through these lists and see whether there are names that you recognise. If you know any of the people, you (or your advisor) can contact and ask them about the journal (they should be happy to respond). Be warned that it is easy to place someones name on a website, so unless they have personally told you, keep away. Check against a known list. In the past, this might have been the first thing to do, but the number of predatory journals is proliferating so quickly that its hard for any list to keep up. Bealls list retired in 2017. The next best list now has more than 3 times that. See here for an interview with the keeper of the new list, Simon Linacre. Sadly Simons list is behind a paywall, so you cant expect to access it. One of the reasons why Beall gave up is that the new tactic for these publishers is to produce lots of new journals. Curating a list is real work and has implications for the publishers on it, hence you now need to pay to access an up to date list. There are more lists: Cabells Predatory Journal Blacklist, Bealls list, DOAJ delisted journals, Scopus discontinued sources, etc If predatory journals are becoming more like legitimate journals, wheres the harm in publishing with them? Your reputation is important. As an emerging researcher, your publishing record is what many people will see first. It is all that is shown in your Google Scholar or ResearchGate profile. Its your shop window or showroom. What prospective employers will want to see is that there are plenty of publications (appropriate for your career stage), and that they are in appropriate journals with good reputations. You might confuse having a good reputation with a high impact factor. The two need not be the same. High impact factor journals dont accept all types of submission, and you may have data that simply doesnt fit into one of their mandates. I would say that its still important to publish this, and there are many journals with good reputations where you can do so. Lets leave discussion about the impact factor for another chapter. The other reason why you would be best to avoid a predatory journal is that they attract very little in the way of scientific impact: few people will read or cite them (see article here). One thing that you definitely want for your work is for people to use it. To do this they must read and cite it. If you publish in a predatory journal, many scientists wont even consider reading the content as it has not been, nor will it be, peer reviewed. Thus, unlike a preprint, it is not being openly offered to the community for review. Due to the ambiguity of whether or not these papers have been peer reviewed, I would also suggest that you do not cite publications that you think may be from predatory journals. You can use the same steps (above) to determine whether or not what you want to cite is from a legitimate journal. 30.2 What do you do if you have already published in a journal that others consider predatory? The first step would be to write to the publisher and withdraw the article. Whether or not you paid an APC, having it on their website is not good for your reputation. Beware, these journals dont adhere to an ethical code, and so they might refuse to withdraw your paper. Or they may want to charge an additional fee to remove it (remember that they are in it for the money). Do not cite the paper, or put it on your CV. You can easily remove such articles from your Google Scholar profile or ResearchGate. Dont put it in your showroom. Prepare a statement that explains how it happened. You may not have been responsible for the submission, or aware that the publication was from a predatory publisher. However, in time you are likely to forget the exact reasons. It would be a good idea to prepare a statement, so that if you are asked (for example in a job interview), you can explain how it happened. People can be very understanding when provided with an explanation, but if you say that you cant remember or cant give any details, then you may sound evasive. Predatory publishing is a big problem in South Africa where 4246 papers have been published in 48 predatory journals: take a look at this article (Mouton and Valentine 2017). And its not just publishing where the predators are lurking, they are also waiting to invite you to a conference (see here). Your work is valuable to you and to your advisor, so please try to make sure that it doesnt end up in the hands of a predator! "],["paywall2.html", "Chapter 31 Why did some journals go behind paywalls? 31.1 Why dont all society journals do without publishers, and go Open Access independently? 31.2 How do publishers make their money? 31.3 Making a profit - In summary** 31.4 What will it take to break the vicious cycle? 31.5 Can we afford not to change? 31.6 Societies need money. Editors cant be publishers. 31.7 A paywall is never acceptable wherever you put it 31.8 The answer lies inside our University Libraries 31.9 We need to give up our addiction to fancy layouts 31.10 Giving up the obsession with metrics", " Chapter 31 Why did some journals go behind paywalls? Academics are not (usually) superstars, nor looking for enormous numbers of readers, but there would be little point to recording our work if we had no readers, or if our work were inaccessible, and so publishing is a necessity. However, we have got into a state in which much of our work is behind a paywall, and thus inaccessible to most. Whether or not we need our work to look pretty and appealing speaks more to our readers as humans than academics. Perhaps it goes without saying that an audience is likely to be larger the more appealing the presentation, and thats not just the writing style but the layout and presentation of the text itself. And this is not new. The first scientific journals appeared in 1665: Journal des Sçavans, and three months later Philosophical Transactions of the Royal Society of London. It is clear that the papers were type set and presented in the manner of a book, perhaps analogous to a collection of short stories. At the start, these were reports of studies that were presented at meetings. Producing proceedings of learned societies became the way in which most scientific journals began. Only later did it become possible to submit a manuscript that had not been presented. And later still when publishers began to manufacture their own scholarly journals in the absence of any academic society. FIGURE 31.1: The first issues of the Worlds first scientific journals FIGURE 31.2: Note that the Journal des Sçavans ceased publication in 1792 due to the French Revolution, but that the Philosophical Transactions of the Royal Society of London continues to this day as the worlds longest running scientific journal. Being the editor of a society journal means being elected by members of that society, and being responsible to an editorial board, normally made up of the societys members. Until very recently, and Im thinking back to my first interactions with editors for my first few publications, submitting to the journal meant producing three (or sometimes more) double spaced copies of a manuscript and mailing them to the editor. Editors of bigger journals had secretaries dedicated to handling the administration of the paper. Following a telephonic enquiry, the copies were sent out to referees by post and sent back to the editorial office with a typed report often together with the marked up manuscript. Once the editor had received all reports, they communicated their decision back to the corresponding author (i.e. the one to whom correspondence was addressed) and, once accepted, the article went into production. Prior to personal computers being commonplace (only 25 years ago), each journal would have had to have had a publisher to set the type and print the pages. Clearly, this was beyond the scope of individual societies and the publisher was a necessity. Libraries had to pay for copies of journals, as the cost of publishing had to be offset by the society. The advent of desktop publishing changed the need for publishers and brought many small society journals onto a larger platform where they could produce attractive content (over the typewritten documents that had been stencil duplicated or similar) and sent around to members. However, for small societies there was no professionalism involved as it devolved to the editor to publish society material. This is where I entered the stage in 2009 when I took over as editor of the African Journal of Herpetology. Thankfully, email had taken the place of the postal service, but once a manuscript was accepted I was the one who needed to type-set the documents (in Quark) and send out proofs to authors. Once proofs were corrected and the issue was ready, I had to find quotes from 3 printers, deliver discs and ultimately collect boxes of printed journals. Back at home, I also packed all of the copies into labelled envelopes (with some help from friends) and carried the boxes once again to the post office. FIGURE 31.3: Stuffing envelopes with journal copies seemed like an endless task. View on YouTube. After the first issue, I realised that I could not do all of this work indefinitely. I knew that there were publishers who were interested in acquiring the journal into their stable, and I contacted them and started negotiations. In 2011, the first copy of AJH from a professional publisher emerged, and allowed me to go back to editing the content through peer review. At the time, I was aware of Open Access and considered this as an option for the journal. Open Access would have required that someone pay for the type setting, and the society would still have to pay for an online dissemination platform, given that they did not have their own platform. This would have meant that authors paid for getting their manuscripts into print. And then, like today, the decision was that our authors would not be willing to pay. Other, richer, societies were able to go Open Access with the costs being covered by the authors. For some this became an incredibly successful model, with submissions increasing as well as the Impact Factor. They demonstrate that Open Access is possible on an independent platform. 31.1 Why dont all society journals do without publishers, and go Open Access independently? The first problem is that societies generate income from journals. Subscribers to print or virtual copies pay the society, and this can defray a large part of the cost of publishing otherwise carried by the members. Some make a profit, and this profit can enable the society to do more for their community of members. This could include providing small grants, subsidising conferences for students and other much appreciated initiatives. Going Open Access means losing this revenue, as well as taking on the extra costs. The second problem for many societies is that their members are paying, and the councils or committees elected to represent the members do not feel that it is fair for their members to pay for open access for everyone else. Part of the privilege of being a member of the society is having a free (or more accurately paid through membership) copy of the societys journals. The costs are not high, and the exclusivity of members having Open Access while it is denied to others is perhaps just a hangover from the days when the only other copies were in the library. Certainly, the costs are nothing like those which authors are now charged by publishers to turn their accepted manuscripts into Open Access. But the current situation is unsustainable. Tax-payers (in the main) pay for science to be conducted at universities and other institutes. In places where Open Access is mandatory, the tax-payer pays again to have the research published at a cost that is far inflated from the actual production costs. Publishers are getting fat, and the losers are the scientists (whose funding is reduced to pay publication costs) and the tax-payers who end up feeding the greedy publishers. 31.2 How do publishers make their money? In the original publishing model, scholarly societies, such as The Royal Society, paid publishers to type set and print their publications. These in turn were bought by the society for their members and any libraries who subscribed to the society. As institutions and their libraries grew internationally, so too did the subscription base such that there was a profit to be made from the cost of the subscriptions for the paper content. Even back in these early Victorian days of scholarly publishing, publishers to started their own journals (aside from any society) as they recognised their superiority in distribution (Brock 1980). This model continued over many decades with some publishing houses growing as they acquired more journal titles from societies because there was a lot of profit to be made. The peculiarity of scholarly publishing includes the unpaid nature of authors, editors and reviewers (all of the content), and the non-equivalence of the output: that is to say that just because you have access to articles in Nature, they are not equivalent to those being published in Science - as a scientist you need to read articles from both of these publications. Interestingly, the dawn of the internet was predicted as the downfall of the academic publisher Elsevier, because it promised the ability for academics to share their content for free (Larivière, Haustein, and Mongeon 2015). Despite this Elseviers profit in 2012-13 was USD 2 billion, with a profit margin of ~40% (Larivière, Haustein, and Mongeon 2015). This profit margin is so large that some have compared it favourably with street gangs selling drugs (Buranyi 2017). In the Biological Sciences, Elsevier, Springer-Nature, Wiley and Taylor-Francis control around 50% of all papers published (Larivière, Haustein, and Mongeon 2015). Selling to university libraries was no longer made on print copies, but on packages of journals from each of these big publishers. The deals made by individual libraries were (and are) made in strict confidence, the exact sums are unknown, but the deals made fall into the hundred and thousands of USD for a set of publications that cover (for example) the science content of one of these publishing houses. The penalty for not subscribing is that your researchers reach a paywall when they try to access a particular paper. You will find, as I have, the luxury of visiting a very wealthy institution and having access to just about every journal title you can think of. If you are not at one of these elite institutions, then you will face a demand for money when you try to access a title that you do not subscribe to. The cost of accessing a single article comes at between 25 and 50 USD (Hagve 2020). For me, and a great deal of other researchers, there are other ways to get around the paywall. But for some people, especially members of the public who simply want to access the information, they may simply pay the price. Imagine then the potential profit to be made from a society that has a large back-catalogue of content. There has been a scramble to sign up editors from society journals with tens of thousands of old journal articles at their command. The publisher offers to scan the entire back-catalogue and then offer it on sale. The society gets a paltry 10%, while the publisher fishes with tens of millions of articles. Even if they only sell 1% of these in 1 year, that makes their profit in the millions of USD. In 2014, universities in Germany abandoned all subscriptions of journals by the Dutch publishing house Elsevier, as they couldnt keep up with the 30% price increase over the previous 5 years, making the average cost ~$4700 per journal per year (Vogel, 2014, and Pm 2014). Despite this, Elsevier continued to allow these universities access to their content for free, before negotiating another (secret) more amenable deal to them. Somehow the publishers had managed to turn the ease of distribution of articles over the internet to their advantage, via effective paywalls. But this was not the last of their master strokes. Open Access titles came about in the early 2000s as the need for hard printed copies fell away as academics became comfortable handling all of their publications as pdfs. In the Biological Sciences, PLOS ONE was the title that revolutionised the market, quickly becoming the single biggest journal. What caught the eyes of the publishers was the article processing charge (APC) that academics seemed to be prepared to pay. When they first started, PLOS ONE cost ~1300 USD for its APC (Khoo 2019). Publishers quickly started titles with similar no impact factor goals. Competitive titles began at the same cost as PLOS ONE, but once these titles became established, with higher Impact Factors, they quickly increased their APC (Khoo 2019). Commercial publications (as oposed to non-profit journals) have become adept at pricing their titles toward what libraries and authors are prepared to pay, such that commercial publications are regularly more expensive than non-profit journals (Björk and Solomon 2015). In their analyses of drivers of APC for OA journals, Budzinski et al (2020) found several variables that explained the vast difference in APCs of different journals. Impact Factor played an important role, but so too did market power of the publishers (presumably the ability to distribute the title and content), the hybrid model (whether it is gold OA, or ******), and the concentration of disciplines (*****) Librarians analysed content that was Open Access finding that it was more highly cited, and so academics began to look for the potential to publish Open Access. The publishers were happy to oblige, and in the early days conducted double dipping charging both the APC for the authors, and collecting full revenue for subscription to hybrid journals by universities (Pinfield, Salter, and Bath 2016). It was only in May 2018 that Knowledge Unlatched formed an alliance to prevent double-dipping in Open Access publications. The end to double-dipping, as mandated by governments (Pinfield, Salter, and Bath 2016), has led to even more complicated publishing deals known as transformative publisher agreements. With these agreements, researchers from universities that have full subscriptions to certain publishers will receive free Gold OA for any journals in the package. In effect, the price of the OA is offset against the cost of the subscription. As you may have noticed, this will quickly start a bias in the publishing trends of academics from some (middle income) institutions publishing with certain titles, because they receive the benefit of OA. Those from privileged institutions will continue to publish anywhere they can, and the real losers will be those from developing, especially middle-income countries, who cannot afford transformative agreements, and cannot afford to provide their researchers with costs to cover APCs (J. Measey 2018). For these researchers, there will be a reduced set of journals that they can subscribe to. This is the current reality that many of us find ourselves in. On the face of it, Plan S makes total sense (Schiltz 2018). If all papers published by European researchers are Open Access, then everyone can read them and there is no more need for paywalls. Unfortunately, the way in which Plan S has been implemented has only been for wealthy European institutions. Others are left to continue to pay a hefty APC price for OA publishing, and their libraries pay a subscription to access journal content (Hagve 2020). 31.2.1 How could such a profitable business lead to making a loss? To be fair, we should also consider that some publishers have not (always) been able to turn a profit, even when their turnover is in millions of USD. One such beleaguered publisher is PLOS. Despite growing exponentially in the early noughties, to become the worlds biggest academic publisher in 2013, PLOS has not managed to turn a profit since 2015 (Davies 2019). At the time of writing (May 2021), the APC on a PLOS ONE article was USD 1749, while other PLOS titles ranged from USD 2100 to 4000 (see PLOS fees site). This begs the question, how much does it cost to process an article? Data from the PLOS Financial Overview suggests that processing your article costs USD ~315, with another USD ~262 to keep it online. So where does the rest of the money go? PLOS spend the bulk of your APCs on the editorial aspects of publishing. Remember that PLOS dont pay academic editors, but they do have huge financial burdens of the salaries of their own editorial staff. PLOS is based in San Francisco, California, which just happens to be one of the most expensive cities in the world to live in. Chief among their many options are to raise the costs of your APCs in order to pay their staff, or move their operation to somewhere cheaper. Interestingly, the other two large OA outfits, MDPI and Frontiers, are both based in Switzerland, possibly one of the most expensive countries in the world in which to pay salaried staff. Most recently, PLOS announced a new funding model to keep themselves afloat that spreads the cost of their APC among the authors, and aims to cap profits at 10% (Else 2021). The new scheme, Community Action Publishing, sees a return to the institutional subscription model where institutions will be charged proportionately at the rate their academics publish in PLOS. Great if your institutions can afford to opt in. If not, you can expect to face your proportion of the APC now as a co-author (instead of only the corresponding author paying). Time will tell whether PLOS can make their new financial model work in order to keep their staff in the comfort to which they have become accustomed. No doubt we will see more of these new funding models as the increasingly bloated OA market attempts to consolidate itself, while still feeding on the funds of the global tax payer. 31.3 Making a profit - In summary** From society journals old subscription model (mostly obselete) selling bundles to university libraries (undisclosed sums - millions of USD) selling articles of large back catalogues (~10% goes to society) From their own journals old subscription model (mostly obselete) selling bundles to university libraries (undisclosed sums - millions of USD) selling articles of large back catalogues From Open Access APC Double dipping Transformative publisher agreements In case you hadnt realised, there is no advertising (at least in Biological Sciences - some medical journals do have advertising). The only time you see adverts is when you are browsing the content of Nature and Science. Oddly, this doesnt make them any cheaper to publish in, but presumably does increase the profits for these particular titles. 31.3.1 What about academic books? The story about the move from print to eBooks in academic books shows some even more remarkable disparities in the prices of eBooks compared to their physically printed paper counterparts (see Figure 31.4). University libraries are required to buy versions that are specifically licensed for university use. The copyright law means that universities are not allowed to scan their paper copies and make these available. But in order to buy the university library copy, the price paid might be as much as 10 times that of the paper edition (Figure 31.4). FIGURE 31.4: The cost of eBooks compared to printed copies of the same books. In crowdsourced data compiled by people in the Campaign to investigate the academic eBook market, you can see that most of the titles have a much more expensive eBook version. Note that in all cases the eBook licence is the equivalent of a single printed book: i.e. a 1 user copy. Data as entered on 17 May 2021. More than this, publishers appear to inflate the prices of their eBooks without warning, but as much as 200% (J. Anderson and al 2021). In addition, there are moves to make licensing annual for universities, with examples where once-off purchases have become unavailable as the publisher has moved them to an annual pricing model. While copyright law would protect you as an individual from any publisher that was undertaking such terrible behaviour, UK universities appear to be without recourse, such that they are now petitioning the Minister for Higher Education (J. Anderson and al 2021). 31.4 What will it take to break the vicious cycle? We need new models for publishing. Society journals are still kings in this game and ultimately hold the cards for moving away from filling the pockets of publishing companies. What we have seen in recent years is that journals can come from nowhere to become dominant players in the system. Think PLoS ONE, and the even more recent Scientific Reports. These mega Open Access journals didnt exist 10 years ago. And they dont need to exist 10 years from now. What is needed is for the actual costs of publishing (not that currently inflated by publishers) to be covered by the institutions that employ the academics. This could cover type-setting (fulfilling our irrational desire for fancy layouts and the additional IT infrastructure (on-line submission system and online dissemination platform). Most (if not all) societies are not-for-profit organisations, and only need to cover the costs of publishing. 31.5 Can we afford not to change? If you are from a rich country or institution, then you can probably afford the current system. Those who cannot are researchers in disadvantaged countries. In some cases, the cost of publishing Open Access is greater than the cost of the research. These are insurmountable costs for many researchers. We have a massive hole in scientific contributions from the poorest of nations, and the current Open Access models will see their work being the most hidden from view, while the countries paying for their work do so disproportionately. But even developing countries could be winners in a new Open Access model. By sourcing the relevant IT skills in the country, governments of middle-income countries could facilitate the content of their own societys with relative comfort. In my opinion, everyone should publish work from scientists in the poorest countries as Open Access without any charges. 31.6 Societies need money. Editors cant be publishers. We need free software. We desperately need good, free editorial management software. There are some free versions out there, but what we need are free versions that are at least as good, if not better, than existing platforms (e.g. ScholarOne; Editorial Manager). Galipeau et al (2016) make the point about the ever expanding role of editors in the modern publishing era. There is no scope for editors to take on extra work. We need a free La-Tex interface with robust templates for all societal journals. Ideally, this would be packaged with the above editorial management software. This must have the ability to cope with figures and equations, and the unusual demands that some society journals have. We need a solution for hosting and disseminating the Open Access society journals (and their supplementary information if not hosted elsewhere) in perpetuity. This last point is perhaps the most expensive, and almost certainly requires government assistance. Maybe this is an interesting use of the block-chain with libraries keeping the data. It would be an interesting way to build a doi with editor and referee unique IDs, and the documents information hanging off. We need to take back our content stuck behind paywalls. Yes, its time for you all to dig up those old submitted manuscripts and submit them to an institutional repository where it can be accessed for free. 31.7 A paywall is never acceptable wherever you put it Any paywall, whether it be high (i.e. EUR 9500 for Nature in 2020), or considerably lower (i.e. EUR 900 for NeoBiota in 2020) is a wall that excludes many researchers, and certainly those from many developing countries. I have made this point before (J. Measey 2018). While previously I lobbied for the source of these publishing fees to become public - which would show that for a great majority of researchers, publishing fees are coming from research funds. Funds that would otherwise further knowledge are going directly into the pockets of publishers. Publishers instantly refused to do this. Now I think that our energies would be better spent demolishing the paywall (what they refer to as Diamond Open Access). And for almost all of us, this means doing so without the benefit of a rich uncle. Until we have Diamond Open Access for all, having the paywall after publication is actually preferable for most of us, as most of us cannot afford to pay anything as we simply dont have this type of discretionary funds. We do have to publish our work, and would rather that it was out there behind a paywall, than not out there at all. I am not advocating a paywall, but I disagree that by placing the paywall before publication (i.e. on acceptance) solves anything for anyone other than the most privileged researchers. In the words of Peterson et al (2019), do not replace one problem with another. Instead, what we need is to tear down the paywall with a completely new publishing model for academia. We are all quick and ready to agree that Open Access is the best way forward for all scientific results. The aims and objectives of Science Europe are laudable and will lead to a far better publishing environment for European scientists. Scientists from other high-income countries will also benefit from this decision, having a far greater number of journals in which to publish Open Access. If current trends continue, scientists from low-income countries will be granted full fee waivers. Many journals use the Hinari Eligibility list of countries to separate Group A (free access) and Group B (low cost access  normally billed at a 50% reduction in fees). The lists are made up from five global economic and development criteria. Middle-income countries are missing from these lists, and receive no support for fee waivers. Their governments provide scientists with no means of paying fees. Scientists who pay fees often do so from their own research budgets. The increasing number of journals that charge unjustifiably high publishing costs are forcing middle-income scientists away from Open Access journals. In my own lab, publication fees are regularly more than the cost of conducting much of our ecological research. 31.8 The answer lies inside our University Libraries The university library has undergone a massive transformation over the last 20 years. During my PhD, I made a weekly visit to the library to physically pick up the latest issues of all the journals that came through the postal service from all over the world. For papers that I found out about but had no access to, I had a stack of postcards that were specifically for reprint requests, and I enthusiastically filled them out and posted them off to researchers the world over. Librarians arranged these issues on the shelves and eventually sent them off for binding into volumes and then worried about the physical space that was available inside the library as every year publication inflation (Larivière and Costas 2016) meant more pages to be supported within their walls. Probably the most stressful time in the library now is around negotiating the next contract with a mega-publisher. Will they be able to meet next years demand for cash? How much are other universities paying? Of course, the bundles are sold with non-disclosure agreements, so that librarians who successfully negotiate a lower price at one institution cannot influence the negotiations at another. Doesnt this sound like an extortion racket? Like others, I think that the logical solution to our problem with publishers is to turn instead to our university libraries to curate our academic outputs (Ferric C. Fang and Casadevall 2012). There are clear reasons why it makes sense for libraries to take on the roll as publishers. Most of us are employed by universities or research institutions that also fund libraries. Linking the work we do (writing, reviewing and editing) more closely with our institutions would result in a greater appreciation for this part of our workload. Libraries have fantastic networks, and are our professional long-term storage partners. They developed efficient and impressive information technology (IT) long before it hit most academic departments. Their inter-library networks are what we now need to disseminate the knowledge that we generate without any walls. The idea of libraries as the new publishers isnt new. Raju and Pietersen (Raju and Pietersen 2017) proposed this as a solution in Africa. Here I extend the same idea as an exclusive way of publishing academic journals for the world. 31.8.1 Moving back to publishing through scholarly societies without publishers we still need to organise academics at a level beyond the individual and spanning institutions. This means elevating the importance of scholarly societies (Harington 2020), with all of the additional benefits that these bring (e.g. networking, conference organisation, newsletters, socialising, mentoring, stewardship, community of practice, ethics, outreach, etc.). However, far from relying on the publishers be the sources of income for societies (Harington 2020), we need a professional society model (such as is seen in medicine and other vocationally orientated disciplines) whereby the relationship between academics and their societies is strengthened through their institutions. 31.9 We need to give up our addiction to fancy layouts Once the storage and dissemination of our contributions are taken care of, the only service left from the publishers is a fancy layout. This is mostly a historical legacy (see above). I have to admit that I really like seeing my work being nicely produced and printed. But Im happy to give this up if it means demolishing paywalls. In reality, LaTex can solve most of these problems so that we simply use the journal (library) produced template, that will need minimal manipulation afterwards. I feel sure that those who are hung up on the importance of their layout can find undergraduates at their own institutions who will be happy to provide layout services for a reasonable fee. No doubt, there will be some institutions that will invest extra to have nicer layouts. But I feel confident that this will not change the impact factor, or any other metrics, as academics will value the content for what it contains rather than what it looks like. Admittedly, nothing about the contents of the highest ranking journals suggests that impact factor is consistently related to research quality. If our futures lie with the overlay model of publishing, then I suggest that we need to have less reliance on international storage of (what are currently) preprints, and instead a closer relationship between university libraries and scholarly societies. If you have read this far, then I hope that you will join the call for Diamond Open Access - no paywalls for anyone. 31.10 Giving up the obsession with metrics Another key move will be having all academic institutions and funders adopting the San Francisco Declaration on Research Assessment (known as DORA) in order to stop hiring staff based on their publishing metrics, and the negative impacts that this is known to have (Casadevall and Fang 2012). This will have an impact on many aspects of science including the current way in which science is funded on a winner takes all basis (Casadevall and Fang 2012). Many suggestions for reforming science are out there, but when the participants are still ruled by the cult of metrics, it will be hard to see the necessary reform taking place (Ferric C. Fang and Casadevall 2012). "],["publishmore.html", "Chapter 32 Are researchers writing more, and is more better? 32.1 Are some authors unfeasibly prolific? 32.2 Is writing a lot of papers a good strategy? 32.3 At what rate is the literature increasing? 32.4 If more is being published, will Impact Factors increase?", " Chapter 32 Are researchers writing more, and is more better? The idiom publish or perish suggests that researchers will increase their output in order to obtain positions and promotions. And if a researchers productivity is measured by their publication output, shouldnt we all be writing more papers? Certainly, it appears that more papers are being published (see Figure 32.1. An estimate for the total number of scholarly articles in existence was 50 million in 2009, with more than 25 million published in the years from 1984 (Jinha 2010). Similarly, if we are all be writing more, then wouldnt some people start publishing two (or more) papers, when one would be adequate? This idea of salami slicing to inflate outputs would be an understandable strategy if researchers were all trying to increase their output. Alternatively, the names of authors might be added to papers in which they did not make significant input via ghost authorship or hyperauthorship (see Cronin 2001 for an interesting historical perspective, and Part I). FIGURE 32.1: The growth in the number of papers published in Life Sciences over time. The number of papers published (blue line) compared to a standard growth rate (black line). The data come from www.scopus.com. A study by Fanelli and Larivière (2016) has a new take on the above questions, by asking whether researchers are actually writing more papers now than they did 100 years ago. They used Web of Science to look for unique authors (more than half a million of them) and determine whether the first year of publication and the total number of publications resulted in an increasing trend. But it is possible that these figures could be explained by the fact that the culture in publishing in biological sciences has changed a great deal since then. One hundred years ago, it was very unlikely that any postgraduate students would publish articles in peer reviewed journals. Moreover, it was also acceptable for advisers to take the thesis work of their students and write it up in monologues. This has certainly changed with the ranks of authors now being swelled considerably so that many more authors are likely to be included on only a single publication in which they participated. Hence, Fanelli and Larivières (2016) trend line for biology is very stable at around 5.5 publications whether you started publishing in 1900 or 2000 (note that earth science and chemistry do both increase dramatically), but this may reflect an influx of junior authors into the publishing system. 32.1 Are some authors unfeasibly prolific? Whether or not it is feasible for individuals to write so many articles, was the question posed in a study that examined prolific authors in four fields of medicine (E. Wager, Singhvi, and Kleinert 2015). This publication piqued my interest as it turns out that they decided that researchers with more than 25 publications in a year were unfeasibly prolific as this would be the equivalent of &gt;1 publication per 10 working days. Their angle was to suggest that publication fraud was likely, and that funders should be more circumspect when accepting researchers productivity as a metric. Looking back through the peer review of this article (which is a great aspect of many PeerJ articles), Im astounded that only one reviewer questioned the premise that its infeasible to author that number of papers in a year. I have published &gt;25 papers in a year, and I know other people who do this regularly. To me, there is no question that (a) it is possible and (b) that they really are the authors. Firstly, the idea that prolific authors constrain their activity to working days is naïve. Most will be working throughout a normal weekend, and working in the early morning and late evening, especially in China (see Barnett, Mewburn, and Schroter 2019). A hallmark of a prolific author would be emails early in the morning and/or late at night. This gives you an indication of their working hours, and how they are struggling to keep up with correspondence on top of writing papers. Authorship of a publication is often the result of several years of work. Thus, publications that I co-authored in 2017 frequently had research conducted in 2014 or earlier. For example, one of the publications, Measey et al (2017) is the product of aSCR work that started in 2009, funded in 2011 with fieldwork in 2012, and required the development of software for analysis by Ben Stevenson and colleagues (2015), before it could be completed and submitted. Thus, from my perspective, when I look at authoring a lot of publications it reflects the activity of the initial concept for the work, raising of money, conducting the field work or experiment, analysing the data and then writing it up (with the subsequent submission and peer review time). Thus, publications in 2017 result from a lot of work done for more than 3 years. 32.2 Is writing a lot of papers a good strategy? This is a question of long standing, and one that you may find yourself asking at some point early on in your career. Id suggest that the answer will be more about the sort of person that you are, or the lab culture you experience, over any strategy that you might consciously decide. If you tend toward perfectionism, this will likely result in fewer papers that (I hope) youd consider to be of high quality. If on the other hand your desire were to finish projects and move on, youd be more likely to tend toward more papers. It is clear that the current climate leads towards the latter strategy, with increasing numbers of early career researchers bewildered at the idea of increasing their publication metrics (S. Helmer, Blumenthal, and Paschen 2020). But what should you do? Given that the best personality type lies somewhere in the middle, you can decide for yourself whether you identify with one side more than the other. But which is the better strategy? Vincent Larivière and Rodrigo Costas (2016) tried to answer this question by considering how many papers unique authors wrote and seeing how this relates to their share of authoring a paper in the top 1% of cited papers. Their result showed clearly that for researchers in the life sciences, writing a lot of papers was a good strategy if you started back in the 1980s. However, for those starting after 2009, the trend was reversed with those authors writing more papers less likely to have a smash hit paper (in the top 1% of cited papers). Maybe the time scale was too short to know. After all, if you started publishing in 2009 and had &gt;20 papers by 2013 then you have been incredibly prolific. Other studies continue to show that in the life sciences, writing more papers still provides returns towards having papers highly cited: the more papers you author, the higher the chance of having a highly cited paper (Sandström and Besselaar 2016). One aspect not considered Larivière and Costas (2016) is that becoming known as a researcher who finishes work (resulting in a publication) is likely to make you more attractive to collaborators. Thus, publishing work is likely to get you invited to participate in more work. Obviously, quality plays a part in invitations to collaborative work too. Thus pulling the argument back to the centre ground. There are other scenarios in which you might be encouraged to write more. In Denmark, for example, research funding is apportioned to universities based on the number of outputs their researchers generated in a point system, where higher ranked journals get more points. This resulted in researchers in the life sciences changing their publication strategy with a notable increase in publications in the highest points bracket following this change (Deutz et al. 2021). If you find yourself becoming preoccupied about which is the best strategy for you, Id suggest that you get back to finishing what you were writing before you got distracted! 32.2.1 Natural selection of bad science In 2016, Smaldino and McElreath proposed that ever increasing numbers of publications not only leads to bad science, but is currently selected for in an academic environment where publishing is considered as a currency. They argued that the most productive laboratories will be rewarded with more grant funding, larger numbers of students, and that these students will learn about the methods and benefits of prolific publication. When these offspring of the prolific lab look for jobs, they are more likely to be successful as they have more publications themselves. An academic environment that rewards increasing numbers of publications eventually selects towards methodologies that produce the greatest number of publishable results. To suggest that this leads to a culture of bad science Smaldino and McElreath (2016) conducted an analysis in trends over time of statistical power in behavioural science publications. Over time, better science should be shown by researchers increasing their statistical power as this will provide studies with lower error rates. However, increasing the statistical power of experiments takes more time and resources, resulting in fewer publications. Their results, from review papers in social and behavioural sciences, suggested that between 1960 and 2011 there had been no trend toward increasing statistical power. Biological systems, whether they be academics in a department or grass growing in experimental pots, will respond to the rewards generated in that system. When grant funding bodies and academic institutions reward publishing as a behaviour, it is inevitable that the behaviour of researchers inside that system will respond by increasing their publication output. Moreover, if those institutions maintain increasing numbers of researchers in temporary positions, those individuals are further incentivised to become more productive to justify their continued contracts, or the possibility of obtaining a (more permanent) position elsewhere. Eventually, this negative feedback, or gameification of publishing metrics, produces a dystopian and dysfunctional academic reality (S. Helmer, Blumenthal, and Paschen 2020). An example of this kind of confirmation bias driven publishing effect toward bad science can be found in the literature of fluctuating asymmetry, and in particular those studies on human faces (Dongen 2011). Back in the 1990s, there was a flurry of high profile articles puporting preference for symmetry (and against asymmetry) in human faces. The studies were (relatively) cheap and fast to conduct as the researchers had access to hundreds of students right on their doorsteps. The studies not only hit the top journals, but were very popular in the mainstream media as scientists were apparently able to predict which faces were the most attractive. Stefan van Dongen (2011) hypothesised that if publication bias was leading to bad science in studies of fluctuating asymmetry in human faces, there would be a negative association between effect size and sample size when fluctuating asymmetry in human faces was not the main aim of the study. Ideally, hed have compared published with unpublished studies, but the problem with unpublished studies is that they are very difficult to find. He found that when fluctuating asymmetry in human faces was not the main aim of the study, the effect sizes diminished, suggesting that there was important publication bias. Where others have looked, publication bias has been found and is particularly associated with a decreasing effect size that correlates with journal Impact Factor: i.e. once the large eggect is published in a big journal, the natural selection of bad science results in publication bias, and diminishing effect sizes that ripple through lower impact factor journals (M. R. Munafò, Matheson, and Flint 2007; Brembs, Button, and Munafò 2013; Smaldino and McElreath 2016), while negative results disappear almost entirely (Fanelli 2012). The direct result of a system driven by Impact Factor and author publication metrics is that we will have a generation of scientists at the top institutions that are trained not to conduct the best science, but to generate publications that can be sold to the best journals. We should be deeply suspicious of any claim of linkage between top journals and quality (Brembs, Button, and Munafò 2013). Indeed, what we see increasingly is that the potential rewards of publishing in top Impact Factor journals leads not only to bad science, but increasingly to deliberate fraud. Continuing along this path threatens to undermine the entire scientific project, and places science and scientists as just another stakeholder in a system ruled by economic markets, and their promotion of the fashion of the day (Brembs, Button, and Munafò 2013; Casadevall and Fang 2012). 32.3 At what rate is the literature increasing? A study using several databases (Web of Science, Scopus, Dimensions and Microsoft Academic) back to the beginning of their collections at the start of scientific journals in the mid 1600s. They suggest that the inflation rate of scientific literature runs at 4.02%, such that the literature will double in 16.8 years (Bornmann, Mutz, and Haunschild 2020). This means that there is literally twice as much published in 2020 as there was in 2003. Although the early period of scientific publishing was notably slower than today, it is since the mid-1940s (following the end of World War II) that science has seen an exponential growth in productivity, with annual growth of 5.1%, and a doubling time of 13.8 years (Bornmann, Mutz, and Haunschild 2020). 32.4 If more is being published, will Impact Factors increase? Yes. If the numbers of citations per paper remains constant, then the Impact Factor of journals should increase annually at 5%. My impression is that citations are increasing in papers as the literature increases, which suggests that Impact Factor will grow at a faster rate. "],["retract.html", "Chapter 33 When should you correct or retract your paper? 33.1 Making a correction to a published paper 33.2 A retraction is unusual 33.3 Retraction Watch 33.4 Fabrication of data 33.5 What to do if you suspect others 33.6 Confirmation Bias and the paradox of high-flying academic careers", " Chapter 33 When should you correct or retract your paper? Once your Version of Record is published, any changes that you may wish to make will result in a separate correction publication. In extreme cases, you may even need to retract the paper. The different options available in many journals to correct your paper are shown in Table 33.1. If you are in doubt about exactly what kind of correction you need read the guidelines from the Council of Science Editors and the Committee on Publication Ethics (COPE) (Barbour et al. 2009). TABLE 33.1: Journals have a number of different ways in which to correct the published Version of Record. You many not need a full retraction to set your study straight. Source: Council of Science Editors. Action Example Conclusions impacted Issued by Corrigendum / erratum / correction Important typos / incorrect figure legends or tables / author name or address issues Not Author Expression of concern Data appear unreliable / misconduct suspected Undetermined Editor (perhaps through information received) Partial retraction One aspect of the study is corrupted / Inappropriate analysis Overall findings remain Author or Editor Full retraction Majority of the study is corrupted / Evidence of misconduct / Work is invalidated Yes Author or Editor 33.1 Making a correction to a published paper It is very unlikely that you will be in a position where you will need to think about retracting your paper. If you notice a mistake, especially one that results in a difference to how the results are presented, then you should approach the editor about publishing a correction (also termed a corrigendum or erratum - plural errata). Because a corrigendum is a change to the VoR, it will result in what is in effect an additional separate publication (with its own DOI). This will succinctly point out the error and how this should be rectified. In the journal, this will only be a few lines. In addition, on the site of the original publication, the journal will place a notice that there has been a correction, and provide a hyperlink to the correction. However, it results in a lot of extra administrative work for everyone, so its best avoided if at all possible. This is another reason why its worth taking your time when checking your proofs. Another way to avoid having to make a corrigendum is to ensure that all co-authors are happy with the original submission, the resubmission and the proofs. Mistakes do occur, and it is likely to be some time after the publication that you might find that there was an error. Errors such as typos, or mistakes in the introduction or discussion are unlikely to warrant a corrigendum. However, if the error is in the way that the results were calculated, or causes a change in the significance, then you should consider making a corrigendum. If you feel that it is necessary, do consult your co-authors before taking it to the editor. It is well worth having someone else check your new calculation, as the last thing you want is a compounded error. If the mistake is systemic, and changes all of the results, their significance and/or the validity of the conclusion, then you need to consider a full retraction. 33.2 A retraction is unusual A person who has committed a mistake, and doesnt correct it, is committing another mistake.  Confucius A retraction of a paper is when your paper is effectively unpublished. This happens at the discretion of the editor (and often the entire editorial board), and is a very serious issue. Retractions are rare. Reasons for retractions vary. It could be that a piece of equipment was later found to have malfunctioned or was calibrated incorrectly (Anon 2018). A cell line was misidentified. Or they can be through no fault of the authors. For example, Toro et al (2019) had their manuscript rejected by Journal of Biosciences, but due to an administrative error, the article was printed in an issue, and later retracted. However, the top reason for retraction is now misconduct (Ferric C. Fang, Steen, and Casadevall 2012), and this is hardly surprising given the crazy incentives that many scientists received to publish in journals with top impact factors. Another important factor with retractions is that they appear to be more common in journals with higher impact factors (Brembs, Button, and Munafò 2013), and this should not surprise us as these journals are prone to publishing studies with confirmation bias (Forstmeier, Wagenmakers, and Parker 2017; J. Measey 2021). Although retractions are so rare in life sciences, 0.025% of all papers published between 1990 and 2020, they appear to be on the increase in the last 30 years: from around 8 to over 200 papers per 100 000 published (see Figure 33.1). It takes a mean time of nearly 2 years between notification of problems with a paper, and issuing a correction or retraction (Grey, Avenell, and Bolland 2021). FIGURE 33.1: The growth of retractions in life sciences journals over time. The three lines show when the original paper is published (blue line) and when a correction, expression of concern or retraction are made (black line). Articles that are finally retracted (green line) are only a part of those with other issues after 2008. While the number of papers published that are later retracted appears to take turn downward from 2014, this may simply represent the lag before they are later retracted. This data came from the Retraction Watch database, selecting only data from Basic Life Sciences and Environment. The data is normalised by dividing the total number of publications (as taken from SCOPUS) in this area for the year by 10 000 (following Saunders 2015), and multiplying this by numbers of Original or Retracted papers. What exactly happened in 2011? There were a number of laboratories that made multiple retractions in 2011 (see Ferric C. Fang and Casadevall 2011; Brainard and You 2018), and given that there was so much around, perhaps it allowed some people to feel that they should come forward allowing all the bad news to come out at once (for more insight see Oransky 2011; Brainard and You 2018). If you have bad news, then let it slip out when everyone is looking at worse news elsewhere - this is what politicians do all the time. What is clear from Figure 33.1 is that the rising trend in retractions (black line) appears to have been unaffected by the 2011 spike in biological sciences. 33.2.1 How do you know if a paper you cited is later retracted? Citations to retracted papers are not uncommon, and often positively cite the paper even when the retraction has been made for misconduct (Bar-Ilan and Halevi 2017). This suggests that most authors are simply not aware of the retracted status of many publications. Of course if you visit the publishers website, you should see a clear notification at the Version of Record (e.g. Figure 33.2), that points to the retraction notice (see Figure 33.3). FIGURE 33.2: You should not cite a retracted paper. Once papers are retracted they dont disappear. They continue to be available at the publishers website, but with a clear notice that they have been retracted (see below). In addition, a separate publication is made announcing the retraction of the work, as shown in Figure 33.3. If you downloaded the article before it was retracted, then you will not be aware of what has happened unless you are following that particular publication. Similarly, if you get your search results from Google Scholar, there is no indication that a paper has been retracted. Contrast this with search results of Scopus and Web of Science, both of which clearly indicate if an article has been retracted. The problem that even highly publicised retractions continue to be cited by articles that follow (Piller 2021). This is likely to be a problem that both authors and editors move on once an article is accepted. Clearly, the community is still responsible for watching what happens to the literature, even once a paper is cited. Of course, the publishers could be using items such as DOIs to track retracted papers and query their citations. 33.2.2 Notification of retraction The notification of retraction is supposed to explain exactly why a paper has been retracted. For example, if you have cited or used this work you should know whether it is because data has been fabricated, or more innocently there was a mistake with the equipment or another aspect of the investigation. However, it seems that some journals are issuing retraction notices that fall short of the guidelines required by COPE (Barbour et al. 2009), and that these delays are not in the interest of anyone involved (see Grey, Avenell, and Bolland 2021). Clearly, there is need for improvement here on the part of the journals. But we must be cautious about playing a blame game when it comes to journal retractions (Smith n.d.). We already know that peer review has shortcomings (see Part IV), and even the best of peer reviewers and/or editors cannot be expected to spot potentially fatal errors, especially when these come about from deliberate deceit on the part of the authors. Retraction will remain a necessary part of the scientific publishing process, and as retractions become more commonplace among journals, we can hope that guidelines will be followed in a timely manor (Grey, Avenell, and Bolland 2021). FIGURE 33.3: You can however, cite the retraction which is published under a separate citation string. You might want to do this as an example of the type of work that is retracted, like the one shown (Costa-Pereira and Pruitt 2020). This retraction notice refers the the Version of Record seen in Figure 33.2. Some literature databases will notify you if a paper that you have in your database is retracted - but dont count on this. What I have learned while looking for data for Figure 33.1, is how poorly Web of Science and Scopus are at tracking retractions. It is unclear to me whether this is because they arent demanding this data explicitly from the publishers, or perhaps because the publishers are hiding the data. For example, for the same 30 year period, Web of Science lists only 133 retractions for this period. Really what this means that if you want to be sure that there hasnt been a retraction in any of your source material, you need to run a search on the Retraction Watch database. Right now, the chance that any paper you have cited will get retracted is still low (one in 500), but it seems likely that it will go up. 33.3 Retraction Watch To learn more about retractions in science, I encourage you to read the blog at Retraction Watch (https://retractionwatch.com/). This will give you an idea of the reasons why retractions are made, and give you some perspectives about the practices (and malpractices) that go on in the scientific environment. 33.4 Fabrication of data The fabrication of data does happen. A growing body of retractions and alleged evidence on the tampering of data in spreadsheets has led to the suspension of a top Canadian researcher, Jonathan Pruitt. The detection of fraudulent (usually duplicated) data in spreadsheets is not too difficult to spot, and has become the subject of some contract data scientists who specialise in finding such instances of fraud. Images are increasingly being used in journals to demonstrate results, and the manipulation of images in published papers appears to be rife. In a study of more than 20000 papers from 40 journals (1995 to 2014), Bik et al. (2016) found that nearly 2% had features suggesting deliberate manipulation. These could include simple duplication of an image from supposedly different experiments, duplication with manipulation (e.g. rotation, reversal, etc.) and duplication with alteration (including adding and subtracting parts of the copied image). The authors suggested that as they only considered these types of manipulations from certain image types, the actual level of image fraud in scientific papers is likely much higher (Bik, Casadevall, and Fang 2016). Some have suggested that the pressure to obtain a permanent academic position is enough to drive some scientists to commit fraud (Husemann et al. 2017; Kun 2018; Fanelli, Costas, and Larivière 2015). The idiom publish or perish, and the importance of publishing will be made later under the chapter about looking for a job. However, I hope that by shedding some light on unethical practices, this book equips you to avoid these together with those that may espouse them, and instead show you that there is a better path to success. Pruitts case highlights a good reason for increased transparency in the publication process. A blog post from someone caught up in the Pruitt retractions makes the point that journals that insisted on full data deposits for publication were well ahead of those that hadnt (Bolnick 2021). Of growing concern in many areas of Biological Sciences is the potential to manipulate results that are essentially images of results, for example blots on a gel. However, it turns out that manipulated images are also not too hard to discern. 33.4.1 Who is responsible? In the case of fraud, retraction statements should indicate who the perpetrator is in order to exonerate the other researchers. Some research into the likely source of the fraud has been conducted. There are clearly serial fraudsters, and the presence of their names in the author list is a red flag for those investigating fraud. Data from papers that are known to be fraudulent suggest that the first author is the most likely to be responsible for the fraud committed, and middle authors the least (Hussinger and Pellens 2019). This suggests that in a collaboration, you should be very careful who you collaborate with. While you might not be responsible, the discovery of (particularly large scale) fraud might well harm your career. In a study looking for patterns about types of authors involved in retractions (all reasons), suggested that Early Career Researchers were particularly likely to be involved in retractions (Fanelli, Costas, and Larivière 2015). 33.5 What to do if you suspect others If you suspect that someone in a lab in your department, faculty or university is fabricating data, find out whether your university has a research integrity officer (RIO); most universities in the US have one. Document your evidence if you can and approach the RIO or person in the equivalent position. If you cant find such a person, then ask at you university library for the most relevant person. Libraries are usually neutral places where you can find out information without arousing suspicion. You do need to be careful that you do not place yourself in harms way when reporting, so be prudent about sharing until you are assured protection from any potential retaliation. It isnt easy to be a whistleblower - but it is the right thing to do. If the research is published, and you think it is fraudulent, approach the editor directly. If there is some conflict of interest (like the person is at your institution), then you can try to sort it out internally (as described above). Otherwise, you can approach the editor directly yourself, anonymously or by using a third party. The Committee on Publication Ethics (COPE) has published some useful flowcharts to guide researchers who suspect fraud in manuscripts or published articles: Image manipulation in a published article (COPE 2018a) How to recognise potential authorship problems (COPE 2018b) Systematic manipulation of the publication process (COPE 2018c) How to recognise potential manipulation of the peer review process (COPE 2017) If you suspect fabricated data in a submitted manuscript (E. Wager 2006a) Ghost, guest, or gift authorship in a submitted manuscript (E. Wager 2006b) Undisclosed conflict of interest in a submitted manuscript in a published article Plagiarism in a submitted manuscript (L. Wager 2006) 33.6 Confirmation Bias and the paradox of high-flying academic careers Jonathan Pruitt had it all going for him. His studies of spider sociality were producing significant results that opened the door to publications in high impact journals. In turn, this opened the door to getting prizes and funding. The funding allowed him to conduct more studies and soon a prestigious chair in Canada with more funding to pursue his rocketing career. Things started to unravel for Pruitt when colleagues raised concern about the data in some of his publications. Things gathered pace very quickly, and doubt gathered around more and more of his publications. Although there is much written about the Pruitt debacle on the internet, the blog by Am. Nat. editor and former Pruitt fan and friend, Dan Bolnick, is particularly enlightening (Bolnick 2021). Pruitts case is becoming increasingly untenable as more editors backed by co-authors are retracting papers where he contributed data (see Marcus 2020). For Pruitt, this has become a threat to his career and livelihood (Pennisi, 2020, and Pm 2020). Similarly, his university is facing the possibility that they hired a fraud. Consequently, this whole debacle has slipped into the legal world. Bolnick has clearly suffered personally from the affair, but has set out to provide as transparent an account as possible. Of note are his assurances to one of Pruitts co-authors to: use transparency to gain community support for the retraction process.  Bolnick (2021) The harrowing part of Bolnicks account is when he, co-authors and other editors started to receive letters from Pruitts Lawyer (see one example on Bolnicks blog). At the point that the layer steps in, the functioning academic community that had raised itself to meet the demands of the concerns began to get muted in what Bolnick calls a chilling effect. Bolnick then makes an important point that the legal threats from Pruitts Lawyer were stifling the freedom for academics (in this case the co-authors and editors) to publish. Another example of a rising star with high profile papers, allegedly making a habit of fabricating data, comes in the world of marine biology (Clark et al. 2020). The researchers in question, Danielle Dixson under the supervision of Philip Munday, made counter-claims that the detractors were unimaginative or that they are attempting to make a career from criticism. Meanwhile, students from their own labs continue to raise concern about the culture of fraud (see Enserink 2021). In this case, the tide of evidence against the marine biologists appears to have turned, with forensic data specialists finding multiple examples of suspect data. Neither case is fully resolved as the cases against these scientists still rest with their institutions. The lives of co-authors, former students and colleagues are put on hold, until some unforeseen point in the future. It is clear from these reports that there are systemic problems when high profile scientists are accused of fraud. Journals say that its the responsibility of the institutions, and the institutions have no impetus to find fraud as that might lose them a very productive (think research income) and high profile scientist. What university would want to have its name dragged through the mud, and on top of this lose a large amount of grant income? Top researchers become untouchables in many institutions because they are essentially cash cows that no-one wants to disturb. Allegations against such individuals also include bullying and sexual misconduct. For those interested in reading more high profile misdemeaners in science Stuart Ritchie (2020) has put together a popular book on the subject. Another important issue that arises from (alleged) scientific fraud is that it creates a culture of research that pushes towards an extremely unlikely hypothesis, in the misbelief that the hypothesis is likely given the nature of the publications (also see Fanelli, Costas, and Ioannidis 2017). Forsmeier et al (2017) have an excellent review that outlines the problems with a culture that pushes towards increasingly unlikely hypotheses (see also J. Measey 2021 on Type I errors). At the heart of all of this is the cult of the Impact Factor and the research mentality that it generates. "],["bullying.html", "Chapter 34 Are you bullying or being bullied? 34.1 How to spot a bully 34.2 What to do about bullying 34.3 What to do if the procedure against bullying at your institution doesnt work?", " Chapter 34 Are you bullying or being bullied? I am going to talk about academic bullying because it is currently prevalent in academia, and because most of the bullies are unaware of what they are doing. In a 2019 survey of graduate students (see here Figure 34.1), 22% felt that they had experienced bullying during their PhD program. The only way of improving the situation around academic bullying is for everyone to become more aware. It may not be happening to you, but it may be happening to people around you either in your lab or in another lab in the same department or faculty. If you think that this is very rare behaviour in academia, think again (Devlin and Marsh 2018). FIGURE 34.1: Responses to a survey of graduate students (in 2019) demonstrates the changes in bullying propensity in different research cultures. 34.1 How to spot a bully A bully is anyone who abuses or misuses their position of power in order to humiliate, denigrate or injure another. This does not need to be your advisor, or someone in your lab. It can be anyone in your working environment (watch the video here or here). These people are usually in positions of power with influence over you and your future. As in my example (below) you may be worried that the power they have could be used by them to negatively impact your future. If you are worried about this, then their behaviour most likely conforms to bullying. Bullying often involves harassment that is designed to undermine your dignity, often through sexism, racism, or another prejudice (Krishna and Soumyaja 2020). Even if you think that your bully didnt mean to cause offence, the fact that they did upset you and that this behaviour was unwanted is enough to fulfil the criteria for bullying. Thus, it is not what they intended, but what you felt that is important in bullying. A direct consequence of this is that bullies often dont recognise this as a description of their behaviour. It is worth bearing in mind that bullies are often damaged individuals who are repeating behaviour that they have themselves experienced from others. This doesnt excuse their behaviour, but they may think that such behaviour is normal. What you should ask yourself is if someone were to observe this behaviour from the outside, would they recognise the interaction as normal or see that something was not correct? Of course, if you observe this going on with someone else in your group, or outside your group. Take the initiative to approach the person after and determine whether they feel like a victim: remember that not all interactions are as they appear from the outside. This is where a good set of institutional rules about bullying is important. 34.2 What to do about bullying First, you need to find the rules that your institution has regarding bullying. If your institution has no rules, then they will need them and so helping them achieve this would be a good place to start (Mahmoudi and Keashly 2021). No one wants to be the first case study, but there may need to be a first in order to set up a protocol. Avoid the bully when asking for your institutional rules, but you should be able to find them via your departmental secretary, administrative support staff in the department or faculty. Read the documentation carefully and learn about how and by whom such reports are dealt with. Become aware of resources that are available; paritymovement.org is a great place to start. Read more about other peoples experiences and be aware that you are not alone Malaga-Trillo and Gerlach (2004). Next, document your case. Make some notes about the incident(s), when they happened, what was said, how you were made to feel and what power you feel the person has over you. Share your burden with a trusted friend or colleague. It is worth sharing the incident with others to see what they think about your predicament. In the survey mentioned above, more than half of the respondents who said that they experienced bullying felt that they could not discuss their experience for fear of reprisals. However, you do not have to discuss it inside the workplace, and often its better to talk to people outside as the context is not so important in bullying. In your description, attempt to strip down the interaction into the component parts. Follow your universitys rules about who to go to with your complaint. Dont leave it to the next person in your lab to experience, they may not be as strong or as resourceful as you. It may not be your career that is destroyed, but the next student might not be so lucky. 34.3 What to do if the procedure against bullying at your institution doesnt work? My worst experience of bullying happened when I was a PhD student. It happened to me, and I witnessed it happening to other members of my lab. It wasnt hard to spot. Students would come out of my advisors office in tears, and recount horrific stories of how he had debased and humiliated them. At the time, our department had no specific code on bullying, but there was a complaints procedure which started with the head of department. Unfortunately, as my advisor was also the head of the department, I could not follow the procedure as it was supposed to be done. Instead, I went to the academic who was responsible for postgraduates. The first two times, that staff member simply went to the head of department (yes, my advisor) and I was called in both times and bullied some more: how dare I complain about him? The last time I tried to complain, once I had finished my PhD and felt much safer from the bully, I went to the dean of the faculty. He was the line manager of my advisor (still head of department) and was a lot more sympathetic. After listening to my story, and how my other lab mates were still suffering, he called them in one by one. And one by one they each denied all of the bullying that had happened. They were afraid. Unlike me, who had finished, they were still relying on their advisor to get their postgraduate degrees. The result was that without any corroborating evidence, there was no case for the dean to take forwards. What should you do if the procedure at your institution doesnt work? You become a survivor. You also become more vigilant against bullying in the future. Whatever happens, dont be tempted to become the bully yourself. Support other survivors and make progress to improve the system for future postgraduate students. Bullying is in human nature, and it wont stop. But we can make people more aware of it, and we can have procedures that work both for the bullied and the bullies. "],["mentalhealth.html", "Chapter 35 Keeping track of your mental health", " Chapter 35 Keeping track of your mental health I have already published this chapter as part of a previous book for PhD students, but I have retained much of the content here as it is clear that mental health is also an important aspect for early career researchers. Stress is a natural part of life and many people are at their most productive when they are under some degree of pressure, such as a deadline. Although deadlines dont work for everyone. Problems arise when we become overwhelmed by stress and are unable to fully respond. When this occurs productivity can drop off and survival responses can be triggered as if responding to an actual physical attack. These responses include fight, flight or freeze responses. Anxiety and panic can be triggered. In this state additional demands on your time may also push your life off balance, so that you start to neglect your personal wellbeing which can negatively impact on relationships, exercise regime, or even nutrition and personal hygiene. Some people can find that the additional stress can cause physical symptoms that may even need medical treatment. Your sense of competence and mastery can be negatively impacted such that you may even suffer from feelings of inadequacy or imposter syndrome. Impostor syndrome is an experience you have when you believe that you are not as competent as you think others perceive you to be. It is not uncommon in many professions, and especially prevalent in academia (Clance and Imes 1978). This is now widely recognised and there are lots of useful shared experience out there to read (e.g. Dickerson 2019). Although there are not many studies on mental health for PhD students, those that exist (as well as surveys: Nature 2019) all suggest that there is a significant toll, which is proportionately higher than for others in society (Levecque et al. 2017). Whatever your prior experience of stress in a working environment, academia is known to be particularly stressful, and as a PhD student you are likely to absorb a significant amount of this stress into your own life (Stubb, Pyhältö, and Lonka 2011). The General Health Questionnaire (see GHQ-12 in Table 35.1) is an instrument used to measure psychological distress. It is quick, reliable and simple to score, so you can use it at any time during your PhD studies as an indicator of whether you need to reach out to personal, occupational or professional support networks. Right now, I suggest you complete the GHQ-12 (Table 35.1) and record your answers as a baseline. Keep the scores somewhere safe. During the course of your PhD, if you feel that your scores may have changed, take the test again and compare them with your baseline scores. Although there are no hard rules, if three or more of your scores have moved by two or more points it could be worth discussing with your support network to help you decide whether or not to seek professional help. TABLE 35.1: A General Health Questionnaire with 12 questions (GHQ-12) that you can use to keep track of your mental health General Health Questionnaire: Have you recently 0 1 2 3 been feeling reasonably happy, all things considered? Better than usual Same as usual Less than usual Much less than usual lost much sleep over worry? Not at all No more than usual More than usual Much more than usual been feeling unhappy and depressed? Not at all No more than usual More than usual Much more than usual felt you couldnt overcome your difficulties? Not at all No more than usual More than usual Much more than usual felt under constant strain? Not at all No more than usual More than usual Much more than usual felt capable of making decisions about things? Better than usual Same as usual Less than usual Much less than usual been able to face up to your problems? Better than usual Same as usual Less than usual Much less than usual been thinking of yourself as a worthless person? Not at all No more than usual More than usual Much more than usual been losing confidence in yourself? Not at all No more than usual More than usual Much more than usual been able to enjoy your normal day-to-day activities? Better than usual Same as usual Less than usual Much less than usual been able to concentrate on whatever you are doing? Better than usual Same as usual Less than usual Much less than usual felt that you are playing a useful part in things? Better than usual Same as usual Less than usual Much less than usual Even if you dont feel you need the support of your institution now, it is worth finding out how they can support your mental health in the future if needed. Although there has been some stigma attached to difficulties with mental health in the past, most institutions accept that pressures are mounting on postgraduate students and that they may require support. Most institutions have experienced councillors available to support you if needed. Importantly, you should realise that none of these symptoms are unusual and that there is a high probability that many of your colleagues may also be struggling. Knowing that your problems are shared and reaching out to support networks early is an excellent way to prevent them from escalating beyond your control. A study into the mental health of PhD students in Belgium exemplifies the kinds of difficulties that they face when compared with other similar groups (Levecque et al. 2017). FIGURE 35.1: You are still high risk for mental health worries even after youve stopped being a student. A comparison of the mental health of PhD students (data from Levecque et al. 2017) with highly educated general population, highly educated employees and higher education students using the General Health Questionnaire. The Risk Ratio (RR: adjusted for age and gender) in PhD students in Flanders, Belgium is consistently higher (&gt;1) when compared to any of the other surveyed groups. No matter how well you think of your own abilities to cope with mental health issues, doing a PhD will cause you additional stress and can trigger maladaptive coping mechanisms. Learning how to cope with additional stress early in your career can be beneficial for future personal development. Academia is recognised as a particularly stressful environment; you will likely take on some of this environmental stress in addition to any stress associated with your studies. Additional stressors come from home and family situations. Your best means of coping will be to try and develop a support network and to understand where and with whom you can discuss any difficulties as they arise. Knowing who this is and how and when to approach them will put you in a stronger position if you need them in future. "],["jobinacademia.html", "Chapter 36 Getting a job inside academia 36.1 Key Insights if you want a career in academia", " Chapter 36 Getting a job inside academia I have already written at the start of this book (see part 1) that competition is high to get jobs in academia and your chances are therefore diminishing. However, academia needs new academics, and so I wanted to try to provide some key insights into what might be important in getting a job as an academic. Of course, there is no single way in, and your path is likely to be different to mine and others that you meet. During lockdown in 2020 my lab held some meetings with invited guests from all over the world. What follows is a list of key insights that came from a meeting with four academics on four continents. if you are interested in getting a job in academia then take a look and consider these. 36.1 Key Insights if you want a career in academia Here is a list of key insights that our team shared. They are in no particular order, but each one probably deserves a lot more information. Academics often suffer from imposter syndrome A suite of skills that are all are required: Need a logical mind: even OCD Good writing skills Computational skills Attention to detail The importance of finishing the job Being creative (not just for arts students) Need to read (a lot) The coolest job in the world as youre paid to learn Research has to be fun Once you have a tenured position metrics are unimportant to you (but remain important to your students!) Have to produce a publication that you are proud of You have to tolerate rejections Papers Conferences Positions Promotions Dont be harsh on yourself - it happens to everyone Dont rely on how people used to get hired, or that positions you see now will become available in the future Dont ignore the importance of natural history observations Write the notes as they demonstrate productivity They make your CV look stronger in the early stages Use them to get things published strategically Dont fill your CV exclusively with these notes (there are more important things) There is still a glass ceiling in employment institutions Things are improving Dont allow comments phase you - many people dont understand their own prejudices or discriminations. Share the down sides, youll find out that lots of other people experience them, and not just you Role models are very useful in science Especially someone with whom you can identify, preferably from your own background Use your network to explore which role model might fit best Someone needs to fit into the context of the job This means that not every job will be right for you as other people might fit better [not the fault of you or your CV] Could be why lots of people get jobs from the inside - they are already known to fit into the team Many institutions pride themselves on their position in the community, and will look fondly on people who are clearly committed to the place. This could include: ++ Speaking the local language ++ Writing popular articles for a local audience ++ Engaging with the local press and media ++ Giving talks to local groups Give back into the faculty or institute - can you demonstrate that you do more than just conduct research and write papers. Are you active in your community (both big - academic community and small - departmental community) Learn about opportunities and take advantage of them [you make your own luck] Many people dont know about opportunities that are out there. Meet people one on one at smaller meetings [big meetings arent good for this] Moving around [in postdocs or between jobs] can make it more difficult to get accepted into some places that have a culture of staying put If you know where you want to be, its worth investing time to that institution and community [but dont count on it!] Try to keep multiple irons in the fire Even though career paths look linear, this is really only in hindsight. In reality they are wondering paths that sometimes wonder right out and back in again Writing small grants isnt a waste of time as it develops this as a skill Grant writing is different to thesis writing or paper writing Having a CV with evidence of lots of grants gained (even if they are small) demonstrates to people that you know this stage of the process Showing that you can finish the same projects and produce outputs is even better Try saying yes to opportunities (especially early on in your career) You never know where it will take you Establish collaborations outside your direct circle Creativity includes reinventing yourself and your science as you move through your career Each grant proposal is to do different work and take you into new paths and directions Some will work out and open up whole new areas or specialities. Others wont Its easier if you can describe exactly what you do early on in your career A very mixed up CV leaves some people unclear about who they are hiring and for what This doesnt mean that you have to be overly focussed, but early on its useful to have a tag (or a few specific categories like systematics, comparative anatomy, natural history to organize your publications if theyre really different from each other) What type of job do you want? Teaching - then get teaching experience Research - then make sure your CV is strong There are more types of jobs out there, but if you know what you want (or dont want) then make sure that your CV reflects this Your first job is not necessarily your last job But it could be if you love it You can use it as a springboard to go elsewhere You might need to take the first job to get somewhere else Learn about what you are good at and embrace it This might require some honest reflection Its totally possible to have a job outside academia and then move back in Some jobs might even give you an advantage in getting an academic position Many academic subjects are applied, and so experience in the relevant jobs really help [industry relevant experience] ++ You may then have inside knowledge to subjects that are taught Maintain your understanding of the field (to get back in) Make sure that there is a continuing narrative, a reason why you left and why this helps you come back in Keep irrelevant jobs off your CV Knowing what you dont want to do can be as helpful as knowing what you do want to do Internships are great opportunities for this Get feedback on the letters that you write when applying for jobs Ask people whether they will give you a letter of reference, and if that will be positive Take note of what the job is asking for and ask specifically for those aspects to be mentioned Different regions of the world have different styles for letters of reference ++ US letters are thorough [and often over the top, even flamboyant] and very long ++ Europeans tend to be understated and more direct ++ Some parts of the world may provide just a few sentences I ask students to draft their own letters that accentuate what they themselves want to underline about their experiences. I wont use the same words, but it will help remind and inform me of what colleagues have done. "],["habilitation.html", "Chapter 37 Habilitation, DSc and Tenure 37.1 Habilitation 37.2 Doctor of Science (DSc) 37.3 Tenure", " Chapter 37 Habilitation, DSc and Tenure These are qualifications post-PhD that exist in some countries and might be prerequisites to getting some positions within academia. I do not go into these in detail here because they are country specific, and you are likely to learn much more about them at the institution where you are conducting your PhD. If you need to do one of these further qualifications, then you are best advised to seek this information within your institution. The brief inclusion here serves as a guide to their existence, and for you to be aware that different rules apply in different countries and that if you are mobile in your career there may be additional steps that are required of you before you can apply for a job or certain promotions. 37.1 Habilitation Habilitation from the Latin habilitare, to make fit, started in Germany first as part of the PhD process, and later as a separate post-doctoral qualification in the 1800s. This process has been adopted by a number of (mostly European) countries as a requisite step in teaching or directing research. In countries where this qualification exists, it is usually a prerequisite before being able to apply as a candidate for a professorship. In some countries, most notably Germany, the habilitation comes after having already held a job as a researcher and lecturer, and comes with a serious expectation that this will lead to a promotion to become a professor. In this way, it could be seen as a similar process to going for tenure in the US. In France, the related qualification is the Habilitation à Diriger des Recherches (Accreditation to Direct Research or HDR). Like the German system, the HDR is applied for by someone who already holds a position as a lecturer (Maître de Conférences) for several years, when they hold sufficient research to put together a portfolio. You need to be accredited with HDR before you can advise PhD students. Ironically, this portfolio should include the supervision of at least one PhD student. Thus, youll need to arrange to be a co-advisor who is actually the main advisor before moving forwards with your HDR portfolio. Given that your first PhD student may take some years to finish (see part 1), this would be worth finding a sympathetic person with an HDR sooner rather than later in once you are in your Maître de Conférences post. In the biological sciences, most requirements for habilitation are cumulative, meaning that you can assemble a set of published research papers that you have written or led. The number and quality of such publications will depend on where you are submitting this thesis, meaning that in some places it may take as long as 10 years. Importantly, the habilitation is not advised. 37.2 Doctor of Science (DSc) In the absence of any requirement for habilitation, there is the possibility (at many universities) of compiling published papers, that you have written or directed, into a thesis that can be examined for a Doctor of Science (DSc). Like the PhD, the DSc allows you to call yourself Doctor (although you likely already can) and put the letters DSc after your name. The DSc is touted as an advanced doctoral degree. You will need to register as you would for a PhD, but in most cases your thesis will not be advised. One interesting point to note is that registration for a DSc need not have possession of a PhD as a prerequisite. If you are in a position where you have never done a PhD, but have worked within or alongside academia, including publishing papers, for a considerable period, you might be in a position to register for a DSc. 37.3 Tenure Obtaining tenure (in the USA and Canada) gives you a special kind of academic freedom such that it is very hard for you to be removed from your post. In some states this means that you are not required to retire (a job for life - although there are increasingly attractive offers for professors to retire). Tenure exists around the need for independent academic freedom: that as an academic scholar you are free to hold your own, scholarly, views and as such cannot be censured by the state. Getting tenure, therefore, at the university where you are employed is an important step, vital if you want to move from contract to permanent employment. In practice, if you dont get tenure it will most likely mean that you wont get to continue at that university: tenure or bust. In order to obtain tenure in most US universities you will need to provide: - A portfolio of peer-reviewed published research - The proven ability to attract grant funding + A significant amount of which goes to the university - Teaching excellence + As assessed by undergraduate and postgraduate students - Academic visibility + The recognition of your research by peers through inclusion in conferences, invitations to give seminars, etc. - Administrative and/or community service + This includes roles such as being an editor for a journal + Peer review for journals and grant awarding bodies + Serving on your universitys committees and panels The relative importance to each of the above aspects will depend on the type of college where you are trying to get tenure. Unsurprisingly, a teaching college will require you to have excellence in teaching, while a research university will place more emphasis on your research portfolio and your standing as an academic in the international community. If you arent from North America, it is important that you know what the priorities of your institution are before you apply for a position, or even before you try to do a postgraduate degree (see part 1). Once you are in an untenured post at a US university, you will have a limited amount of time to achieve the above portfolio in order to achieve tenure. Getting tenure often comes together with promotion (to professor) and a reduction in (undergraduate) teaching load. The time limited nature of getting tenure is such that even after you have received your PhD, this is a much higher hurdle to attain. "],["leavingacademia.html", "Chapter 38 Leaving academia for a job outside 38.1 Key Insights if you are looking for a career outside academia", " Chapter 38 Leaving academia for a job outside In addition to thinking about jobs inside academia we also invited some past members of my lab who have got jobs outside of academia. They also provided us with their key insights into how the world outside academia is different to that inside. Again, if you are thinking about it getting a job outside academia take a look at some of these key insights. 38.1 Key Insights if you are looking for a career outside academia The importance of the networks that they had made during their times as academics. In addition, the importance of how to manage and grow a network. Many jobs these days involve project work, and include generating the funding from donors as well as completing the project and writing the report. Post graduate degrees really help with learning how to start, manage, and complete projects. Although papers and citations gained during academic life wont help with some jobs, they allow flexibility in the job market (potentially to re-join academia). They also demonstrate your ability to write. More papers are likely to improve your chances and some jobs include writing research papers as part of the job. Employers are interested in the experience and skills that youve acquired during your academic work. Instead of just listing papers you need to sell what youve done in cover letters and interviews: What kind of experience do you have with your specialist area? Do you understand about management? Do you have good organisational skills? Have you done fieldwork? Have you managed students? Regardless of your academic background, you should expect to enter into your job at quite a junior level or even as an intern, and then work your way up Employers are looking for emotional intelligence (the ability to understand and manage your own emotions, and those of the people around you). They will expect you to be a good team member, work with different stakeholders and clients. Conflict management skills are important. You might not need to wait for a job advert. Use your contacts and write to people who are employers You might need to become comfortable with feeling uncomfortable: your work might be so different from what youve done before that you should and you should be able to adapt There are expectations from employers that you will meet challenges that your employers place before you (and not shy away) Pay special attention to the Key Performance Areas (KPAs) of the position you apply for. These are what you will need to report on in order to have your performance in your job assessed. You might need to get used to different working cultures that are meeting focussed (even when you have meetings about having meetings) The working culture might not be static, and could change with the replacement of a manager or director. If you are employed by a governmental agency, it will be expected that you are accountable to your employers as well as the public that pays through their taxes The position you are employed in will likely involve you constantly acquiring new skills, such that you feel like more of a student then when you were studying. This really adds to the interest in the working life, and allows you to meet new and unexpected challenges. New subjects and other areas might be well outside your expertise, but can be just as rewarding once you rise to meet the challenges. Jobs outside academia are especially challenging in working out how to apply the results of scientific studies. Your employers might expect you to conceive your projects, as well as carrying them out. You are expected to be an authority in your work, and interpret your results in context and with reasonable confidence At the end of the day, you need to discuss what you want and what you expect from your job outside academia with as many people as possible in that profession. "],["lastnote.html", "Last note", " Last note I really hope that this book has been helpful and that it has achieved what I set out to do: provide you with the guide on how to write a PhD in biological sciences. If you feel that this book has important items missing, out-of-date or simply wrong, then please help. Any good guide relies upon the people that use it to keep it viable. You can contribute to the project at the Github pages for this book, using bookdown. If I could emphasise one really important aspect of all of your PhD studies; that is to enjoy them! "],["references.html", "References", " References Abdill, Richard J, and Ran Blekhman. 2019. Tracking the Popularity and Outcomes of All bioRxiv Preprints. Edited by Emma Pewsey, Peter Rodgers, and Casey S Greene. eLife 8 (April): e45133. https://doi.org/10.7554/eLife.45133. Adam, David. 2002. The Counting House. Nature 415 (6873): 72629. https://doi.org/10.1038/415726a. Adams, Jonathan. 2012. The Rise of Research Networks. Nature 490 (7420): 33536. https://doi.org/https://doi.org/10.1038/490335a. Aksnes, Dag W. 2003. A Macro Study of Self-Citation. Scientometrics 56 (2): 23546. https://doi.org/10.1023/A:1021919228368. Anderson, J, and et al. 2021. Campaign to Investigate the Academic Ebook Market. Campaign to Investigate the Academic Ebook Market. https://academicebookinvestigation.org/. Anderson, Melissa S., Brian C. Martinson, and Raymond De Vries. 2007. Normative Dissonance in Science: Results from a National Survey of US Scientists. Journal of Empirical Research on Human Research Ethics 2 (4): 314. https://doi.org/DOI: 10.1525/jer.2007.2.4.3. Anon. 2018. Retraction. Behavioral Ecology 29 (2): 5088. https://doi.org/10.1093/beheco/ary014. Arms, William Y. 2002. What Are The Alternatives To Peer Review? Quality Control in Scholarly Publishing on the Web. Journal of Electronic Publishing 8 (1). https://doi.org/https://doi.org/10.3998/3336451.0008.103. Baglini, Rebekah, and Christine Parsons. 2020. If You Cant Be Kind in Peer Review, Be Neutral. Nature, November, d41586-020-03394-y. https://doi.org/10.1038/d41586-020-03394-y. Baker, M. 2016. 1,500 Scientists Lift the Lid on Reproducibility : Nature News &amp; Comment. Nature 533: 45254. https://doi.org/doi:10.1038/533452a. Barbour, Virginia, Sabine Kleinert, Elizabeth Wager, and Steven Yentis. 2009. Guidelines for Retracting Articles. Committee on Publication Ethics. https://doi.org/10.24318/cope.2019.1.4. Bar-Ilan, Judit, and Gali Halevi. 2017. Post Retraction Citations in Context: A Case Study. Scientometrics 113 (1): 54765. https://doi.org/10.1007/s11192-017-2242-0. Barnett, Adrian, Inger Mewburn, and Sara Schroter. 2019. Working 9 to 5, Not the Way to Make an Academic Living: Observational Analysis of Manuscript and Peer Review Submissions over Time. BMJ, December, l6460. https://doi.org/10.1136/bmj.l6460. Baskin, Patricia K., and Robert A. Gross. 2011. Honorary and Ghost Authorship. BMJ. https://doi.org/https://doi.org/10.1136/bmj.d6223. Baxter-Gilbert, James, Julia L. Riley, Carla Wagener, Nitya P. Mohanty, and John Measey. 2020. Shrinking Before Our Isles: The Rapid Expression of Insular Dwarfism in Two Invasive Populations of Guttural Toad (Sclerophrys Gutturalis). Biology Letters 16 (11): 20200651. https://doi.org/10.1098/rsbl.2020.0651. Bergstrom, Carl T., and Theodore C. Bergstrom. 2006. The Economics of Ecology Journals. Frontiers in Ecology and the Environment 4 (9): 48895. https://doi.org/https://doi.org/10.1890/1540-9295(2006)4[488:TEOEJ]2.0.CO;2. Bett, Harry Kipkemoi. 2020. Predatory Publishing Through McCornarcks Information Manipulation Theory. Global Knowledge, Memory and Communication 69 (4/5): 33139. https://doi.org/10.1108/GKMC-07-2019-0078. Bik, Elisabeth M., Arturo Casadevall, and Ferric C. Fang. 2016. The Prevalence of Inappropriate Image Duplication in Biomedical Research Publications. mBio 7 (3). https://doi.org/10.1128/mBio.00809-16. Björk, Bo-Christer, and David Solomon. 2015. Article Processing Charges in OA Journals: Relationship Between Price and Quality. Scientometrics 103 (2): 37385. https://doi.org/10.1007/s11192-015-1556-z. Bolnick, Dan. 2021. 17 Months. Eco-Evo Evo-Eco. https://ecoevoevoeco.blogspot.com/2021/05/17-months.html. Bornmann, Lutz, Ruediger Mutz, and Robin Haunschild. 2020. Growth Rates of Modern Science: A Latent Piecewise Growth Curve Approach to Model Publication Numbers from Established and New Literature Databases. arXiv Preprint arXiv:2012.07675. https://arxiv.org/abs/2012.07675v1. Bornmann, Lutz, Markus Wolf, and Hans-Dieter Daniel. 2012. Closed Versus Open Reviewing of Journal Manuscripts: How Far Do Comments Differ in Language Use? Scientometrics 91 (3): 84356. https://doi.org/10.1007/s11192-011-0569-5. Brainard, Jeffrey, and Jia You. 2018. What a Massive Database of Retracted Papers Reveals about Science Publishings Death Penalty. Science, October. https://doi.org/10.1126/science.aav8384. Braun, Tibor, and Ildikó Dióspatonyi. 2005. Counting the Gatekeepers of International Science Journals a Worthwhile Science Indicator. Current Science 89 (9): 154851. https://www.jstor.org/stable/24110926. Bravo, Giangiacomo, Mike Farjam, Francisco Grimaldo Moreno, Aliaksandr Birukou, and Flaminio Squazzoni. 2018. Hidden Connections: Network Effects on Editorial Decisions in Four Computer Science Journals. Journal of Informetrics 12 (1): 10112. https://doi.org/https://doi.org/10.1016/j.joi.2017.12.002. Brembs, Björn, Katherine Button, and Marcus Munafò. 2013. Deep Impact: Unintended Consequences of Journal Rank. Frontiers in Human Neuroscience 7. https://doi.org/10.3389/fnhum.2013.00291. Brock, William H. 1980. The Development of Commercial Science Journals in Victorian Britain. Development of Science Publishing in Europe, 95122. Brown, J. 2010. An Introduction to Overlay Journals. Report. UK: Repositories Support Project. http://www.rsp.ac.uk/pubs/. Budden, Amber E., Tom Tregenza, Lonnie W. Aarssen, Julia Koricheva, Roosa Leimu, and Christopher J. Lortie. 2008. Double-Blind Review Favours Increased Representation of Female Authors. Trends in Ecology &amp; Evolution 23 (1): 46. https://doi.org/10.1016/j.tree.2007.07.008. Budzinski, Oliver, Thomas Grebel, Jens Wolling, and Xijie Zhang. 2020. Drivers of Article Processing Charges in Open Access. Scientometrics 124 (3): 21852206. https://doi.org/10.1007/s11192-020-03578-3. Buranyi, S. 2017. Is the Staggeringly Profitable Business of Scientific Publishing Bad for Science? The Guardian. https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science. Casadevall, Arturo, and Ferric C Fang. 2012. Reforming Science: Methodological and Cultural Reforms. Infection and Immunity 80 (3): 89196. https://doi.org/10.1128/IAI.06183-11. Casnici, Niccolò, Francisco Grimaldo, Nigel Gilbert, Pierpaolo Dondio, and Flaminio Squazzoni. 2017. Assessing Peer Review by Gauging the Fate of Rejected Manuscripts: The Case of the Journal of Artificial Societies and Social Simulation. Scientometrics 113 (1): 53346. https://doi.org/https://doi.org/10.1007/s11192-017-2241-1. Ceci, Stephen J., and Douglas P. Peters. 1982. Peer Review: A Study of Reliability. Change 14 (6): 4448. https://www.jstor.org/stable/40164010. Chorus, Caspar, and Ludo Waltman. 2016. A Large-Scale Analysis of Impact Factor Biased Journal Self-Citations. PLOS ONE 11 (8): e0161021. https://doi.org/10.1371/journal.pone.0161021. Clance, Pauline Rose, and Suzanne Ament Imes. 1978. The Imposter Phenomenon in High Achieving Women: Dynamics and Therapeutic Intervention. Psychotherapy: Theory, Research &amp; Practice 15 (3): 24147. https://doi.org/10.1037/h0086006. Clark, Timothy D., Graham D. Raby, Dominique G. Roche, Sandra A. Binning, Ben Speers-Roesch, Fredrik Jutfelt, and Josefin Sundin. 2020. Ocean Acidification Does Not Impair the Behaviour of Coral Reef Fishes. Nature 577 (7790): 37075. https://doi.org/10.1038/s41586-019-1903-y. COPE. 2017. How to Spot Potential Manipulation of the Peer Review Process. Committee on Publication Ethics. https://doi.org/10.24318/cope.2019.2.15. . 2018a. What to Do If You Suspect Image Manipulation in a Published Article. Committee on Publication Ethics; Springer Nature. https://doi.org/10.24318/cope.2019.2.21. . 2018b. How to Recognise Potential Authorship Problems. Committee on Publication Ethics. https://doi.org/10.24318/cope.2019.2.22. . 2018c. Systematic Manipulation of the Publication Process. Committee on Publication Ethics; Springer Nature. https://doi.org/10.24318/cope.2019.2.23. Costa-Pereira, Raul, and Jonathan Pruitt. 2020. Retraction: Behaviour, Morphology and Microhabitat Use: What Drives Individual Niche Variation? Biology Letters 16 (8). https://doi.org/10.1098/rsbl.2020.0588. Crijns, Tom J., Janna S. E. Ottenhoff, and David Ring. 2021. The Effect of Peer Review on the Improvement of Rejected Manuscripts. Accountability in Research 0 (0): 111. https://doi.org/10.1080/08989621.2020.1869547. Cronin, Blaise. 2001. Hyperauthorship: A Postmodern Perversion or Evidence of a Structural Shift in Scholarly Communication Practices? Journal of the American Society for Information Science and Technology 52 (7): 55869. https://doi.org/https://doi.org/10.1002/asi.1097. Davarpanah, Mohammad Reza, and Farzaneh Amel. 2009. Author Self-Citation Pattern in Science. Library Review 58 (4): 3019. https://doi.org/https://doi.org/10.1108/00242530910952846. Davies, Phil. 2019. Is PLOS Running Out Of Time? Financial Statements Suggest Urgency To Innovate. The Scholarly Kitchen. https://scholarlykitchen.sspnet.org/2019/11/22/is-plos-running-out-of-time/. Day, Nancy Evelyn. 2011. The Silent Majority: Manuscript Rejection and Its Impact on Scholars. Academy of Management Learning &amp; Education 10 (4): 70418. https://doi.org/10.5465/amle.2010.0027. Deutz, Daniella Bayle, Thea Marie Drachen, Dorte Drongstrup, Niels Opstrup, and Charlotte Wien. 2021. Quantitative Quality: A Study on How Performance-Based Measures May Change the Publication Patterns of Danish Researchers. Scientometrics 126 (4): 330320. https://doi.org/10.1007/s11192-021-03881-7. Devlin, Hannah, and Sarah Marsh. 2018. Hundreds of Academics at Top UK Universities Accused of Bullying. The Guardian, September. http://www.theguardian.com/education/2018/sep/28/academics-uk-universities-accused-bullying-students-colleagues. Dickerson, Desiree. 2019. How I Overcame Impostor Syndrome After Leaving Academia. Nature 574 (7779): 58888. https://doi.org/10.1038/d41586-019-03036-y. Dondio, Pierpaolo, Niccolò Casnici, Francisco Grimaldo, Nigel Gilbert, and Flaminio Squazzoni. 2019. The Invisible Hand of Peer Review: The Implications of Author-Referee Networks on Peer Review in a Scholarly Journal. Journal of Informetrics 13 (2): 70816. https://doi.org/10.1016/j.joi.2019.03.018. Dongen, Stefan Van. 2011. Associations Between Asymmetry and Human Attractiveness: Possible Direct Effects of Asymmetry and Signatures of Publication Bias. Annals of Human Biology 38 (3): 31723. https://doi.org/10.3109/03014460.2010.544676. Drvenica, Ivana, Giangiacomo Bravo, Lucija Vejmelka, Aleksandar Dekanski, and Olgica Nedi. 2019. Peer Review of Reviewers: The Authors Perspective. Publications 7 (1): 1. https://doi.org/10.3390/publications7010001. Ducarme, Frédéric, Gloria Luque, and Franck Courchamp. 2013. What Are \"Charismatic Species\" for Conservation Biologists ? BioSciences Master Reviews 1 (July): 18. Eck, Nees Jan van, and Ludo Waltman. 2010. Software Survey: VOSviewer, a Computer Program for Bibliometric Mapping. Scientometrics 84 (2): 52338. https://doi.org/10.1007/s11192-009-0146-3. Egghe, Leo. 2006. Theory and Practise of the g-Index. Scientometrics 69 (1): 13152. https://doi.org/10.1007/s11192-006-0144-7. Eisen, Michael B, Anna Akhmanova, Timothy E Behrens, Diane M Harper, Detlef Weigel, and Mone Zaidi. 2020. Implementing a \"Publish, Then Review\" Model of Publishing. eLife 9 (December): e64910. https://doi.org/10.7554/eLife.64910. Ellender, Bruce, and Olaf Weyl. 2014. A Review of Current Knowledge, Risk and Ecological Impacts Associated with Non-Native Freshwater Fish Introductions in South Africa. Aquatic Invasions 9 (2): 11732. https://doi.org/10.3391/ai.2014.9.2.01. Else, Holly. 2021. Open-Access Publisher PLOS Pushes to Extend Clout Beyond Biomedicine. Nature 593 (7860): 48990. https://doi.org/10.1038/d41586-020-01907-3. Enserink, Martin. 2021. Does Ocean Acidification Alter Fish Behavior? Fraud Allegations Create a Sea of Doubt. Science AAAS. https://www.sciencemag.org/news/2021/05/does-ocean-acidification-alter-fish-behavior-fraud-allegations-create-sea-doubt. Eve, Martin Paul, Cameron Neylon, Daniel Paul ODonnell, Samuel Moore, Robert Gadie, Victoria Odeniyi, and Shahina Parvin. 2021. Reading Peer Review: PLOS ONE and Institutional Change in Academia. Elements in Publishing and Book Culture, January. https://doi.org/10.1017/9781108783521. Eysenbach, Gunther. 2019. Celebrating 20 Years of Open Access and Innovation at JMIR Publications. Journal of Medical Internet Research 21 (12): e17578. https://doi.org/10.2196/17578. Fanelli, Daniele. 2010. Positive Results Increase down the Hierarchy of the Sciences. PloS One 5 (4): e10068. https://doi.org/https://doi.org/10.1371/journal.pone.0010068. . 2012. Negative Results Are Disappearing from Most Disciplines and Countries. Scientometrics 90 (3): 891904. https://doi.org/10.1007/s11192-011-0494-7. Fanelli, Daniele, Rodrigo Costas, and John P. A. Ioannidis. 2017. Meta-Assessment of Bias in Science. Proceedings of the National Academy of Sciences 114 (14): 371419. https://doi.org/10.1073/pnas.1618569114. Fanelli, Daniele, Rodrigo Costas, and Vincent Larivière. 2015. Misconduct Policies, Academic Culture and Career Stage, Not Gender or Pressures to Publish, Affect Scientific Integrity. PLOS ONE 10 (6): e0127556. https://doi.org/10.1371/journal.pone.0127556. Fanelli, Daniele, and Vincent Larivière. 2016. Researchers Individual Publication Rate Has Not Increased in a Century. PLOS ONE 11 (3): e0149504. https://doi.org/10.1371/journal.pone.0149504. Fang, Ferric C., and Arturo Casadevall. 2011. Retracted Science and the Retraction Index. Infection and Immunity 79 (10): 385559. https://doi.org/10.1128/IAI.05661-11. . 2012. Reforming Science: Structural Reforms. Infection and Immunity 80 (3): 897901. https://doi.org/10.1128/IAI.06184-11. Fang, Ferric C., R. Grant Steen, and Arturo Casadevall. 2012. Misconduct Accounts for the Majority of Retracted Scientific Publications. Proceedings of the National Academy of Sciences 109 (42): 1702833. https://doi.org/10.1073/pnas.1212247109. Fang, Ferric C, Anthony Bowen, and Arturo Casadevall. 2016. NIH Peer Review Percentile Scores Are Poorly Predictive of Grant Productivity. eLife 5 (February): e13323. https://doi.org/10.7554/eLife.13323. Field, Andy. 2013. Discovering Statistics Using IBM SPSS Statistics. SAGE. Forstmeier, Wolfgang, Eric-Jan Wagenmakers, and Timothy H Parker. 2017. Detecting and Avoiding Likely False-Positive Findingsa Practical Guide. Biological Reviews 92 (4): 194168. https://doi.org/https://doi.org/10.1111/brv.12315. Fox, Charles W., and C. E. Timothy Paine. 2019. Gender Differences in Peer Review Outcomes and Manuscript Impact at Six Journals of Ecology and Evolution. Ecology and Evolution 9 (6): 3599619. https://doi.org/https://doi.org/10.1002/ece3.4993. Franco, Annie, Neil Malhotra, and Gabor Simonovits. 2014. Publication Bias in the Social Sciences: Unlocking the File Drawer. Science 345 (6203): 15025. https://doi.org/DOI: 10.1126/science.1255484. Galipeau, James, Virginia Barbour, Patricia Baskin, Sally Bell-Syer, Kelly Cobey, Miranda Cumpston, Jon Deeks, et al. 2016. A Scoping Review of Competencies for Scientific Editors of Biomedical Journals. BMC Medicine 14 (1): 16. https://doi.org/10.1186/s12916-016-0561-2. Garfield, Eugene. 1999. Journal Impact Factor: A Brief Review. CMAJ 161 (8): 97980. https://www.cmaj.ca/content/161/8/979. Glonti, Ketevan, Daniel Cauchi, Erik Cobo, Isabelle Boutron, David Moher, and Darko Hren. 2019. A Scoping Review on the Roles and Tasks of Peer Reviewers in the Manuscript Review Process in Biomedical Journals. BMC Medicine 17 (1): 118. https://doi.org/10.1186/s12916-019-1347-0. Goyanes, Manuel, and Marton Demeter. 2020. How the Geographic Diversity of Editorial Boards Affects What Is Published in JCR-Ranked Communication Journals. Journalism &amp; Mass Communication Quarterly 97 (4): 112348. https://doi.org/10.1177/1077699020904169. Goyes Vallejos, Johana. 2021. Whats in a Name? Science 372 (6543): 75454. https://doi.org/10.1126/science.372.6543.754. Gray, Russell J. 2020. Sorry, Were Open: Golden Open-Access and Inequality in Non-Human Biological Sciences. Scientometrics 124: 166375. https://doi.org/https://doi.org/10.1007/s11192-020-03540-3. Grey, Andrew, Alison Avenell, and Mark Bolland. 2021. Timeliness and Content of Retraction Notices for Publications by a Single Research Group. Accountability in Research 0 (0): 132. https://doi.org/10.1080/08989621.2021.1920409. Hagve, Martin. 2020. The Money Behind Academic Publishing. Tidsskrift for Den Norske Legeforening, August. https://doi.org/10.4045/tidsskr.20.0118. Harington, Robert M. 2020. The Importance of Scholarly Societies for Research and Community Support. FASEB BioAdvances 2 (9): 57374. https://doi.org/https://doi.org/10.1096/fba.2020-00053. Haustein, Stefanie, Timothy D. Bowman, and Rodrigo Costas. 2015. When Is an Article Actually Published? An Analysis of Online Availability, Publication, and Indexation Dates. arXiv:1505.00796 [Cs], May. http://arxiv.org/abs/1505.00796. Haynes, Alex B., Thomas G. Weiser, William R. Berry, Stuart R. Lipsitz, Abdel-Hadi S. Breizat, E. Patchen Dellinger, Teodoro Herbosa, et al. 2009. A Surgical Safety Checklist to Reduce Morbidity and Mortality in a Global Population. New England Journal of Medicine 360 (5): 49199. https://doi.org/10.1056/NEJMsa0810119. Heesen, Remco, and Liam Kofi Bright. 2020. Is Peer Review a Good Idea? The British Journal for the Philosophy of Science, December, 000000. https://doi.org/10.1093/bjps/axz029. Helmer, Markus, Manuel Schottdorf, Andreas Neef, and Demian Battaglia. 2017. Gender Bias in Scholarly Peer Review. Elife 6: e21718. https://doi.org/DOI: 10.7554/eLife.21718. Helmer, Sven, David B. Blumenthal, and Kathrin Paschen. 2020. What Is Meaningful Research and How Should We Measure It? Scientometrics 125 (1): 15369. https://doi.org/10.1007/s11192-020-03649-5. Heneberg, Petr. 2016. From Excessive Journal Self-Cites to Citation Stacking: Analysis of Journal Self-Citation Kinetics in Search for Journals, Which Boost Their Scientometric Indicators. PLOS ONE 11 (4): e0153730. https://doi.org/10.1371/journal.pone.0153730. Hirsch, Jorge E. 2005. An Index to Quantify an Individuals Scientific Research Output. Proceedings of the National Academy of Sciences 102 (46): 1656972. https://doi.org/https://doi.org/10.1073/pnas.0507655102. Hopewell, Sally, Claudia M. Witt, Klaus Linde, Katja Icke, Olubusola Adedire, Shona Kirtley, and Douglas G. Altman. 2018. Influence of Peer Review on the Reporting of Primary Outcome(s) and Statistical Analyses of Randomised Trials. Trials 19 (1): 30. https://doi.org/10.1186/s13063-017-2395-4. Huisman, Janine, and Jeroen Smits. 2017. Duration and Quality of the Peer Review Process: The Authors Perspective. Scientometrics 113 (1): 63350. https://doi.org/10.1007/s11192-017-2310-5. Husemann, Martin, Rebecca Rogers, Sebastian Meyer, and Jan Christian Habel. 2017. Publicationism and Scientists Satisfaction Depend on Gender, Career Stage and the Wider Academic System. Palgrave Communications 3 (1): 110. https://doi.org/https://doi.org/10.1057/palcomms.2017.32. Hussinger, Katrin, and Maikel Pellens. 2019. Scientific Misconduct and Accountability in Teams. PLOS ONE 14 (5): e0215962. https://doi.org/10.1371/journal.pone.0215962. Hyland, Ken, and Feng (Kevin) Jiang. 2020. This Work Is Antithetical to the Spirit of Research: An Anatomy of Harsh Peer Reviews. Journal of English for Academic Purposes 46 (July): 100867. https://doi.org/10.1016/j.jeap.2020.100867. Ioannidis, John P. A. 2008. Measuring Co-Authorship and Networking-Adjusted Scientific Impact. PLOS ONE 3 (7): e2778. https://doi.org/10.1371/journal.pone.0002778. Ioannidis, John P. A., Kevin Boyack, and Paul F. Wouters. 2016. Citation Metrics: A Primer on How (Not) to Normalize. PLOS Biology 14 (9): e1002542. https://doi.org/10.1371/journal.pbio.1002542. Ioannidis, John PA, and Brett D. Thombs. 2019. A Users Guide to Inflated and Manipulated Impact Factors. European Journal of Clinical Investigation 49 (9): e13151. https://doi.org/https://doi.org/10.1111/eci.13151. Jefferson, Tom, Philip Alderson, Elizabeth Wager, and Frank Davidoff. 2002. Effects of Editorial Peer Review: A Systematic Review. JAMA 287 (21): 278486. https://doi.org/DOI: 10.1001/jama.287.21.2784. Jiang, Shan. 2021. Understanding Authors Psychological Reactions to Peer Reviews: A Text Mining Approach. Scientometrics, May. https://doi.org/10.1007/s11192-021-04032-8. Jinha, Arif E. 2010. Article 50 Million: An Estimate of the Number of Scholarly Articles in Existence. Learned Publishing 23 (3): 25863. https://doi.org/https://doi.org/10.1087/20100308. Khoo, Shaun. 2018. There Is Little Evidence to Suggest Peer Reviewer Training Programmes Improve the Quality of Reviews. Impact of Social Sciences. https://blogs.lse.ac.uk/impactofsocialsciences/2018/05/23/there-is-little-evidence-to-suggest-peer-reviewer-training-programmes-improve-the-quality-of-reviews/. . 2019. Article Processing Charge Hyperinflation and Price Insensitivity: An Open Access Sequel to the Serials Crisis. LIBER Quarterly 29 (1): 118. https://doi.org/10.18352/lq.10280. Kidwell, Mallory C., Ljiljana B. Lazarevi, Erica Baranski, Tom E. Hardwicke, Sarah Piechowski, Lina-Sophia Falkenberg, Curtis Kennett, et al. 2016. Badges to Acknowledge Open Practices: A Simple, Low-Cost, Effective Method for Increasing Transparency. PLOS Biology 14 (5): e1002456. https://doi.org/10.1371/journal.pbio.1002456. Kriegeskorte, Nikolaus, Alexander Walther, and Diana Deca. 2012. An Emerging Consensus for Open Evaluation: 18 Visions for the Future of Scientific Publishing. Frontiers in Computational Neuroscience 6: 94. https://doi.org/https://doi.org/10.3389/fncom.2012.00094. Krishna, Arathi, and Devi Soumyaja. 2020. Playing Safe GamesThematic Analysis of Victims Perspectives on Gendered Bullying in Academia. Journal of Aggression, Conflict and Peace Research 12 (4): 197208. https://doi.org/https://doi.org/10.1108/JACPR-03-2020-0478. Kun, Ádám. 2018. Publish and Who Should Perish: You or Science? Publications 6 (2): 18. https://doi.org/10.3390/publications6020018. Larivière, Vincent, and Rodrigo Costas. 2016. How Many Is Too Many? On the Relationship Between Research Productivity and Impact. PLOS ONE 11 (9): e0162709. https://doi.org/10.1371/journal.pone.0162709. Larivière, Vincent, Stefanie Haustein, and Philippe Mongeon. 2015. Big Publishers, Bigger Profits: How the Scholarly Community Lost the Control of Its Journals, no. 2: 9. Lee, Carole J., Cassidy R. Sugimoto, Guo Zhang, and Blaise Cronin. 2013. Bias in Peer Review. Journal of the American Society for Information Science and Technology 64 (1): 217. https://doi.org/DOI: 10.1002/asi.22784. Levecque, Katia, Frederik Anseel, Alain De Beuckelaer, Johan Van der Heyden, and Lydia Gisle. 2017. Work Organization and Mental Health Problems in PhD Students. Research Policy 46 (4): 86879. https://doi.org/https://doi.org/10.1016/j.respol.2017.02.008. Link, Ann M. 1998. US and Non-US Submissions: An Analysis of Reviewer Bias. JAMA 280 (3): 246. https://doi.org/10.1001/jama.280.3.246. Lund, Brady D., and Ting Wang. 2020. An Analysis of Spam from Predatory Publications in Library and Information Science. Journal of Scholarly Publishing 52 (1): 3545. https://doi.org/10.3138/jsp.52.1.03. Mahmoudi, Morteza. 2020. A Survivors Guide to Academic Bullying. Nature Human Behaviour 4 (11): 109191. https://doi.org/https://doi.org/10.1038/s41562-020-00937-1. Mahmoudi, Morteza, and Loraleigh Keashly. 2021. Filling the Space: A Framework for Coordinated Global Actions to Diminish Academic Bullying. Angewandte Chemie 133 (7): 337884. https://doi.org/https://doi.org/10.1002/anie.202009270. Mahoney, Michael J. 1977. Publication Prejudices: An Experimental Study of Confirmatory Bias in the Peer Review System. Cognitive Therapy and Research 1 (2): 16175. https://doi.org/10.1007/BF01173636. Malaga-Trillo, Edward, and Gabriele Gerlach. 2004. Meyer Case Poses a Challenge to the System. Nature 431 (7008): 5056. https://doi.org/https://doi.org/10.1038/431505b. Manlove, Kezia R., and Rebecca M. Belou. 2018. Authors and Editors Assort on Gender and Geography in High-Rank Ecological Publications. PLOS ONE 13 (2): e0192481. https://doi.org/10.1371/journal.pone.0192481. Marcus, Author Adam. 2020. Spider Researcher Uses Legal Threats, Public Records Requests to Prevent Retractions. Retraction Watch. https://retractionwatch.com/2020/08/20/spider-researcher-uses-legal-threats-public-records-requests-to-halt-correction-of-the-record/. Marks, Michael S., Mark Marsh, Trina A. Schroer, and Tom H. Stevens. 2013. Misuse of Journal Impact Factors in Scientific Assessment. Traffic 14: 61112. https://doi.org/https://doi.org/10.1111/tra.12075. Marshall, Benjamin Michael, and Colin Thomas Strine. 2021. Make Like a Glass Frog: In Support of Increased Transparency in Herpetology. Herpetological Journal 31 (1). https://doi.org/https://doi.org/10.33256/31.1.3545. Martin, Ben R. 2016. Editors JIF-Boosting Stratagems  Which Are Appropriate and Which Not? Research Policy 45 (1): 17. https://doi.org/10.1016/j.respol.2015.09.001. Matheson, Alastair. 2016. Ghostwriting: The Importance of Definition and Its Place in Contemporary Drug Marketing. BMJ 354 (August): i4578. https://doi.org/10.1136/bmj.i4578. Mayden, Kelley D. 2012. Peer Review: Publications Gold Standard. Journal of the Advanced Practitioner in Oncology 3 (2): 11722. https://doi.org/DOI: 10.6004/jadpro.2012.3.2.8. McKiernan, Erin C., Lesley A. Schimanski, Carol Muñoz Nieves, Lisa Matthias, Meredith T. Niles, and Juan Pablo Alperin. 2019. Use of the Journal Impact Factor in Academic Review, Promotion, and Tenure Evaluations. e27638v2. PeerJ Inc. https://doi.org/10.7287/peerj.preprints.27638v2. McPeek, Mark A., Donald L. Deangelis, Ruth G. Shaw, Allen J. Moore, Mark D. Rausher, Donald R. Strong, Aaron M. Ellison, et al. 2009. The Golden Rule of Reviewing. American Naturalist 173 (5): E15558. https://doi.org/10.1086/598847. Measey, G. John, Ben C. Stevenson, Tanya Scott, Res Altwegg, and David L. Borchers. 2017. Counting Chirps: Acoustic Monitoring of Cryptic Frogs. Journal of Applied Ecology 54 (3): 894902. https://doi.org/https://doi.org/10.1111/1365-2664.12810. Measey, John. 2011. The Past, Present and Future of African Herpetology. African Journal of Herpetology 60 (2): 89100. https://doi.org/10.1080/21564574.2011.628413. . 2018. Europes Plan S Could Raise Everyone Elses Publication Paywall. Nature 562 (7728): 49494. https://doi.org/10.1038/d41586-018-07152-z. . 2021. How to Write a PhD in Biological Sciences: A Guide for the Uninitiated. http://www.howtowriteaphd.org/. Metze, Konradin. 2010. Bureaucrats, Researchers, Editors, and the Impact Factor: A Vicious Circle That Is Detrimental to Science. Clinics 65 (10): 93740. https://doi.org/10.1590/S1807-59322010001000002. Mouton, Johann, and Astrid Valentine. 2017. The Extent of South African Authored Articles in Predatory Journals. South African Journal of Science 113 (7-8): 19. https://doi.org/10.17159/sajs.2017/20170010. Munafò, M. R., I. J. Matheson, and J. Flint. 2007. Association of the Drd2 Gene Taq1A Polymorphism and Alcoholism: A Meta-Analysis of CaseControl Studies and Evidence of Publication Bias. Molecular Psychiatry 12 (5): 45461. https://doi.org/10.1038/sj.mp.4001938. Munafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017. A Manifesto for Reproducible Science. Nature Human Behaviour 1 (1): 19. https://doi.org/10.1038/s41562-016-0021. Nuñez, Martin A., and Tatsuya Amano. 2021. Monolingual Searches Can Limit and Bias Results in Global Literature Reviews. Nature Ecology &amp; Evolution 5 (3): 26464. https://doi.org/10.1038/s41559-020-01369-w. OCarroll, C, Niamh Brennan, B Hyllseth, U Kohl, G ONeill, and R Van Den Berg. 2017. Providing Researchers with the Skills and Competencies They Need to Practise Open Science: Open Science Skills Working Group Report. Report. European Commission DG-RTG. http://www.tara.tcd.ie/handle/2262/89492. Okike, Kanu, Kevin T. Hug, Mininder S. Kocher, and Seth S. Leopold. 2016. Single-Blind Vs Double-Blind Peer Review in the Setting of Author Prestige. JAMA 316 (12): 1315. https://doi.org/10.1001/jama.2016.11014. Oransky, Author Ivan. 2011. The Year of the Retraction: A Look Back at 2011. Retraction Watch. https://retractionwatch.com/2011/12/30/the-year-of-the-retraction-a-look-back-at-2011/. Parish, Austin J., Kevin W. Boyack, and John P. A. Ioannidis. 2018. Dynamics of Co-Authorship and Productivity Across Different Fields of Scientific Research. Edited by Wolfgang Glanzel. PLOS ONE 13 (1): e0189742. https://doi.org/10.1371/journal.pone.0189742. Parker, Timothy H., Simon C. Griffith, Judith L. Bronstein, Fiona Fidler, Susan Foster, Hannah Fraser, Wolfgang Forstmeier, et al. 2018. Empowering Peer Reviewers with a Checklist to Improve Transparency. Nature Ecology &amp; Evolution 2 (6): 92935. https://doi.org/10.1038/s41559-018-0545-z. Pennisi, Elizabeth, 2020, and 2:10 Pm. 2020. Embattled Spider Biologist Seeks to Delay Additional Retractions of Problematic Papers. Science, March. https://www.sciencemag.org/news/2020/03/embattled-spider-biologist-seeks-delay-additional-retractions-problematic-papers. Perry, Gad, Jaime Bertoluci, Bruce Bury, Robert W. Hansen, Robert Jehle, John Measey, Brad R. Moon, Erin Muths, and Marco A. L. Zuffi. 2012. The Peer in Peer Review. African Journal of Herpetology 61 (1): 12. https://doi.org/10.1080/21564574.2012.658665. Peterson, A. Townsend, Robert P. Anderson, Maria Beger, Janine Bolliger, Lluís Brotons, Christopher P. Burridge, Marlon E. Cobos, Angela P. Cuervo-Robayo, Enrico Di Minin, and Jeffrey Diez. 2019. Open Access Solutions for Biodiversity Journals: Do Not Replace One Problem with Another. Diversity and Distributions 25 (1): 58. https://doi.org/https://doi.org/10.1111/ddi.12885. Piller, Charles. 2021. Disgraced COVID-19 Studies Are Still Routinely Cited. Science 371 (6527): 33132. https://doi.org/10.1126/science.371.6527.331. Pinfield, S., J. Salter, and P. A. Bath. 2016. The Total Cost of Publication in a Hybrid Open-Access Environment: Institutional Approaches to Funding Journal Article-Processing Charges in Combination with Subscriptions. Journal of the Association for Information Science and Technology 67 (7): 175166. https://doi.org/10.1002/asi.23446. Piwowar, Heather, Jason Priem, Vincent Larivière, Juan Pablo Alperin, Lisa Matthias, Bree Norlander, Ashley Farley, Jevin West, and Stefanie Haustein. 2018. The State of OA: A Large-Scale Analysis of the Prevalence and Impact of Open Access Articles. PeerJ 6: e4375. https://doi.org/https://doi.org/10.7717/peerj.4375. Powers, Stephen M., and Stephanie E. Hampton. 2019. Open Science, Reproducibility, and Transparency in Ecology. Ecological Applications 29 (1): e01822. https://doi.org/https://doi.org/10.1002/eap.1822. Priem, Jason, Paul Groth, and Dario Taraborelli. 2012. The Altmetrics Collection. PloS One 7 (11): e48753. https://doi.org/10.1371/journal.pone.0048753. Quan, Wei, Bikun Chen, and Fei Shu. 2017. Publish or Impoverish: An Investigation of the Monetary Reward System of Science in China (1999-2016). Aslib Journal of Information Management 69 (5): 486502. https://doi.org/10.1108/AJIM-01-2017-0014. Raju, Reggie, and Jeremiah Pietersen. 2017. Library as Publisher: From an African Lens. Journal of Electronic Publishing 20 (2). https://doi.org/10.3998/3336451.0020.203. Rennie, Drummond, and Annette Flanagin. 1994. Authorship! Authorship!: Guests, Ghosts, Grafters, and the Two-Sided Coin. JAMA 271 (6): 46971. https://doi.org/10.1001/jama.1994.03510300075043. Ritchie, Stuart. 2020. Science Fictions: How Fraud, Bias, Negligence, and Hype Undermine the Search for Truth. Metropolitan Books. /books/1117290/science-fictions/9781529110647. Rittman, Martyn. 2020. Fast, Citable Feedback: Peer Reviews for Preprints and Other Content Types. Website. Crossref. https://www.crossref.org/blog/fast-citable-feedback-peer-reviews-for-preprints-and-other-content-types/. Ross-Hellauer, Tony. 2017. What Is Open Peer Review? A Systematic Review. F1000Research 6 (August): 588. https://doi.org/10.12688/f1000research.11369.2. Rothwell, Peter M., and Christopher N. Martyn. 2000. Reproducibility of Peer Review in Clinical Neuroscience: Is Agreement Between Reviewers Any Greater Than Would Be Expected by Chance Alone? Brain 123 (9): 196469. https://doi.org/10.1093/brain/123.9.1964. Sandström, Ulf, and Peter van den Besselaar. 2016. Quantity and/or Quality? The Importance of Publishing Many Papers. Edited by Pablo Dorta-González. PLOS ONE 11 (11): e0166149. https://doi.org/10.1371/journal.pone.0166149. Saunders, N. 2015. PubMed Retraction Reporting Update R-Bloggers. https://www.r-bloggers.com/2015/03/pubmed-retraction-reporting-update/. Schiltz, Marc. 2018. Science Without Publication Paywalls: cOAlition S for the Realisation of Full and Immediate Open Access. PLoS Medicine 15 (9): e1002663. https://doi.org/https://doi.org/10.1371/journal.pbio.3000031. Schroter, Sara, Nick Black, Stephen Evans, James Carpenter, Fiona Godlee, and Richard Smith. 2004. Effects of Training on Quality of Peer Review: Randomised Controlled Trial. BMJ 328 (7441): 673. https://doi.org/10.1136/bmj.38023.700775.AE. Sidiropoulos, Antonis, Dimitrios Katsaros, and Yannis Manolopoulos. 2007. Generalized Hirsch h-Index for Disclosing Latent Facts in Citation Networks. Scientometrics 72 (2): 25380. https://doi.org/10.1007/s11192-007-1722-z. Silbiger, Nyssa J., and Amber D. Stubler. 2019. Unprofessional Peer Reviews Disproportionately Harm Underrepresented Groups in STEM. PeerJ 7 (December): e8247. https://doi.org/10.7717/peerj.8247. Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. 2011. False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science 22 (11): 135966. https://doi.org/https://doi.org/10.1177/0956797611417632. Smaldino, Paul E., and Richard McElreath. 2016. The Natural Selection of Bad Science. Royal Society Open Science 3 (9): 160384. https://doi.org/https://doi.org/10.1098/rsos.160384. Smith, Elise M. n.d. Reimagining the Peer-Review System for Translational Health Science Journals. Clinical and Translational Science n/a (n/a). Accessed May 21, 2021. https://doi.org/https://doi.org/10.1111/cts.13050. Stergiou, Konstantinos I., and Stephan Lessenich. 2014. On Impact Factors and University Rankings: From Birth to Boycott. Ethics in Science and Environmental Politics 13 (2): 10111. https://doi.org/https://doi.org/10.3354/esep00141. Stevenson, Ben C., David L. Borchers, Res Altwegg, René J. Swift, Douglas M. Gillespie, and G. John Measey. 2015. A General Framework for Animal Density Estimation from Acoustic Detections Across a Fixed Microphone Array. Methods in Ecology and Evolution 6 (1): 3848. https://doi.org/https://doi.org/10.1111/2041-210X.12291. Stubb, Jenni, Kirsi Pyhältö, and Kirsti Lonka. 2011. Balancing Between Inspiration and Exhaustion: PhD Students Experienced Socio-Psychological Well-Being. Studies in Continuing Education 33 (1): 3350. https://doi.org/https://doi.org/10.1080/0158037X.2010.515572. Teixeira da Silva, Jaime A. 2021. The Matthew Effect Impacts Science and Academic Publishing by Preferentially Amplifying Citations, Metrics and Status. Scientometrics 126 (6): 537377. https://doi.org/10.1007/s11192-021-03967-2. Tennant, Jon. 2017. The Open Access Citation Advantage. Retrieved August 2. https://doi.org/DOI: 10.14293/S2199-1006.1.SOR-EDU.CLPDPZB.v1. Thurner, S., and R. Hanel. 2011. Peer-Review in a World with Rational Scientists: Toward Selection of the Average. The European Physical Journal B 84 (4): 70711. https://doi.org/10.1140/epjb/e2011-20545-7. Tomkins, Andrew, Min Zhang, and William D. Heavlin. 2017. Single Versus Double Blind Reviewing at WSDM 2017. arXiv:1702.00502 [Cs], October. https://doi.org/https://arxiv.org/abs/1702.00502v6. Toro, V. P., A. D. Padhye, M. V. Biware, and N. A. Ghaya. 2019. Retraction Note to: Larvicidal Effects of GC-MS Fractions from Leaf Extracts of Cassia Uniflora Mill Non Spreng. Journal of Biosciences 44 (4): 76. https://doi.org/10.1007/s12038-019-9892-4. Travis, G. D. L., and H. M. Collins. 1991. New Light on Old Boys: Cognitive and Institutional Particularism in the Peer Review System. Science, Technology, &amp; Human Values 16 (3): 32241. https://doi.org/10.1177/016224399101600303. Tregenza, Tom. 2002. Gender Bias in the Refereeing Process? Trends in Ecology &amp; Evolution 17 (8): 34950. https://doi.org/10.1016/S0169-5347(02)02545-4. Trivers, Robert. 2011. The Folly of Fools: The Logic of Deceit and Self-Deception in Human Life. 1st edition. New York, NY: Basic Books. Vale, Ronald D. 2015. Accelerating Scientific Publication in Biology. Proceedings of the National Academy of Sciences 112 (44): 1343946. https://doi.org/10.1073/pnas.1511912112. VanDenBerg, Ryan, Nariman Nezami, Vi Nguyen, Jason K. Sicklick, and Clifford R. Weiss. 2021. A Solution to Academic Radiologys Experience With Solicitation E-Mails From Predatory Journals. American Journal of Roentgenology 216 (1): 23340. https://doi.org/DOI: 10.2214/AJR.20.22923. Voelkl, Bernhard, Naomi S. Altman, Anders Forsman, Wolfgang Forstmeier, Jessica Gurevitch, Ivana Jaric, Natasha A. Karp, et al. 2020. Reproducibility of Animal Research in Light of Biological Variation. Nature Reviews Neuroscience 21 (7): 38493. https://doi.org/10.1038/s41583-020-0313-3. Vogel, Gretchen, 2014, and 1:30 Pm. 2014. German University Tells Elsevier No Deal. Science AAAS. https://www.sciencemag.org/news/2014/03/german-university-tells-elsevier-no-deal. Wager, Elizabeth. 2006a. Suspected Fabricated Data in a Submitted Manuscript. Committee on Publication Ethics. https://doi.org/10.24318/cope.2019.2.3. . 2006b. Suspected Ghost, Guest or Gift Authorship. Committee on Publication Ethics. https://doi.org/10.24318/cope.2019.2.18. Wager, Elizabeth, Sanjay Singhvi, and Sabine Kleinert. 2015. Too Much of a Good Thing? An Observational Study of Prolific Authors. PeerJ 3: e1154. https://doi.org/https://doi.org/10.7717/peerj.1154. Wager, Liz. 2006. Suspected Plagiarism in a Submitted Manuscript. Committee on Publication Ethics. https://doi.org/10.24318/cope.2019.2.1. Wang, Peiling, Sukjin You, R Manasa, and Dietmar Wolfram. 2016. Open Peer Review in Scientific Publishing: A Web Mining Study of Authors and Reviewers. Journal of Data and Information Science. https://doi.org/10.20309/jdis.201625. Willett, Peter. 2013. The Characteristics of Journal Editorial Boards in Library and Information Science. International Journal of Knowledge Content Development &amp; Technology 3 (1): 517. https://doi.org/10.5865/IJKCT.2013.3.1.005. Wislar, Joseph S., Annette Flanagin, Phil B. Fontanarosa, and Catherine D. DeAngelis. 2011. Honorary and Ghost Authorship in High Impact Biomedical Journals: A Cross Sectional Survey. BMJ 343 (October): d6128. https://doi.org/10.1136/bmj.d6128. Xie, Yihui. 2016. Bookdown: Authoring Books and Technical Documents with R Markdown. CRC Press. Xie, Yihui, Joseph J Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. CRC Press. Zong, Qianjin, Yafen Xie, and Jiechun Liang. 2020. Does Open Peer Review Improve Citation Count? Evidence from a Propensity Score Matching Analysis of PeerJ. Scientometrics 125 (1): 60723. https://doi.org/10.1007/s11192-020-03545-y. Zvereva, Elena L., and Mikhail V. Kozlov. 2021. Biases in Ecological Research: Attitudes of Scientists and Ways of Control. Scientific Reports 11 (1): 226. https://doi.org/10.1038/s41598-020-80677-4. "]]
